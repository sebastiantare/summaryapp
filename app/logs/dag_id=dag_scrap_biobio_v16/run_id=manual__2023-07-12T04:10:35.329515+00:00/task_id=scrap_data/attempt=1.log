[2023-07-12T04:10:37.343+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: dag_scrap_biobio_v16.scrap_data manual__2023-07-12T04:10:35.329515+00:00 [queued]>
[2023-07-12T04:10:37.352+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: dag_scrap_biobio_v16.scrap_data manual__2023-07-12T04:10:35.329515+00:00 [queued]>
[2023-07-12T04:10:37.352+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-07-12T04:10:37.367+0000] {taskinstance.py:1327} INFO - Executing <Task(_PythonVirtualenvDecoratedOperator): scrap_data> on 2023-07-12 04:10:35.329515+00:00
[2023-07-12T04:10:37.375+0000] {standard_task_runner.py:57} INFO - Started process 3232 to run task
[2023-07-12T04:10:37.378+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'dag_scrap_biobio_v16', 'scrap_data', 'manual__2023-07-12T04:10:35.329515+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/dag_scrap_biobio.py', '--cfg-path', '/tmp/tmp8rnu7wxf']
[2023-07-12T04:10:37.378+0000] {standard_task_runner.py:85} INFO - Job 12: Subtask scrap_data
[2023-07-12T04:10:37.416+0000] {task_command.py:410} INFO - Running <TaskInstance: dag_scrap_biobio_v16.scrap_data manual__2023-07-12T04:10:35.329515+00:00 [running]> on host bfd1c2ede1e4
[2023-07-12T04:10:37.479+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='dag_scrap_biobio_v16' AIRFLOW_CTX_TASK_ID='scrap_data' AIRFLOW_CTX_EXECUTION_DATE='2023-07-12T04:10:35.329515+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-07-12T04:10:35.329515+00:00'
[2023-07-12T04:10:37.480+0000] {process_utils.py:181} INFO - Executing cmd: /usr/local/bin/python -m virtualenv /tmp/venv_rhfupe2 --system-site-packages --python=python3.9
[2023-07-12T04:10:37.491+0000] {process_utils.py:185} INFO - Output:
[2023-07-12T04:10:39.153+0000] {process_utils.py:189} INFO - created virtual environment CPython3.9.2.final.0-64 in 1071ms
[2023-07-12T04:10:39.153+0000] {process_utils.py:189} INFO -   creator CPython3Posix(dest=/tmp/venv_rhfupe2, clear=False, no_vcs_ignore=False, global=True)
[2023-07-12T04:10:39.154+0000] {process_utils.py:189} INFO -   seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/tmp/tmpq8fmyphj)
[2023-07-12T04:10:39.154+0000] {process_utils.py:189} INFO -     added seed packages: pip==23.1, setuptools==67.6.1, wheel==0.40.0
[2023-07-12T04:10:39.154+0000] {process_utils.py:189} INFO -   activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
[2023-07-12T04:10:39.187+0000] {process_utils.py:181} INFO - Executing cmd: /tmp/venv_rhfupe2/bin/pip install -r /tmp/venv_rhfupe2/requirements.txt
[2023-07-12T04:10:39.196+0000] {process_utils.py:185} INFO - Output:
[2023-07-12T04:10:39.723+0000] {process_utils.py:189} INFO - WARNING: The directory '/home/***/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.
[2023-07-12T04:10:40.083+0000] {process_utils.py:189} INFO - Collecting selenium (from -r /tmp/venv_rhfupe2/requirements.txt (line 1))
[2023-07-12T04:10:40.206+0000] {process_utils.py:189} INFO -   Downloading selenium-4.10.0-py3-none-any.whl (6.7 MB)
[2023-07-12T04:10:40.386+0000] {process_utils.py:189} INFO -      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.7/6.7 MB 37.9 MB/s eta 0:00:00
[2023-07-12T04:10:40.547+0000] {process_utils.py:189} INFO - Collecting pyspark (from -r /tmp/venv_rhfupe2/requirements.txt (line 2))
[2023-07-12T04:10:40.577+0000] {process_utils.py:189} INFO -   Downloading pyspark-3.4.1.tar.gz (310.8 MB)
[2023-07-12T04:11:08.440+0000] {process_utils.py:189} INFO -      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 310.8/310.8 MB 30.6 MB/s eta 0:00:00
[2023-07-12T04:11:11.600+0000] {process_utils.py:189} INFO -   Preparing metadata (setup.py): started
[2023-07-12T04:11:11.811+0000] {process_utils.py:189} INFO -   Preparing metadata (setup.py): finished with status 'done'
[2023-07-12T04:11:11.864+0000] {process_utils.py:189} INFO - Collecting dateparser (from -r /tmp/venv_rhfupe2/requirements.txt (line 3))
[2023-07-12T04:11:11.902+0000] {process_utils.py:189} INFO -   Downloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)
[2023-07-12T04:11:11.909+0000] {process_utils.py:189} INFO -      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 293.8/293.8 kB 62.3 MB/s eta 0:00:00
[2023-07-12T04:11:11.969+0000] {process_utils.py:189} INFO - Collecting urllib3[socks]<3,>=1.26 (from selenium->-r /tmp/venv_rhfupe2/requirements.txt (line 1))
[2023-07-12T04:11:11.996+0000] {process_utils.py:189} INFO -   Downloading urllib3-2.0.3-py3-none-any.whl (123 kB)
[2023-07-12T04:11:12.002+0000] {process_utils.py:189} INFO -      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.6/123.6 kB 35.1 MB/s eta 0:00:00
[2023-07-12T04:11:12.171+0000] {process_utils.py:189} INFO - Collecting trio~=0.17 (from selenium->-r /tmp/venv_rhfupe2/requirements.txt (line 1))
[2023-07-12T04:11:12.206+0000] {process_utils.py:189} INFO -   Downloading trio-0.22.1-py3-none-any.whl (399 kB)
[2023-07-12T04:11:12.216+0000] {process_utils.py:189} INFO -      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 399.3/399.3 kB 54.3 MB/s eta 0:00:00
[2023-07-12T04:11:12.377+0000] {process_utils.py:189} INFO - Collecting trio-websocket~=0.9 (from selenium->-r /tmp/venv_rhfupe2/requirements.txt (line 1))
[2023-07-12T04:11:12.408+0000] {process_utils.py:189} INFO -   Downloading trio_websocket-0.10.3-py3-none-any.whl (17 kB)
[2023-07-12T04:11:12.466+0000] {process_utils.py:189} INFO - Collecting certifi>=2021.10.8 (from selenium->-r /tmp/venv_rhfupe2/requirements.txt (line 1))
[2023-07-12T04:11:12.492+0000] {process_utils.py:189} INFO -   Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)
[2023-07-12T04:11:12.499+0000] {process_utils.py:189} INFO -      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 157.0/157.0 kB 49.2 MB/s eta 0:00:00
[2023-07-12T04:11:12.679+0000] {process_utils.py:189} INFO - Collecting py4j==0.10.9.7 (from pyspark->-r /tmp/venv_rhfupe2/requirements.txt (line 2))
[2023-07-12T04:11:12.708+0000] {process_utils.py:189} INFO -   Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)
[2023-07-12T04:11:12.720+0000] {process_utils.py:189} INFO -      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200.5/200.5 kB 21.4 MB/s eta 0:00:00
[2023-07-12T04:11:12.772+0000] {process_utils.py:189} INFO - Collecting python-dateutil (from dateparser->-r /tmp/venv_rhfupe2/requirements.txt (line 3))
[2023-07-12T04:11:12.796+0000] {process_utils.py:189} INFO -   Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)
[2023-07-12T04:11:12.805+0000] {process_utils.py:189} INFO -      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 kB 39.9 MB/s eta 0:00:00
[2023-07-12T04:11:12.918+0000] {process_utils.py:189} INFO - Collecting pytz (from dateparser->-r /tmp/venv_rhfupe2/requirements.txt (line 3))
[2023-07-12T04:11:12.950+0000] {process_utils.py:189} INFO -   Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)
[2023-07-12T04:11:12.958+0000] {process_utils.py:189} INFO -      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 502.3/502.3 kB 70.1 MB/s eta 0:00:00
[2023-07-12T04:11:13.634+0000] {process_utils.py:189} INFO - Collecting regex!=2019.02.19,!=2021.8.27 (from dateparser->-r /tmp/venv_rhfupe2/requirements.txt (line 3))
[2023-07-12T04:11:13.669+0000] {process_utils.py:189} INFO -   Downloading regex-2023.6.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)
[2023-07-12T04:11:13.684+0000] {process_utils.py:189} INFO -      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 769.9/769.9 kB 62.4 MB/s eta 0:00:00
[2023-07-12T04:11:13.849+0000] {process_utils.py:189} INFO - Collecting tzlocal (from dateparser->-r /tmp/venv_rhfupe2/requirements.txt (line 3))
[2023-07-12T04:11:13.871+0000] {process_utils.py:189} INFO -   Downloading tzlocal-5.0.1-py3-none-any.whl (20 kB)
[2023-07-12T04:11:13.919+0000] {process_utils.py:189} INFO - Collecting attrs>=20.1.0 (from trio~=0.17->selenium->-r /tmp/venv_rhfupe2/requirements.txt (line 1))
[2023-07-12T04:11:13.953+0000] {process_utils.py:189} INFO -   Downloading attrs-23.1.0-py3-none-any.whl (61 kB)
[2023-07-12T04:11:13.957+0000] {process_utils.py:189} INFO -      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 kB 23.5 MB/s eta 0:00:00
[2023-07-12T04:11:14.115+0000] {process_utils.py:189} INFO - Collecting sortedcontainers (from trio~=0.17->selenium->-r /tmp/venv_rhfupe2/requirements.txt (line 1))
[2023-07-12T04:11:14.144+0000] {process_utils.py:189} INFO -   Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)
[2023-07-12T04:11:14.187+0000] {process_utils.py:189} INFO - Collecting idna (from trio~=0.17->selenium->-r /tmp/venv_rhfupe2/requirements.txt (line 1))
[2023-07-12T04:11:14.216+0000] {process_utils.py:189} INFO -   Downloading idna-3.4-py3-none-any.whl (61 kB)
[2023-07-12T04:11:14.220+0000] {process_utils.py:189} INFO -      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.5/61.5 kB 29.0 MB/s eta 0:00:00
[2023-07-12T04:11:14.400+0000] {process_utils.py:189} INFO - Collecting outcome (from trio~=0.17->selenium->-r /tmp/venv_rhfupe2/requirements.txt (line 1))
[2023-07-12T04:11:14.426+0000] {process_utils.py:189} INFO -   Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)
[2023-07-12T04:11:14.459+0000] {process_utils.py:189} INFO - Collecting sniffio (from trio~=0.17->selenium->-r /tmp/venv_rhfupe2/requirements.txt (line 1))
[2023-07-12T04:11:14.482+0000] {process_utils.py:189} INFO -   Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)
[2023-07-12T04:11:14.523+0000] {process_utils.py:189} INFO - Collecting exceptiongroup>=1.0.0rc9 (from trio~=0.17->selenium->-r /tmp/venv_rhfupe2/requirements.txt (line 1))
[2023-07-12T04:11:14.554+0000] {process_utils.py:189} INFO -   Downloading exceptiongroup-1.1.2-py3-none-any.whl (14 kB)
[2023-07-12T04:11:14.717+0000] {process_utils.py:189} INFO - Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium->-r /tmp/venv_rhfupe2/requirements.txt (line 1))
[2023-07-12T04:11:14.738+0000] {process_utils.py:189} INFO -   Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)
[2023-07-12T04:11:14.790+0000] {process_utils.py:189} INFO - Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium->-r /tmp/venv_rhfupe2/requirements.txt (line 1))
[2023-07-12T04:11:14.817+0000] {process_utils.py:189} INFO -   Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)
[2023-07-12T04:11:14.868+0000] {process_utils.py:189} INFO - Collecting six>=1.5 (from python-dateutil->dateparser->-r /tmp/venv_rhfupe2/requirements.txt (line 3))
[2023-07-12T04:11:14.893+0000] {process_utils.py:189} INFO -   Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)
[2023-07-12T04:11:14.977+0000] {process_utils.py:189} INFO - Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium->-r /tmp/venv_rhfupe2/requirements.txt (line 1))
[2023-07-12T04:11:15.009+0000] {process_utils.py:189} INFO -   Downloading h11-0.14.0-py3-none-any.whl (58 kB)
[2023-07-12T04:11:15.011+0000] {process_utils.py:189} INFO -      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 57.0 MB/s eta 0:00:00
[2023-07-12T04:11:15.033+0000] {process_utils.py:189} INFO - Building wheels for collected packages: pyspark
[2023-07-12T04:11:15.034+0000] {process_utils.py:189} INFO -   Building wheel for pyspark (setup.py): started
[2023-07-12T04:11:26.887+0000] {process_utils.py:189} INFO -   Building wheel for pyspark (setup.py): finished with status 'done'
[2023-07-12T04:11:27.098+0000] {process_utils.py:189} INFO -   Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285398 sha256=f2eafb78b20cabc4d9df78ba66a53afe129ef1cfd7b525f2be45b0370eb15bb5
[2023-07-12T04:11:27.098+0000] {process_utils.py:189} INFO -   Stored in directory: /tmp/pip-ephem-wheel-cache-x0ju9_30/wheels/2b/9a/39/d8019ffbfb76a39433455e3d5799e94d3e3cae8f41229f6bf8
[2023-07-12T04:11:27.103+0000] {process_utils.py:189} INFO - Successfully built pyspark
[2023-07-12T04:11:28.112+0000] {process_utils.py:189} INFO - Installing collected packages: sortedcontainers, pytz, py4j, urllib3, tzlocal, sniffio, six, regex, pyspark, pysocks, idna, h11, exceptiongroup, certifi, attrs, wsproto, python-dateutil, outcome, trio, dateparser, trio-websocket, selenium
[2023-07-12T04:11:36.347+0000] {process_utils.py:189} INFO - Successfully installed attrs-23.1.0 certifi-2023.5.7 dateparser-1.1.8 exceptiongroup-1.1.2 h11-0.14.0 idna-3.4 outcome-1.2.0 py4j-0.10.9.7 pysocks-1.7.1 pyspark-3.4.1 python-dateutil-2.8.2 pytz-2023.3 regex-2023.6.3 selenium-4.10.0 six-1.16.0 sniffio-1.3.0 sortedcontainers-2.4.0 trio-0.22.1 trio-websocket-0.10.3 tzlocal-5.0.1 urllib3-2.0.3 wsproto-1.2.0
[2023-07-12T04:11:36.490+0000] {process_utils.py:189} INFO - 
[2023-07-12T04:11:36.490+0000] {process_utils.py:189} INFO - [notice] A new release of pip is available: 23.1 -> 23.1.2
[2023-07-12T04:11:36.490+0000] {process_utils.py:189} INFO - [notice] To update, run: /tmp/venv_rhfupe2/bin/python -m pip install --upgrade pip
[2023-07-12T04:11:36.727+0000] {process_utils.py:181} INFO - Executing cmd: /tmp/venv_rhfupe2/bin/python /tmp/venv_rhfupe2/script.py /tmp/venv_rhfupe2/script.in /tmp/venv_rhfupe2/script.out /tmp/venv_rhfupe2/string_args.txt
[2023-07-12T04:11:36.736+0000] {process_utils.py:185} INFO - Output:
[2023-07-12T04:11:37.064+0000] {process_utils.py:189} INFO - /tmp/venv_rhfupe2/lib/python3.9/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found
[2023-07-12T04:11:38.431+0000] {process_utils.py:189} INFO - Setting default log level to "WARN".
[2023-07-12T04:11:38.432+0000] {process_utils.py:189} INFO - To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[2023-07-12T04:11:38.546+0000] {process_utils.py:189} INFO - 23/07/12 04:11:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2023-07-12T04:11:47.563+0000] {process_utils.py:189} INFO - 1) BROWSER OK
[2023-07-12T04:11:47.564+0000] {process_utils.py:189} INFO - 2) GET OK
[2023-07-12T04:11:47.564+0000] {process_utils.py:189} INFO - 3) BUTTON OK
[2023-07-12T04:11:47.564+0000] {process_utils.py:189} INFO - 4) CLICK OK
[2023-07-12T04:11:47.564+0000] {process_utils.py:189} INFO - 5) FETCH OK
[2023-07-12T04:11:47.564+0000] {process_utils.py:189} INFO - 6) FETCH 2 OK
[2023-07-12T04:11:47.564+0000] {process_utils.py:189} INFO - Loading data...
[2023-07-12T04:11:47.564+0000] {process_utils.py:189} INFO - +--------------------+--------------------+--------+------------+------------+-----------+--------------+--------------------+-----------------+--------------+----------------+
[2023-07-12T04:11:47.564+0000] {process_utils.py:189} INFO - |        article_hash|       article_title|category|publish_date|article_body|raw_content| source_entity|        article_link|generated_summary|negative_score|importance_score|
[2023-07-12T04:11:47.565+0000] {process_utils.py:189} INFO - +--------------------+--------------------+--------+------------+------------+-----------+--------------+--------------------+-----------------+--------------+----------------+
[2023-07-12T04:11:47.565+0000] {process_utils.py:189} INFO - |af63fcde0cd7f3918...|¿Senador Sharp? O...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.565+0000] {process_utils.py:189} INFO - |4eae11c756252f500...|Comisión de la Cá...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.565+0000] {process_utils.py:189} INFO - |f44577f3ee639dd0d...|Dos carabineros e...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.565+0000] {process_utils.py:189} INFO - |ae2c0e94606d95f86...|Ericka Ñanco eval...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.566+0000] {process_utils.py:189} INFO - |4cbedbd17db3b0a30...|Gonzalo Feito ase...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.566+0000] {process_utils.py:189} INFO - |a271e42bf9cfd4cf1...|Consejo del Salmó...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.566+0000] {process_utils.py:189} INFO - |5085bf3f60db339c9...|Amplían plazo par...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.566+0000] {process_utils.py:189} INFO - |891e35b4f0a1aad89...|Bobadilla se quer...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.566+0000] {process_utils.py:189} INFO - |9fc74a3dd2d7655c2...|Sistema frontal e...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.566+0000] {process_utils.py:189} INFO - |fba5ecc71e7d4fc10...|Meteorólogo Eduar...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.567+0000] {process_utils.py:189} INFO - |35dd86b7a1366af63...|CDE anuncia que v...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.567+0000] {process_utils.py:189} INFO - |fb98bcb849f2a0388...|Mejor Niñez recon...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.567+0000] {process_utils.py:189} INFO - |f8671487b22b4c622...|Oficialismo y opo...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.567+0000] {process_utils.py:189} INFO - |4394ba80fcb6d8426...|Confirman reunión...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.567+0000] {process_utils.py:189} INFO - |cc2615dfc7db6a890...|En prisión preven...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.567+0000] {process_utils.py:189} INFO - |e0c09687acfa7cb88...|Alcalde Sharp anu...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.567+0000] {process_utils.py:189} INFO - |52b27f27cfe61bf05...|Falsa desaparició...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.568+0000] {process_utils.py:189} INFO - |8f2880ff0e5e60e55...|Viña del Mar: fam...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.568+0000] {process_utils.py:189} INFO - |b3949e116eac6d65c...|Desarticulan band...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.568+0000] {process_utils.py:189} INFO - |de9101c92fb0f99e6...|"No soy homofóbic...|Nacional|        null|        null|       null|biobiochile.cl|https://www.biobi...|             null|          null|            null|
[2023-07-12T04:11:47.568+0000] {process_utils.py:189} INFO - +--------------------+--------------------+--------+------------+------------+-----------+--------------+--------------------+-----------------+--------------+----------------+
[2023-07-12T04:11:47.568+0000] {process_utils.py:189} INFO - only showing top 20 rows
[2023-07-12T04:11:47.568+0000] {process_utils.py:189} INFO - 
[2023-07-12T04:11:47.568+0000] {process_utils.py:189} INFO - Traceback (most recent call last):
[2023-07-12T04:11:47.568+0000] {process_utils.py:189} INFO -   File "/tmp/venv_rhfupe2/script.py", line 163, in <module>
[2023-07-12T04:11:47.568+0000] {process_utils.py:189} INFO -     res = scrapData(*arg_dict["args"], **arg_dict["kwargs"])
[2023-07-12T04:11:47.569+0000] {process_utils.py:189} INFO -   File "/tmp/venv_rhfupe2/script.py", line 159, in scrapData
[2023-07-12T04:11:47.569+0000] {process_utils.py:189} INFO -     writeToDB(data_df)
[2023-07-12T04:11:47.569+0000] {process_utils.py:189} INFO -   File "/tmp/venv_rhfupe2/script.py", line 74, in writeToDB
[2023-07-12T04:11:47.569+0000] {process_utils.py:189} INFO -     data.write \
[2023-07-12T04:11:47.569+0000] {process_utils.py:189} INFO -   File "/tmp/venv_rhfupe2/lib/python3.9/site-packages/pyspark/sql/readwriter.py", line 1396, in save
[2023-07-12T04:11:47.569+0000] {process_utils.py:189} INFO -     self._jwrite.save()
[2023-07-12T04:11:47.569+0000] {process_utils.py:189} INFO -   File "/tmp/venv_rhfupe2/lib/python3.9/site-packages/py4j/java_gateway.py", line 1322, in __call__
[2023-07-12T04:11:47.569+0000] {process_utils.py:189} INFO -     return_value = get_return_value(
[2023-07-12T04:11:47.569+0000] {process_utils.py:189} INFO -   File "/tmp/venv_rhfupe2/lib/python3.9/site-packages/pyspark/errors/exceptions/captured.py", line 169, in deco
[2023-07-12T04:11:47.569+0000] {process_utils.py:189} INFO -     return f(*a, **kw)
[2023-07-12T04:11:47.569+0000] {process_utils.py:189} INFO -   File "/tmp/venv_rhfupe2/lib/python3.9/site-packages/py4j/protocol.py", line 326, in get_return_value
[2023-07-12T04:11:47.569+0000] {process_utils.py:189} INFO -     raise Py4JJavaError(
[2023-07-12T04:11:47.570+0000] {process_utils.py:189} INFO - py4j.protocol.Py4JJavaError: An error occurred while calling o45.save.
[2023-07-12T04:11:47.570+0000] {process_utils.py:189} INFO - : java.sql.SQLException: No suitable driver
[2023-07-12T04:11:47.570+0000] {process_utils.py:189} INFO - 	at java.sql/java.sql.DriverManager.getDriver(DriverManager.java:298)
[2023-07-12T04:11:47.570+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.$anonfun$driverClass$2(JDBCOptions.scala:109)
[2023-07-12T04:11:47.570+0000] {process_utils.py:189} INFO - 	at scala.Option.getOrElse(Option.scala:189)
[2023-07-12T04:11:47.570+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.datasources.jdbc.JDBCOptions.<init>(JDBCOptions.scala:109)
[2023-07-12T04:11:47.570+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:246)
[2023-07-12T04:11:47.570+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.datasources.jdbc.JdbcOptionsInWrite.<init>(JDBCOptions.scala:250)
[2023-07-12T04:11:47.570+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:47)
[2023-07-12T04:11:47.571+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)
[2023-07-12T04:11:47.571+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
[2023-07-12T04:11:47.571+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
[2023-07-12T04:11:47.571+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
[2023-07-12T04:11:47.571+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)
[2023-07-12T04:11:47.571+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)
[2023-07-12T04:11:47.571+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)
[2023-07-12T04:11:47.571+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)
[2023-07-12T04:11:47.571+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)
[2023-07-12T04:11:47.572+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)
[2023-07-12T04:11:47.572+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
[2023-07-12T04:11:47.572+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)
[2023-07-12T04:11:47.572+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)
[2023-07-12T04:11:47.572+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)
[2023-07-12T04:11:47.572+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)
[2023-07-12T04:11:47.572+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)
[2023-07-12T04:11:47.572+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
[2023-07-12T04:11:47.572+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
[2023-07-12T04:11:47.573+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)
[2023-07-12T04:11:47.573+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)
[2023-07-12T04:11:47.573+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)
[2023-07-12T04:11:47.573+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)
[2023-07-12T04:11:47.573+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)
[2023-07-12T04:11:47.573+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)
[2023-07-12T04:11:47.573+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)
[2023-07-12T04:11:47.573+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)
[2023-07-12T04:11:47.573+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)
[2023-07-12T04:11:47.573+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)
[2023-07-12T04:11:47.574+0000] {process_utils.py:189} INFO - 	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)
[2023-07-12T04:11:47.574+0000] {process_utils.py:189} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2023-07-12T04:11:47.574+0000] {process_utils.py:189} INFO - 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[2023-07-12T04:11:47.574+0000] {process_utils.py:189} INFO - 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[2023-07-12T04:11:47.574+0000] {process_utils.py:189} INFO - 	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
[2023-07-12T04:11:47.574+0000] {process_utils.py:189} INFO - 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
[2023-07-12T04:11:47.574+0000] {process_utils.py:189} INFO - 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
[2023-07-12T04:11:47.574+0000] {process_utils.py:189} INFO - 	at py4j.Gateway.invoke(Gateway.java:282)
[2023-07-12T04:11:47.574+0000] {process_utils.py:189} INFO - 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
[2023-07-12T04:11:47.574+0000] {process_utils.py:189} INFO - 	at py4j.commands.CallCommand.execute(CallCommand.java:79)
[2023-07-12T04:11:47.575+0000] {process_utils.py:189} INFO - 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
[2023-07-12T04:11:47.575+0000] {process_utils.py:189} INFO - 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
[2023-07-12T04:11:47.575+0000] {process_utils.py:189} INFO - 	at java.base/java.lang.Thread.run(Thread.java:829)
[2023-07-12T04:11:47.575+0000] {process_utils.py:189} INFO - 
[2023-07-12T04:11:48.252+0000] {taskinstance.py:1824} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/decorators/base.py", line 220, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 374, in execute
    return super().execute(context=serializable_context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 181, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 578, in execute_callable
    result = self._execute_python_callable_in_subprocess(python_path, tmp_path)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 434, in _execute_python_callable_in_subprocess
    os.fspath(string_args_path),
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/process_utils.py", line 170, in execute_in_subprocess
    execute_in_subprocess_with_kwargs(cmd, cwd=cwd)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/process_utils.py", line 193, in execute_in_subprocess_with_kwargs
    raise subprocess.CalledProcessError(exit_code, cmd)
subprocess.CalledProcessError: Command '['/tmp/venv_rhfupe2/bin/python', '/tmp/venv_rhfupe2/script.py', '/tmp/venv_rhfupe2/script.in', '/tmp/venv_rhfupe2/script.out', '/tmp/venv_rhfupe2/string_args.txt']' returned non-zero exit status 1.
[2023-07-12T04:11:48.261+0000] {taskinstance.py:1350} INFO - Marking task as FAILED. dag_id=dag_scrap_biobio_v16, task_id=scrap_data, execution_date=20230712T041035, start_date=20230712T041037, end_date=20230712T041148
[2023-07-12T04:11:48.282+0000] {standard_task_runner.py:109} ERROR - Failed to execute job 12 for task scrap_data (Command '['/tmp/venv_rhfupe2/bin/python', '/tmp/venv_rhfupe2/script.py', '/tmp/venv_rhfupe2/script.in', '/tmp/venv_rhfupe2/script.out', '/tmp/venv_rhfupe2/string_args.txt']' returned non-zero exit status 1.; 3232)
[2023-07-12T04:11:48.293+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 1
[2023-07-12T04:11:48.305+0000] {taskinstance.py:2653} INFO - 0 downstream tasks scheduled from follow-on schedule check
