[2023-07-07T00:00:13.741+0000] {processor.py:157} INFO - Started process (PID=1528) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:00:13.741+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:00:13.742+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:00:13.741+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:00:14.566+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:00:14.565+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:00:14.566+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:00:14.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.844 seconds
[2023-07-07T00:00:44.837+0000] {processor.py:157} INFO - Started process (PID=1550) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:00:44.838+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:00:44.838+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:00:44.838+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:00:45.657+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:00:45.657+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:00:45.658+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:00:45.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.834 seconds
[2023-07-07T00:01:15.944+0000] {processor.py:157} INFO - Started process (PID=1573) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:01:15.951+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:01:15.951+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:01:15.951+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:01:16.697+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:01:16.696+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:01:16.698+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:01:16.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.770 seconds
[2023-07-07T00:01:47.226+0000] {processor.py:157} INFO - Started process (PID=1595) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:01:47.232+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:01:47.232+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:01:47.232+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:01:48.092+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:01:48.091+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:01:48.092+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:01:48.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.883 seconds
[2023-07-07T00:02:18.353+0000] {processor.py:157} INFO - Started process (PID=1617) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:02:18.364+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:02:18.365+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:02:18.365+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:02:19.175+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:02:19.174+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:02:19.175+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:02:19.186+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.836 seconds
[2023-07-07T00:02:49.613+0000] {processor.py:157} INFO - Started process (PID=1639) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:02:49.620+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:02:49.621+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:02:49.621+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:02:50.440+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:02:50.439+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:02:50.440+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:02:50.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.839 seconds
[2023-07-07T00:03:20.809+0000] {processor.py:157} INFO - Started process (PID=1661) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:03:20.815+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:03:20.816+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:03:20.816+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:03:21.560+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:03:21.559+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:03:21.561+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:03:21.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.765 seconds
[2023-07-07T00:03:52.022+0000] {processor.py:157} INFO - Started process (PID=1683) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:03:52.029+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:03:52.029+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:03:52.029+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:03:52.849+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:03:52.848+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:03:52.849+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:03:52.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.844 seconds
[2023-07-07T00:04:23.110+0000] {processor.py:157} INFO - Started process (PID=1705) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:04:23.121+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:04:23.122+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:04:23.122+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:04:23.947+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:04:23.946+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:04:23.947+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:04:23.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.851 seconds
[2023-07-07T00:04:54.229+0000] {processor.py:157} INFO - Started process (PID=1734) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:04:54.235+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:04:54.235+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:04:54.235+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:04:55.052+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:04:55.051+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:04:55.052+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:04:55.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.841 seconds
[2023-07-07T00:05:25.345+0000] {processor.py:157} INFO - Started process (PID=1756) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:05:25.350+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:05:25.350+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:05:25.350+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:05:26.086+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:05:26.085+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:05:26.086+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:05:26.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.754 seconds
[2023-07-07T00:05:56.585+0000] {processor.py:157} INFO - Started process (PID=1778) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:05:56.590+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:05:56.591+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:05:56.591+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:05:57.400+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:05:57.399+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:05:57.400+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:05:57.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.834 seconds
[2023-07-07T00:06:27.808+0000] {processor.py:157} INFO - Started process (PID=1800) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:06:27.814+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:06:27.814+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:06:27.814+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:06:28.621+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:06:28.620+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:06:28.621+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:06:28.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.830 seconds
[2023-07-07T00:06:58.885+0000] {processor.py:157} INFO - Started process (PID=1822) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:06:58.890+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:06:58.890+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:06:58.890+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:06:59.695+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:06:59.694+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:06:59.695+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:06:59.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.830 seconds
[2023-07-07T00:07:30.126+0000] {processor.py:157} INFO - Started process (PID=1844) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:07:30.132+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:07:30.132+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:07:30.132+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:07:30.865+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:07:30.864+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:07:30.865+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:07:30.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.757 seconds
[2023-07-07T00:08:01.383+0000] {processor.py:157} INFO - Started process (PID=1866) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:08:01.390+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:08:01.390+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:08:01.390+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:08:02.218+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:08:02.217+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:08:02.218+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:08:02.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.851 seconds
[2023-07-07T00:08:32.524+0000] {processor.py:157} INFO - Started process (PID=1888) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:08:32.530+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:08:32.530+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:08:32.530+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:08:33.246+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:08:33.245+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:08:33.246+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:08:33.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.735 seconds
[2023-07-07T00:09:03.780+0000] {processor.py:157} INFO - Started process (PID=1910) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:09:03.788+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:09:03.789+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:09:03.789+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:09:04.599+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:09:04.598+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:09:04.599+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:09:04.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.832 seconds
[2023-07-07T00:09:34.888+0000] {processor.py:157} INFO - Started process (PID=1932) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:09:34.894+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:09:34.894+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:09:34.894+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:09:35.645+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:09:35.644+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:09:35.645+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:09:35.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.774 seconds
[2023-07-07T00:10:06.156+0000] {processor.py:157} INFO - Started process (PID=1954) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:10:06.161+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:10:06.161+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:10:06.161+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:10:06.984+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:10:06.983+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:10:06.984+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:10:06.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.842 seconds
[2023-07-07T00:10:37.303+0000] {processor.py:157} INFO - Started process (PID=1976) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:10:37.310+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:10:37.311+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:10:37.311+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:10:38.053+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:10:38.052+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:10:38.054+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:10:38.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.769 seconds
[2023-07-07T00:11:08.581+0000] {processor.py:157} INFO - Started process (PID=1998) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:11:08.586+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:11:08.586+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:11:08.586+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:11:09.420+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:11:09.419+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:11:09.420+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:11:09.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.857 seconds
[2023-07-07T00:11:39.710+0000] {processor.py:157} INFO - Started process (PID=2020) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:11:39.715+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:11:39.715+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:11:39.715+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:11:40.451+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:11:40.450+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:11:40.451+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:11:40.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.755 seconds
[2023-07-07T00:12:10.987+0000] {processor.py:157} INFO - Started process (PID=2042) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:12:10.992+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:12:10.993+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:12:10.993+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:12:11.808+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:12:11.807+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:12:11.808+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:12:11.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.834 seconds
[2023-07-07T00:12:42.101+0000] {processor.py:157} INFO - Started process (PID=2065) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:12:42.103+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:12:42.103+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:12:42.103+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:12:42.852+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:12:42.851+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:12:42.852+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:12:42.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.769 seconds
[2023-07-07T00:13:13.368+0000] {processor.py:157} INFO - Started process (PID=2087) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:13:13.379+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:13:13.379+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:13:13.379+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:13:14.192+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:13:14.191+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:13:14.192+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:13:14.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.844 seconds
[2023-07-07T00:13:44.619+0000] {processor.py:157} INFO - Started process (PID=2109) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:13:44.624+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:13:44.624+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:13:44.624+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:13:45.378+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:13:45.377+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:13:45.378+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:13:45.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.773 seconds
[2023-07-07T00:14:15.870+0000] {processor.py:157} INFO - Started process (PID=2131) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:14:15.876+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:14:15.876+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:14:15.876+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:14:16.681+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:14:16.680+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:14:16.681+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:14:16.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.824 seconds
[2023-07-07T00:14:47.129+0000] {processor.py:157} INFO - Started process (PID=2154) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:14:47.130+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:14:47.131+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:14:47.131+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:14:47.873+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:14:47.872+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:14:47.873+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:14:47.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.763 seconds
[2023-07-07T00:15:18.408+0000] {processor.py:157} INFO - Started process (PID=2176) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:15:18.413+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:15:18.414+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:15:18.414+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:15:19.228+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:15:19.227+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:15:19.228+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:15:19.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.834 seconds
[2023-07-07T00:15:49.514+0000] {processor.py:157} INFO - Started process (PID=2198) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:15:49.519+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:15:49.520+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:15:49.520+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:15:50.272+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:15:50.271+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:15:50.272+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:15:50.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.794 seconds
[2023-07-07T00:16:20.789+0000] {processor.py:157} INFO - Started process (PID=2221) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:16:20.798+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:16:20.799+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:16:20.799+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:16:21.617+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:16:21.617+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:16:21.618+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:16:21.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.842 seconds
[2023-07-07T00:16:51.981+0000] {processor.py:157} INFO - Started process (PID=2243) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:16:51.988+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:16:51.989+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:16:51.989+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:16:52.723+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:16:52.722+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:16:52.723+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:16:52.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.758 seconds
[2023-07-07T00:17:23.185+0000] {processor.py:157} INFO - Started process (PID=2265) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:17:23.191+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:17:23.191+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:17:23.191+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:17:24.029+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:17:24.028+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:17:24.029+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:17:24.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.860 seconds
[2023-07-07T00:17:54.311+0000] {processor.py:157} INFO - Started process (PID=2287) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:17:54.318+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:17:54.318+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:17:54.318+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:17:55.208+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:17:55.207+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:17:55.208+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:17:55.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.916 seconds
[2023-07-07T00:18:25.471+0000] {processor.py:157} INFO - Started process (PID=2309) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:18:25.472+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:18:25.472+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:18:25.472+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:18:26.343+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:18:26.342+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:18:26.344+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:18:26.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.885 seconds
[2023-07-07T00:18:56.613+0000] {processor.py:157} INFO - Started process (PID=2331) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:18:56.618+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:18:56.618+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:18:56.618+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:18:57.413+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:18:57.412+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:18:57.413+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:18:57.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.818 seconds
[2023-07-07T00:19:27.814+0000] {processor.py:157} INFO - Started process (PID=2360) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:19:27.822+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:19:27.823+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:19:27.822+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:19:28.647+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:19:28.646+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:19:28.647+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:19:28.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.846 seconds
[2023-07-07T00:19:59.033+0000] {processor.py:157} INFO - Started process (PID=2382) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:19:59.039+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:19:59.039+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:19:59.039+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:19:59.887+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:19:59.887+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:19:59.888+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:19:59.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.872 seconds
[2023-07-07T00:20:30.161+0000] {processor.py:157} INFO - Started process (PID=2404) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:20:30.173+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:20:30.174+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:20:30.174+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:20:31.009+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:20:31.008+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:20:31.010+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:20:31.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.867 seconds
[2023-07-07T00:21:01.285+0000] {processor.py:157} INFO - Started process (PID=2426) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:21:01.297+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:21:01.297+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:21:01.297+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:21:02.080+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:21:02.079+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:21:02.080+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:21:02.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.808 seconds
[2023-07-07T00:21:32.512+0000] {processor.py:157} INFO - Started process (PID=2448) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:21:32.518+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:21:32.518+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:21:32.518+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:21:33.353+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:21:33.352+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:21:33.353+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:21:33.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.859 seconds
[2023-07-07T00:22:03.606+0000] {processor.py:157} INFO - Started process (PID=2470) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:22:03.613+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:22:03.613+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:22:03.613+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:22:04.449+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:22:04.448+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:22:04.449+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:22:04.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.856 seconds
[2023-07-07T00:22:34.723+0000] {processor.py:157} INFO - Started process (PID=2492) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:22:34.724+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:22:34.724+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:22:34.724+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:22:35.567+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:22:35.566+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:22:35.567+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:22:35.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.857 seconds
[2023-07-07T00:23:05.831+0000] {processor.py:157} INFO - Started process (PID=2514) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:23:05.840+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:23:05.841+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:23:05.841+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:23:06.560+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:23:06.559+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:23:06.560+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:23:06.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.742 seconds
[2023-07-07T00:23:37.115+0000] {processor.py:157} INFO - Started process (PID=2536) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:23:37.123+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:23:37.123+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:23:37.123+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:23:37.924+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:23:37.924+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:23:37.924+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:23:37.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.827 seconds
[2023-07-07T00:24:08.201+0000] {processor.py:157} INFO - Started process (PID=2558) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:24:08.207+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:24:08.208+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:24:08.208+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:24:09.012+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:24:09.011+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 31, in <module>
    @dag(
NameError: name 'dag' is not defined
[2023-07-07T00:24:09.012+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:24:09.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.828 seconds
[2023-07-07T00:24:23.188+0000] {processor.py:157} INFO - Started process (PID=2573) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:24:23.188+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:24:23.188+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:24:23.188+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:24:24.121+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:24:24.118+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:24:24.121+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:24:24.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.951 seconds
[2023-07-07T00:24:54.407+0000] {processor.py:157} INFO - Started process (PID=2596) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:24:54.413+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:24:54.413+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:24:54.413+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:24:55.216+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:24:55.213+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:24:55.216+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:24:55.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.824 seconds
[2023-07-07T00:25:25.627+0000] {processor.py:157} INFO - Started process (PID=2619) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:25:25.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:25:25.633+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:25:25.633+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:25:26.502+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:25:26.500+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:25:26.502+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:25:26.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.891 seconds
[2023-07-07T00:25:56.773+0000] {processor.py:157} INFO - Started process (PID=2642) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:25:56.784+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:25:56.784+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:25:56.784+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:25:57.668+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:25:57.666+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:25:57.668+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:25:57.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.910 seconds
[2023-07-07T00:26:27.925+0000] {processor.py:157} INFO - Started process (PID=2665) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:26:27.931+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:26:27.931+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:26:27.931+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:26:28.837+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:26:28.834+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:26:28.837+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:26:28.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.929 seconds
[2023-07-07T00:26:59.054+0000] {processor.py:157} INFO - Started process (PID=2695) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:26:59.066+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:26:59.066+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:26:59.066+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:26:59.862+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:26:59.860+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:26:59.862+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:26:59.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.824 seconds
[2023-07-07T00:27:30.323+0000] {processor.py:157} INFO - Started process (PID=2718) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:27:30.328+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:27:30.329+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:27:30.329+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:27:31.212+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:27:31.210+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:27:31.212+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:27:31.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.908 seconds
[2023-07-07T00:28:01.503+0000] {processor.py:157} INFO - Started process (PID=2741) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:28:01.515+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:28:01.515+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:28:01.515+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:28:02.385+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:28:02.383+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:28:02.386+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:28:02.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.901 seconds
[2023-07-07T00:28:32.678+0000] {processor.py:157} INFO - Started process (PID=2764) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:28:32.685+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:28:32.685+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:28:32.685+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:28:33.545+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:28:33.543+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:28:33.546+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:28:33.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.885 seconds
[2023-07-07T00:29:03.835+0000] {processor.py:157} INFO - Started process (PID=2787) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:29:03.846+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:29:03.846+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:29:03.846+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:29:04.633+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:29:04.631+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:29:04.634+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:29:04.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.811 seconds
[2023-07-07T00:29:35.070+0000] {processor.py:157} INFO - Started process (PID=2810) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:29:35.077+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:29:35.078+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:29:35.078+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:29:35.961+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:29:35.958+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:29:35.961+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:29:35.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.906 seconds
[2023-07-07T00:30:06.237+0000] {processor.py:157} INFO - Started process (PID=2833) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:30:06.244+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:30:06.245+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:30:06.245+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:30:07.113+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:30:07.110+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:30:07.113+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:30:07.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.894 seconds
[2023-07-07T00:30:37.411+0000] {processor.py:157} INFO - Started process (PID=2856) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:30:37.416+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:30:37.416+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:30:37.416+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:30:38.336+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:30:38.334+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:30:38.336+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:30:38.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.944 seconds
[2023-07-07T00:31:08.633+0000] {processor.py:157} INFO - Started process (PID=2879) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:31:08.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:31:08.634+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:31:08.634+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:31:09.487+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:31:09.485+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:31:09.487+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:31:09.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.870 seconds
[2023-07-07T00:31:39.769+0000] {processor.py:157} INFO - Started process (PID=2902) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:31:39.774+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:31:39.775+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:31:39.775+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:31:40.671+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:31:40.669+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:31:40.672+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:31:40.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.922 seconds
[2023-07-07T00:32:10.959+0000] {processor.py:157} INFO - Started process (PID=2925) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:32:10.964+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:32:10.965+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:32:10.965+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:32:11.837+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:32:11.835+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:32:11.838+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:32:11.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.900 seconds
[2023-07-07T00:32:42.132+0000] {processor.py:157} INFO - Started process (PID=2948) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:32:42.137+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:32:42.137+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:32:42.137+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:32:43.004+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:32:43.002+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:32:43.004+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:32:43.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.892 seconds
[2023-07-07T00:33:13.298+0000] {processor.py:157} INFO - Started process (PID=2971) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:33:13.304+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:33:13.304+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:33:13.304+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:33:14.092+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:33:14.089+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:33:14.092+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:33:14.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.809 seconds
[2023-07-07T00:33:44.381+0000] {processor.py:157} INFO - Started process (PID=2994) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:33:44.382+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:33:44.382+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:33:44.382+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:33:45.251+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:33:45.249+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:33:45.252+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:33:45.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.884 seconds
[2023-07-07T00:34:15.539+0000] {processor.py:157} INFO - Started process (PID=3017) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:34:15.549+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:34:15.550+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:34:15.550+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:34:16.423+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:34:16.420+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:34:16.423+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:34:16.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.902 seconds
[2023-07-07T00:34:46.718+0000] {processor.py:157} INFO - Started process (PID=3040) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:34:46.725+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:34:46.725+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:34:46.725+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:34:47.589+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:34:47.587+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:34:47.590+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:34:47.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.886 seconds
[2023-07-07T00:35:17.874+0000] {processor.py:157} INFO - Started process (PID=3063) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:35:17.885+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:35:17.885+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:35:17.885+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:35:18.677+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:35:18.675+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:35:18.677+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:35:18.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.817 seconds
[2023-07-07T00:35:49.150+0000] {processor.py:157} INFO - Started process (PID=3086) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:35:49.155+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:35:49.156+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:35:49.156+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:35:50.020+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:35:50.018+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:35:50.020+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:35:50.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.884 seconds
[2023-07-07T00:36:20.319+0000] {processor.py:157} INFO - Started process (PID=3109) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:36:20.324+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:36:20.325+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:36:20.325+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:36:21.205+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:36:21.203+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:36:21.205+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:36:21.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.901 seconds
[2023-07-07T00:36:51.426+0000] {processor.py:157} INFO - Started process (PID=3133) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:36:51.433+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:36:51.434+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:36:51.434+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:36:52.303+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:36:52.301+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:36:52.304+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:36:52.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.897 seconds
[2023-07-07T00:37:22.542+0000] {processor.py:157} INFO - Started process (PID=3156) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:37:22.550+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:37:22.551+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:37:22.551+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:37:23.385+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:37:23.383+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:37:23.385+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:37:23.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.857 seconds
[2023-07-07T00:37:53.791+0000] {processor.py:157} INFO - Started process (PID=3179) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:37:53.801+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:37:53.802+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:37:53.802+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:37:54.671+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:37:54.669+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:37:54.671+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:37:54.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.899 seconds
[2023-07-07T00:38:24.903+0000] {processor.py:157} INFO - Started process (PID=3202) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:38:24.908+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:38:24.909+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:38:24.909+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:38:25.780+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:38:25.778+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:38:25.780+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:38:25.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.896 seconds
[2023-07-07T00:38:56.050+0000] {processor.py:157} INFO - Started process (PID=3226) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:38:56.051+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:38:56.051+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:38:56.051+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:38:56.913+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:38:56.911+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:38:56.913+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:38:56.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.881 seconds
[2023-07-07T00:39:27.177+0000] {processor.py:157} INFO - Started process (PID=3249) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:39:27.182+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:39:27.182+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:39:27.182+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:39:27.973+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:39:27.971+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:39:27.974+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:39:27.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.816 seconds
[2023-07-07T00:39:58.441+0000] {processor.py:157} INFO - Started process (PID=3272) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:39:58.448+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:39:58.448+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:39:58.448+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:39:59.317+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:39:59.315+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:39:59.318+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:39:59.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.890 seconds
[2023-07-07T00:40:29.586+0000] {processor.py:157} INFO - Started process (PID=3295) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:40:29.593+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:40:29.593+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:40:29.593+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:40:30.449+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:40:30.447+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:40:30.449+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:40:30.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.882 seconds
[2023-07-07T00:41:00.713+0000] {processor.py:157} INFO - Started process (PID=3318) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:41:00.718+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:41:00.719+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:41:00.719+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:41:01.575+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:41:01.572+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:41:01.575+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:41:01.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.881 seconds
[2023-07-07T00:41:31.849+0000] {processor.py:157} INFO - Started process (PID=3341) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:41:31.854+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:41:31.855+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:41:31.855+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:41:32.644+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:41:32.642+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:41:32.645+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:41:32.658+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.811 seconds
[2023-07-07T00:42:03.122+0000] {processor.py:157} INFO - Started process (PID=3371) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:42:03.129+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:42:03.130+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:42:03.129+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:42:03.992+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:42:03.989+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:42:03.992+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:42:04.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.890 seconds
[2023-07-07T00:42:34.258+0000] {processor.py:157} INFO - Started process (PID=3394) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:42:34.264+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:42:34.264+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:42:34.264+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:42:35.127+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:42:35.125+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:42:35.127+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:42:35.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.888 seconds
[2023-07-07T00:43:05.394+0000] {processor.py:157} INFO - Started process (PID=3417) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:43:05.400+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:43:05.400+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:43:05.400+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:43:06.262+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:43:06.260+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:43:06.263+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:43:06.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.889 seconds
[2023-07-07T00:43:36.537+0000] {processor.py:157} INFO - Started process (PID=3440) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:43:36.542+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:43:36.542+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:43:36.542+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:43:37.369+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:43:37.366+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:43:37.369+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:43:37.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.848 seconds
[2023-07-07T00:44:07.618+0000] {processor.py:157} INFO - Started process (PID=3463) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:44:07.628+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:44:07.628+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:44:07.628+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:44:08.505+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:44:08.503+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:44:08.506+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:44:08.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.905 seconds
[2023-07-07T00:44:38.771+0000] {processor.py:157} INFO - Started process (PID=3486) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:44:38.777+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:44:38.778+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:44:38.778+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:44:39.630+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:44:39.627+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:44:39.630+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:44:39.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.873 seconds
[2023-07-07T00:45:09.901+0000] {processor.py:157} INFO - Started process (PID=3509) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:45:09.906+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:45:09.907+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:45:09.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:45:10.769+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:45:10.767+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:45:10.770+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:45:10.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.887 seconds
[2023-07-07T00:45:41.065+0000] {processor.py:157} INFO - Started process (PID=3532) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:45:41.071+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:45:41.071+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:45:41.071+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:45:41.891+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:45:41.887+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:45:41.892+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:45:41.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.849 seconds
[2023-07-07T00:46:12.153+0000] {processor.py:157} INFO - Started process (PID=3555) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:46:12.163+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:46:12.164+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:46:12.164+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:46:13.071+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:46:13.069+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:46:13.072+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:46:13.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.944 seconds
[2023-07-07T00:46:43.340+0000] {processor.py:157} INFO - Started process (PID=3578) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:46:43.345+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:46:43.345+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:46:43.345+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:46:44.219+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:46:44.216+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:46:44.219+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:46:44.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.899 seconds
[2023-07-07T00:47:14.496+0000] {processor.py:157} INFO - Started process (PID=3602) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:47:14.501+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:47:14.502+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:47:14.501+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:47:15.366+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:47:15.364+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:47:15.366+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:47:15.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.890 seconds
[2023-07-07T00:47:45.641+0000] {processor.py:157} INFO - Started process (PID=3625) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:47:45.652+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:47:45.652+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:47:45.652+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:47:46.451+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:47:46.449+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:47:46.451+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:47:46.466+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.828 seconds
[2023-07-07T00:48:16.722+0000] {processor.py:157} INFO - Started process (PID=3648) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:48:16.732+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:48:16.733+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:48:16.733+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:48:17.613+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:48:17.611+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:48:17.614+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:48:17.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.905 seconds
[2023-07-07T00:48:47.882+0000] {processor.py:157} INFO - Started process (PID=3671) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:48:47.887+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:48:47.888+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:48:47.888+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:48:48.780+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:48:48.778+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:48:48.780+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:48:48.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.918 seconds
[2023-07-07T00:49:19.074+0000] {processor.py:157} INFO - Started process (PID=3694) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:49:19.080+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:49:19.080+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:49:19.080+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:49:20.096+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:49:20.094+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:49:20.097+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:49:20.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.049 seconds
[2023-07-07T00:49:50.342+0000] {processor.py:157} INFO - Started process (PID=3717) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:49:50.486+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:49:50.486+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:49:50.486+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:49:51.355+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:49:51.353+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:49:51.356+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:49:51.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.033 seconds
[2023-07-07T00:50:21.594+0000] {processor.py:157} INFO - Started process (PID=3740) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:50:21.603+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:50:21.604+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:50:21.603+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:50:22.468+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:50:22.465+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:50:22.468+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:50:22.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.886 seconds
[2023-07-07T00:50:52.763+0000] {processor.py:157} INFO - Started process (PID=3763) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:50:52.775+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:50:52.776+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:50:52.776+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:50:53.625+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:50:53.622+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:50:53.625+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:50:53.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.877 seconds
[2023-07-07T00:51:23.909+0000] {processor.py:157} INFO - Started process (PID=3786) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:51:23.916+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:51:23.917+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:51:23.917+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:51:24.774+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:51:24.772+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:51:24.774+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:51:24.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.878 seconds
[2023-07-07T00:51:55.079+0000] {processor.py:157} INFO - Started process (PID=3809) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:51:55.085+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:51:55.086+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:51:55.086+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:51:55.947+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:51:55.945+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:51:55.947+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:51:55.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.887 seconds
[2023-07-07T00:52:26.193+0000] {processor.py:157} INFO - Started process (PID=3833) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:52:26.198+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:52:26.199+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:52:26.199+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:52:27.054+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:52:27.052+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:52:27.055+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:52:27.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.883 seconds
[2023-07-07T00:52:57.328+0000] {processor.py:157} INFO - Started process (PID=3856) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:52:57.333+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:52:57.333+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:52:57.333+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:52:58.184+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:52:58.181+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:52:58.184+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:52:58.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.881 seconds
[2023-07-07T00:53:28.434+0000] {processor.py:157} INFO - Started process (PID=3879) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:53:28.443+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:53:28.443+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:53:28.443+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:53:29.301+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:53:29.299+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:53:29.301+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:53:29.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.889 seconds
[2023-07-07T00:53:59.541+0000] {processor.py:157} INFO - Started process (PID=3902) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:53:59.549+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:53:59.549+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:53:59.549+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:54:00.417+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:54:00.415+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:54:00.417+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:54:00.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.896 seconds
[2023-07-07T00:54:30.697+0000] {processor.py:157} INFO - Started process (PID=3926) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:54:30.709+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:54:30.709+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:54:30.709+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:54:31.579+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:54:31.577+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:54:31.579+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:54:31.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.901 seconds
[2023-07-07T00:55:01.857+0000] {processor.py:157} INFO - Started process (PID=3949) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:55:01.862+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:55:01.863+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:55:01.863+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:55:02.756+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:55:02.754+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:55:02.757+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:55:02.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.920 seconds
[2023-07-07T00:55:33.054+0000] {processor.py:157} INFO - Started process (PID=3972) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:55:33.059+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:55:33.059+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:55:33.059+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:55:33.947+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:55:33.945+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:55:33.948+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:55:33.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.908 seconds
[2023-07-07T00:56:04.240+0000] {processor.py:157} INFO - Started process (PID=3995) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:56:04.245+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:56:04.246+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:56:04.246+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:56:05.122+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:56:05.120+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:56:05.123+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:56:05.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.902 seconds
[2023-07-07T00:56:35.399+0000] {processor.py:157} INFO - Started process (PID=4025) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:56:35.410+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:56:35.410+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:56:35.410+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:56:36.292+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:56:36.290+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:56:36.292+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:56:36.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.913 seconds
[2023-07-07T00:57:06.588+0000] {processor.py:157} INFO - Started process (PID=4048) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:57:06.593+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:57:06.594+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:57:06.594+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:57:07.467+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:57:07.465+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:57:07.467+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:57:07.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.906 seconds
[2023-07-07T00:57:37.764+0000] {processor.py:157} INFO - Started process (PID=4071) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:57:37.772+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:57:37.772+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:57:37.772+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:57:38.640+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:57:38.638+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:57:38.640+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:57:38.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.891 seconds
[2023-07-07T00:58:08.945+0000] {processor.py:157} INFO - Started process (PID=4094) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:58:08.952+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:58:08.953+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:58:08.952+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:58:09.826+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:58:09.823+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:58:09.826+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:58:09.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.901 seconds
[2023-07-07T00:58:40.127+0000] {processor.py:157} INFO - Started process (PID=4117) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:58:40.132+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:58:40.133+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:58:40.133+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:58:41.026+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:58:41.024+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:58:41.027+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:58:41.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.922 seconds
[2023-07-07T00:59:11.332+0000] {processor.py:157} INFO - Started process (PID=4140) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:59:11.344+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:59:11.345+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:59:11.345+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:59:12.250+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:59:12.247+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:59:12.250+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:59:12.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.932 seconds
[2023-07-07T00:59:42.566+0000] {processor.py:157} INFO - Started process (PID=4163) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:59:42.573+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T00:59:42.573+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:59:42.573+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:59:43.454+0000] {logging_mixin.py:149} INFO - [2023-07-07T00:59:43.452+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T00:59:43.454+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T00:59:43.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.908 seconds
[2023-07-07T01:00:13.756+0000] {processor.py:157} INFO - Started process (PID=4186) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:00:13.761+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:00:13.762+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:00:13.762+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:00:14.632+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:00:14.630+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:00:14.632+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:00:14.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.896 seconds
[2023-07-07T01:00:44.929+0000] {processor.py:157} INFO - Started process (PID=4209) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:00:44.934+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:00:44.935+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:00:44.935+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:00:45.798+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:00:45.796+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:00:45.799+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:00:45.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.888 seconds
[2023-07-07T01:01:16.135+0000] {processor.py:157} INFO - Started process (PID=4232) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:01:16.140+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:01:16.141+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:01:16.141+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:01:17.017+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:01:17.015+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:01:17.018+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:01:17.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.903 seconds
[2023-07-07T01:01:47.331+0000] {processor.py:157} INFO - Started process (PID=4255) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:01:47.342+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:01:47.342+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:01:47.342+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:01:48.212+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:01:48.210+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:01:48.213+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:01:48.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.901 seconds
[2023-07-07T01:02:18.513+0000] {processor.py:157} INFO - Started process (PID=4278) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:02:18.518+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:02:18.518+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:02:18.518+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:02:19.386+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:02:19.384+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:02:19.386+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:02:19.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.889 seconds
[2023-07-07T01:02:49.679+0000] {processor.py:157} INFO - Started process (PID=4301) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:02:49.690+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:02:49.691+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:02:49.691+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:02:50.554+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:02:50.552+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:02:50.555+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:02:50.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.889 seconds
[2023-07-07T01:03:20.846+0000] {processor.py:157} INFO - Started process (PID=4324) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:03:20.853+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:03:20.853+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:03:20.853+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:03:21.727+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:03:21.723+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:03:21.727+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:03:21.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.895 seconds
[2023-07-07T01:03:52.019+0000] {processor.py:157} INFO - Started process (PID=4347) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:03:52.026+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:03:52.026+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:03:52.026+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:03:52.936+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:03:52.934+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:03:52.936+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:03:52.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.937 seconds
[2023-07-07T01:04:23.252+0000] {processor.py:157} INFO - Started process (PID=4370) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:04:23.258+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:04:23.258+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:04:23.258+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:04:24.112+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:04:24.110+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:04:24.113+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:04:24.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.879 seconds
[2023-07-07T01:04:54.420+0000] {processor.py:157} INFO - Started process (PID=4393) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:04:54.425+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:04:54.425+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:04:54.425+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:04:55.282+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:04:55.279+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:04:55.282+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:04:55.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.875 seconds
[2023-07-07T01:05:25.600+0000] {processor.py:157} INFO - Started process (PID=4416) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:05:25.607+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:05:25.608+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:05:25.608+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:05:26.476+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:05:26.474+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:05:26.476+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:05:26.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.895 seconds
[2023-07-07T01:05:56.779+0000] {processor.py:157} INFO - Started process (PID=4439) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:05:56.785+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:05:56.785+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:05:56.785+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:05:57.655+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:05:57.651+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:05:57.656+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:05:57.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.895 seconds
[2023-07-07T01:06:27.971+0000] {processor.py:157} INFO - Started process (PID=4462) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:06:27.980+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:06:27.980+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:06:27.980+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:06:28.835+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:06:28.832+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:06:28.835+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:06:28.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.884 seconds
[2023-07-07T01:06:59.143+0000] {processor.py:157} INFO - Started process (PID=4485) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:06:59.149+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:06:59.149+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:06:59.149+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:07:00.005+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:07:00.003+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:07:00.005+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:07:00.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.889 seconds
[2023-07-07T01:07:30.331+0000] {processor.py:157} INFO - Started process (PID=4508) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:07:30.337+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:07:30.337+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:07:30.337+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:07:31.195+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:07:31.192+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:07:31.196+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:07:31.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.883 seconds
[2023-07-07T01:08:01.415+0000] {processor.py:157} INFO - Started process (PID=4531) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:08:01.427+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:08:01.427+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:08:01.427+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:08:02.334+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:08:02.331+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:08:02.334+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:08:02.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.934 seconds
[2023-07-07T01:08:32.579+0000] {processor.py:157} INFO - Started process (PID=4555) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:08:32.586+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:08:32.586+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:08:32.586+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:08:33.442+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:08:33.440+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:08:33.443+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:08:33.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.883 seconds
[2023-07-07T01:09:03.699+0000] {processor.py:157} INFO - Started process (PID=4578) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:09:03.705+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:09:03.705+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:09:03.705+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:09:04.557+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:09:04.555+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:09:04.557+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:09:04.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.873 seconds
[2023-07-07T01:09:34.808+0000] {processor.py:157} INFO - Started process (PID=4601) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:09:34.814+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:09:34.814+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:09:34.814+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:09:35.676+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:09:35.674+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:09:35.676+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:09:35.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.888 seconds
[2023-07-07T01:10:06.073+0000] {processor.py:157} INFO - Started process (PID=4625) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:10:06.078+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:10:06.079+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:10:06.078+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:10:06.935+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:10:06.933+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:10:06.936+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:10:06.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.881 seconds
[2023-07-07T01:10:37.235+0000] {processor.py:157} INFO - Started process (PID=4648) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:10:37.241+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:10:37.241+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:10:37.241+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:10:38.101+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:10:38.099+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:10:38.101+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:10:38.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.885 seconds
[2023-07-07T01:11:08.390+0000] {processor.py:157} INFO - Started process (PID=4671) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:11:08.397+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:11:08.398+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:11:08.397+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:11:09.268+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:11:09.265+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:11:09.268+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:11:09.286+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.898 seconds
[2023-07-07T01:11:39.571+0000] {processor.py:157} INFO - Started process (PID=4701) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:11:39.578+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:11:39.578+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:11:39.578+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:11:40.436+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:11:40.434+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:11:40.437+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:11:40.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.879 seconds
[2023-07-07T01:12:10.723+0000] {processor.py:157} INFO - Started process (PID=4725) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:12:10.730+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:12:10.730+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:12:10.730+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:12:11.584+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:12:11.582+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:12:11.585+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:12:11.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.886 seconds
[2023-07-07T01:12:41.875+0000] {processor.py:157} INFO - Started process (PID=4748) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:12:41.887+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:12:41.887+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:12:41.887+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:12:42.739+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:12:42.737+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:12:42.739+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:12:42.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.880 seconds
[2023-07-07T01:13:13.031+0000] {processor.py:157} INFO - Started process (PID=4771) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:13:13.039+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:13:13.040+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:13:13.040+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:13:13.892+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:13:13.890+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:13:13.893+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:13:13.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.877 seconds
[2023-07-07T01:13:44.163+0000] {processor.py:157} INFO - Started process (PID=4794) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:13:44.168+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:13:44.168+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:13:44.168+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:13:45.021+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:13:45.019+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:13:45.022+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:13:45.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.879 seconds
[2023-07-07T01:14:15.309+0000] {processor.py:157} INFO - Started process (PID=4817) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:14:15.314+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:14:15.315+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:14:15.315+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:14:16.178+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:14:16.176+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:14:16.179+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:14:16.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.888 seconds
[2023-07-07T01:14:46.519+0000] {processor.py:157} INFO - Started process (PID=4840) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:14:46.525+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:14:46.525+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:14:46.525+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:14:47.378+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:14:47.376+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:14:47.378+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:14:47.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.873 seconds
[2023-07-07T01:15:17.679+0000] {processor.py:157} INFO - Started process (PID=4863) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:15:17.688+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:15:17.689+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:15:17.689+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:15:18.533+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:15:18.531+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:15:18.534+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:15:18.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.874 seconds
[2023-07-07T01:15:48.844+0000] {processor.py:157} INFO - Started process (PID=4886) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:15:48.849+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:15:48.849+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:15:48.849+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:15:49.706+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:15:49.704+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:15:49.707+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:15:49.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.882 seconds
[2023-07-07T01:16:20.015+0000] {processor.py:157} INFO - Started process (PID=4909) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:16:20.021+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:16:20.021+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:16:20.021+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:16:20.879+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:16:20.877+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:16:20.879+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:16:20.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.884 seconds
[2023-07-07T01:16:51.179+0000] {processor.py:157} INFO - Started process (PID=4932) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:16:51.184+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:16:51.185+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:16:51.185+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:16:52.040+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:16:52.037+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:16:52.040+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:16:52.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.884 seconds
[2023-07-07T01:17:22.345+0000] {processor.py:157} INFO - Started process (PID=4955) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:17:22.351+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:17:22.351+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:17:22.351+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:17:23.203+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:17:23.201+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:17:23.203+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:17:23.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.876 seconds
[2023-07-07T01:17:53.488+0000] {processor.py:157} INFO - Started process (PID=4978) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:17:53.494+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:17:53.495+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:17:53.495+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:17:54.341+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:17:54.339+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:17:54.341+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:17:54.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.877 seconds
[2023-07-07T01:18:24.649+0000] {processor.py:157} INFO - Started process (PID=5001) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:18:24.655+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:18:24.656+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:18:24.656+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:18:25.511+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:18:25.508+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:18:25.511+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:18:25.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.880 seconds
[2023-07-07T01:18:55.820+0000] {processor.py:157} INFO - Started process (PID=5024) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:18:55.825+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:18:55.826+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:18:55.826+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:18:56.695+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:18:56.693+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:18:56.695+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:18:56.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.896 seconds
[2023-07-07T01:19:26.980+0000] {processor.py:157} INFO - Started process (PID=5047) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:19:26.986+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:19:26.987+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:19:26.987+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:19:27.845+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:19:27.842+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:19:27.845+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:19:27.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.886 seconds
[2023-07-07T01:19:58.144+0000] {processor.py:157} INFO - Started process (PID=5070) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:19:58.145+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:19:58.145+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:19:58.145+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:19:59.109+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:19:59.106+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:19:59.109+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:19:59.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.979 seconds
[2023-07-07T01:20:29.316+0000] {processor.py:157} INFO - Started process (PID=5093) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:20:29.325+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:20:29.326+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:20:29.326+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:20:30.291+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:20:30.289+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:20:30.292+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:20:30.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.003 seconds
[2023-07-07T01:21:00.582+0000] {processor.py:157} INFO - Started process (PID=5116) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:21:00.589+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:21:00.590+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:21:00.590+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:21:01.518+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:21:01.516+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:21:01.519+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:21:01.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.950 seconds
[2023-07-07T01:21:31.788+0000] {processor.py:157} INFO - Started process (PID=5139) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:21:31.789+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:21:31.790+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:21:31.790+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:21:32.722+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:21:32.719+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:21:32.722+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:21:32.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.953 seconds
[2023-07-07T01:22:03.010+0000] {processor.py:157} INFO - Started process (PID=5162) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:22:03.020+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:22:03.021+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:22:03.021+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:22:03.919+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:22:03.917+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:22:03.920+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:22:03.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.929 seconds
[2023-07-07T01:22:34.200+0000] {processor.py:157} INFO - Started process (PID=5185) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:22:34.208+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:22:34.208+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:22:34.208+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:22:35.098+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:22:35.096+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:22:35.098+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:22:35.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.913 seconds
[2023-07-07T01:23:05.394+0000] {processor.py:157} INFO - Started process (PID=5208) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:23:05.401+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:23:05.401+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:23:05.401+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:23:06.329+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:23:06.327+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:23:06.329+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:23:06.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.950 seconds
[2023-07-07T01:23:36.590+0000] {processor.py:157} INFO - Started process (PID=5231) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:23:36.602+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:23:36.602+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:23:36.602+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:23:37.513+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:23:37.510+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:23:37.513+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:23:37.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.945 seconds
[2023-07-07T01:24:07.726+0000] {processor.py:157} INFO - Started process (PID=5255) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:24:07.731+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:24:07.732+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:24:07.732+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:24:08.635+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:24:08.632+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:24:08.636+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:24:08.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.928 seconds
[2023-07-07T01:24:38.843+0000] {processor.py:157} INFO - Started process (PID=5278) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:24:38.848+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:24:38.849+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:24:38.849+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:24:39.760+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:24:39.758+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:24:39.761+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:24:39.778+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.937 seconds
[2023-07-07T01:25:09.973+0000] {processor.py:157} INFO - Started process (PID=5301) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:25:09.979+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:25:09.980+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:25:09.979+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:25:10.879+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:25:10.877+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:25:10.880+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:25:10.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.925 seconds
[2023-07-07T01:25:41.148+0000] {processor.py:157} INFO - Started process (PID=5325) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:25:41.155+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:25:41.156+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:25:41.156+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:25:42.038+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:25:42.036+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:25:42.038+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:25:42.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.904 seconds
[2023-07-07T01:26:12.306+0000] {processor.py:157} INFO - Started process (PID=5355) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:26:12.317+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:26:12.318+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:26:12.318+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:26:13.243+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:26:13.240+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:26:13.243+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:26:13.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.951 seconds
[2023-07-07T01:26:43.497+0000] {processor.py:157} INFO - Started process (PID=5378) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:26:43.509+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:26:43.509+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:26:43.509+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:26:44.471+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:26:44.469+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:26:44.472+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:26:44.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.995 seconds
[2023-07-07T01:27:14.750+0000] {processor.py:157} INFO - Started process (PID=5401) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:27:14.755+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:27:14.756+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:27:14.756+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:27:15.709+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:27:15.707+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:27:15.710+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:27:15.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.978 seconds
[2023-07-07T01:27:46.006+0000] {processor.py:157} INFO - Started process (PID=5424) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:27:46.011+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:27:46.011+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:27:46.011+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:27:46.945+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:27:46.943+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:27:46.946+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:27:46.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.959 seconds
[2023-07-07T01:28:17.235+0000] {processor.py:157} INFO - Started process (PID=5447) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:28:17.241+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:28:17.241+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:28:17.241+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:28:18.148+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:28:18.146+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:28:18.148+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:28:18.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.930 seconds
[2023-07-07T01:28:48.450+0000] {processor.py:157} INFO - Started process (PID=5471) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:28:48.460+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:28:48.460+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:28:48.460+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:28:49.349+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:28:49.347+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:28:49.349+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:28:49.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.915 seconds
[2023-07-07T01:29:19.661+0000] {processor.py:157} INFO - Started process (PID=5494) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:29:19.673+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:29:19.674+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:29:19.674+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:29:20.581+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:29:20.578+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:29:20.581+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:29:20.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.942 seconds
[2023-07-07T01:29:50.877+0000] {processor.py:157} INFO - Started process (PID=5517) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:29:50.884+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:29:50.885+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:29:50.885+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:29:51.782+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:29:51.779+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:29:51.782+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:29:51.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.922 seconds
[2023-07-07T01:30:22.067+0000] {processor.py:157} INFO - Started process (PID=5540) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:30:22.074+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:30:22.074+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:30:22.074+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:30:22.992+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:30:22.990+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:30:22.992+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:30:23.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.943 seconds
[2023-07-07T01:30:53.302+0000] {processor.py:157} INFO - Started process (PID=5563) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:30:53.313+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:30:53.313+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:30:53.313+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:30:54.307+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:30:54.304+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:30:54.307+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:30:54.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.025 seconds
[2023-07-07T01:31:24.569+0000] {processor.py:157} INFO - Started process (PID=5586) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:31:24.575+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:31:24.575+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:31:24.575+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:31:25.513+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:31:25.511+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:31:25.514+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:31:25.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.959 seconds
[2023-07-07T01:31:55.773+0000] {processor.py:157} INFO - Started process (PID=5609) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:31:55.778+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:31:55.778+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:31:55.778+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:31:56.675+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:31:56.673+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:31:56.676+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:31:56.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.916 seconds
[2023-07-07T01:32:26.949+0000] {processor.py:157} INFO - Started process (PID=5633) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:32:26.955+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:32:26.956+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:32:26.956+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:32:27.886+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:32:27.884+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:32:27.886+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:32:27.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.957 seconds
[2023-07-07T01:32:58.158+0000] {processor.py:157} INFO - Started process (PID=5656) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:32:58.167+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:32:58.167+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:32:58.167+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:32:59.069+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:32:59.067+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:32:59.070+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:32:59.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.930 seconds
[2023-07-07T01:33:29.352+0000] {processor.py:157} INFO - Started process (PID=5679) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:33:29.358+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:33:29.358+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:33:29.358+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:33:30.284+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:33:30.282+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:33:30.284+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:33:30.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.951 seconds
[2023-07-07T01:34:00.567+0000] {processor.py:157} INFO - Started process (PID=5702) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:34:00.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:34:00.572+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:34:00.572+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:34:01.432+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:34:01.429+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:34:01.432+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:34:01.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.884 seconds
[2023-07-07T01:34:31.722+0000] {processor.py:157} INFO - Started process (PID=5725) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:34:31.722+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:34:31.723+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:34:31.723+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:34:32.641+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:34:32.638+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:34:32.641+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:34:32.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.937 seconds
[2023-07-07T01:35:02.910+0000] {processor.py:157} INFO - Started process (PID=5748) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:35:02.921+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:35:02.922+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:35:02.921+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:35:03.842+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:35:03.840+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:35:03.842+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:35:03.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.947 seconds
[2023-07-07T01:35:34.145+0000] {processor.py:157} INFO - Started process (PID=5771) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:35:34.151+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:35:34.152+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:35:34.152+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:35:35.047+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:35:35.044+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:35:35.048+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:35:35.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.918 seconds
[2023-07-07T01:36:05.327+0000] {processor.py:157} INFO - Started process (PID=5794) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:36:05.336+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:36:05.337+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:36:05.337+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:36:06.233+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:36:06.231+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:36:06.233+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:36:06.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.920 seconds
[2023-07-07T01:36:36.500+0000] {processor.py:157} INFO - Started process (PID=5817) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:36:36.506+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:36:36.506+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:36:36.506+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:36:37.419+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:36:37.415+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:36:37.420+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:36:37.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.935 seconds
[2023-07-07T01:37:07.693+0000] {processor.py:157} INFO - Started process (PID=5840) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:37:07.703+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:37:07.703+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:37:07.703+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:37:08.592+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:37:08.589+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:37:08.593+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:37:08.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.915 seconds
[2023-07-07T01:37:38.877+0000] {processor.py:157} INFO - Started process (PID=5863) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:37:38.888+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:37:38.888+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:37:38.888+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:37:39.800+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:37:39.797+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:37:39.800+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:37:39.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.940 seconds
[2023-07-07T01:38:10.067+0000] {processor.py:157} INFO - Started process (PID=5886) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:38:10.079+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:38:10.079+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:38:10.079+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:38:10.965+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:38:10.961+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:38:10.965+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:38:10.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.912 seconds
[2023-07-07T01:38:41.235+0000] {processor.py:157} INFO - Started process (PID=5909) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:38:41.241+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:38:41.241+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:38:41.241+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:38:42.129+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:38:42.127+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:38:42.130+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:38:42.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.914 seconds
[2023-07-07T01:39:12.409+0000] {processor.py:157} INFO - Started process (PID=5932) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:39:12.414+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:39:12.414+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:39:12.414+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:39:13.298+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:39:13.296+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:39:13.299+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:39:13.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.911 seconds
[2023-07-07T01:39:43.509+0000] {processor.py:157} INFO - Started process (PID=5956) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:39:43.514+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:39:43.515+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:39:43.515+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:39:44.400+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:39:44.396+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:39:44.400+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:39:44.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.910 seconds
[2023-07-07T01:40:14.628+0000] {processor.py:157} INFO - Started process (PID=5979) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:40:14.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:40:14.634+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:40:14.633+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:40:15.535+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:40:15.533+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:40:15.535+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:40:15.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.928 seconds
[2023-07-07T01:40:45.758+0000] {processor.py:157} INFO - Started process (PID=6009) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:40:45.764+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:40:45.764+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:40:45.764+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:40:46.655+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:40:46.653+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:40:46.656+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:40:46.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.917 seconds
[2023-07-07T01:41:16.850+0000] {processor.py:157} INFO - Started process (PID=6033) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:41:16.856+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:41:16.856+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:41:16.856+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:41:17.739+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:41:17.737+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:41:17.739+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:41:17.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.908 seconds
[2023-07-07T01:41:48.052+0000] {processor.py:157} INFO - Started process (PID=6056) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:41:48.053+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:41:48.054+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:41:48.053+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:41:48.948+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:41:48.945+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:41:48.948+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:41:48.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.912 seconds
[2023-07-07T01:42:19.319+0000] {processor.py:157} INFO - Started process (PID=6079) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:42:19.328+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:42:19.329+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:42:19.329+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:42:20.202+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:42:20.199+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:42:20.202+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:42:20.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.897 seconds
[2023-07-07T01:42:50.474+0000] {processor.py:157} INFO - Started process (PID=6102) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:42:50.484+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:42:50.485+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:42:50.484+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:42:51.397+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:42:51.395+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:42:51.397+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:42:51.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.940 seconds
[2023-07-07T01:43:21.665+0000] {processor.py:157} INFO - Started process (PID=6125) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:43:21.677+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:43:21.677+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:43:21.677+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:43:22.612+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:43:22.610+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:43:22.613+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:43:22.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.962 seconds
[2023-07-07T01:43:52.903+0000] {processor.py:157} INFO - Started process (PID=6148) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:43:52.910+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:43:52.910+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:43:52.910+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:43:53.861+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:43:53.859+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:43:53.862+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:43:53.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.974 seconds
[2023-07-07T01:44:24.168+0000] {processor.py:157} INFO - Started process (PID=6171) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:44:24.174+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:44:24.175+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:44:24.175+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:44:25.089+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:44:25.087+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:44:25.090+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:44:25.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.937 seconds
[2023-07-07T01:44:55.406+0000] {processor.py:157} INFO - Started process (PID=6194) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:44:55.412+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:44:55.413+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:44:55.412+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:44:56.341+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:44:56.339+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:44:56.342+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:44:56.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.952 seconds
[2023-07-07T01:45:26.621+0000] {processor.py:157} INFO - Started process (PID=6217) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:45:26.631+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:45:26.631+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:45:26.631+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:45:27.553+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:45:27.550+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:45:27.553+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:45:27.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.947 seconds
[2023-07-07T01:45:57.845+0000] {processor.py:157} INFO - Started process (PID=6240) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:45:57.850+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:45:57.851+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:45:57.851+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:45:58.784+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:45:58.782+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:45:58.785+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:45:58.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.957 seconds
[2023-07-07T01:46:29.073+0000] {processor.py:157} INFO - Started process (PID=6263) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:46:29.080+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:46:29.080+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:46:29.080+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:46:30.007+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:46:30.004+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:46:30.007+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:46:30.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.953 seconds
[2023-07-07T01:47:00.310+0000] {processor.py:157} INFO - Started process (PID=6286) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:47:00.315+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:47:00.316+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:47:00.316+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:47:01.232+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:47:01.230+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:47:01.233+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:47:01.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.941 seconds
[2023-07-07T01:47:31.505+0000] {processor.py:157} INFO - Started process (PID=6309) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:47:31.512+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:47:31.513+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:47:31.513+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:47:32.439+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:47:32.437+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:47:32.440+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:47:32.459+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.956 seconds
[2023-07-07T01:48:02.721+0000] {processor.py:157} INFO - Started process (PID=6332) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:48:02.726+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:48:02.727+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:48:02.727+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:48:03.641+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:48:03.638+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:48:03.641+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:48:03.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.934 seconds
[2023-07-07T01:48:33.913+0000] {processor.py:157} INFO - Started process (PID=6355) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:48:33.918+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:48:33.918+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:48:33.918+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:48:34.853+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:48:34.851+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:48:34.854+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:48:34.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.960 seconds
[2023-07-07T01:49:05.137+0000] {processor.py:157} INFO - Started process (PID=6378) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:49:05.142+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:49:05.143+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:49:05.143+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:49:06.057+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:49:06.054+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:49:06.057+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:49:06.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.940 seconds
[2023-07-07T01:49:36.355+0000] {processor.py:157} INFO - Started process (PID=6401) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:49:36.360+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:49:36.361+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:49:36.361+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:49:37.289+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:49:37.286+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:49:37.289+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:49:37.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.953 seconds
[2023-07-07T01:50:07.606+0000] {processor.py:157} INFO - Started process (PID=6424) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:50:07.612+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:50:07.613+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:50:07.613+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:50:08.620+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:50:08.617+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:50:08.621+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:50:08.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.029 seconds
[2023-07-07T01:50:38.900+0000] {processor.py:157} INFO - Started process (PID=6447) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:50:38.906+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:50:38.907+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:50:38.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:50:39.797+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:50:39.795+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:50:39.797+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:50:39.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.915 seconds
[2023-07-07T01:51:10.075+0000] {processor.py:157} INFO - Started process (PID=6470) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:51:10.087+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:51:10.088+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:51:10.088+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:51:11.012+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:51:11.010+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:51:11.013+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:51:11.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.954 seconds
[2023-07-07T01:51:41.295+0000] {processor.py:157} INFO - Started process (PID=6493) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:51:41.304+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:51:41.305+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:51:41.305+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:51:42.258+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:51:42.256+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:51:42.259+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:51:42.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.984 seconds
[2023-07-07T01:52:12.586+0000] {processor.py:157} INFO - Started process (PID=6516) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:52:12.595+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:52:12.596+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:52:12.596+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:52:13.623+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:52:13.621+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:52:13.624+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:52:13.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.061 seconds
[2023-07-07T01:52:43.896+0000] {processor.py:157} INFO - Started process (PID=6539) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:52:43.907+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:52:43.908+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:52:43.908+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:52:44.944+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:52:44.942+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:52:44.945+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:52:44.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.065 seconds
[2023-07-07T01:53:15.142+0000] {processor.py:157} INFO - Started process (PID=6562) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:53:15.142+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:53:15.143+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:53:15.143+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:53:16.092+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:53:16.090+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:53:16.093+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:53:16.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.971 seconds
[2023-07-07T01:53:46.388+0000] {processor.py:157} INFO - Started process (PID=6585) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:53:46.395+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:53:46.395+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:53:46.395+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:53:47.338+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:53:47.336+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:53:47.339+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:53:47.352+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.966 seconds
[2023-07-07T01:54:17.671+0000] {processor.py:157} INFO - Started process (PID=6608) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:54:17.681+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:54:17.682+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:54:17.682+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:54:18.647+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:54:18.644+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:54:18.647+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:54:18.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.990 seconds
[2023-07-07T01:54:48.952+0000] {processor.py:157} INFO - Started process (PID=6638) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:54:48.965+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:54:48.966+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:54:48.966+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:54:49.931+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:54:49.928+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:54:49.931+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:54:49.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.993 seconds
[2023-07-07T01:55:20.258+0000] {processor.py:157} INFO - Started process (PID=6662) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:55:20.263+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:55:20.264+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:55:20.264+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:55:21.189+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:55:21.187+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:55:21.189+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:55:21.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.946 seconds
[2023-07-07T01:55:51.445+0000] {processor.py:157} INFO - Started process (PID=6685) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:55:51.454+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:55:51.455+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:55:51.455+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:55:52.395+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:55:52.393+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:55:52.396+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:55:52.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.970 seconds
[2023-07-07T01:56:22.733+0000] {processor.py:157} INFO - Started process (PID=6708) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:56:22.739+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:56:22.739+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:56:22.739+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:56:23.661+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:56:23.659+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:56:23.662+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:56:23.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.942 seconds
[2023-07-07T01:56:53.868+0000] {processor.py:157} INFO - Started process (PID=6732) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:56:53.873+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:56:53.873+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:56:53.873+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:56:54.753+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:56:54.751+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:56:54.754+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:56:54.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.905 seconds
[2023-07-07T01:57:25.141+0000] {processor.py:157} INFO - Started process (PID=6755) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:57:25.148+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:57:25.148+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:57:25.148+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:57:26.050+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:57:26.048+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:57:26.050+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:57:26.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.923 seconds
[2023-07-07T01:57:56.339+0000] {processor.py:157} INFO - Started process (PID=6778) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:57:56.351+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:57:56.351+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:57:56.351+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:57:57.302+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:57:57.299+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:57:57.302+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:57:57.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.981 seconds
[2023-07-07T01:58:27.629+0000] {processor.py:157} INFO - Started process (PID=6801) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:58:27.639+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:58:27.639+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:58:27.639+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:58:28.567+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:58:28.565+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:58:28.568+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:58:28.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.952 seconds
[2023-07-07T01:58:58.861+0000] {processor.py:157} INFO - Started process (PID=6824) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:58:58.866+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:58:58.867+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:58:58.867+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:58:59.800+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:58:59.797+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:58:59.800+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:58:59.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.955 seconds
[2023-07-07T01:59:30.095+0000] {processor.py:157} INFO - Started process (PID=6847) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:59:30.102+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T01:59:30.103+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:59:30.103+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:59:30.996+0000] {logging_mixin.py:149} INFO - [2023-07-07T01:59:30.994+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T01:59:30.997+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T01:59:31.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.917 seconds
[2023-07-07T02:00:01.291+0000] {processor.py:157} INFO - Started process (PID=6870) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:00:01.292+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:00:01.292+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:00:01.292+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:00:02.199+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:00:02.197+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:00:02.200+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:00:02.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.927 seconds
[2023-07-07T02:00:32.493+0000] {processor.py:157} INFO - Started process (PID=6893) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:00:32.498+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:00:32.498+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:00:32.498+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:00:33.366+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:00:33.364+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:00:33.367+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:00:33.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.893 seconds
[2023-07-07T02:01:03.662+0000] {processor.py:157} INFO - Started process (PID=6916) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:01:03.668+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:01:03.668+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:01:03.668+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:01:04.537+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:01:04.535+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:01:04.538+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:01:04.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.894 seconds
[2023-07-07T02:01:34.838+0000] {processor.py:157} INFO - Started process (PID=6939) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:01:34.845+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:01:34.845+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:01:34.845+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:01:35.717+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:01:35.715+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:01:35.717+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:01:35.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.898 seconds
[2023-07-07T02:02:06.010+0000] {processor.py:157} INFO - Started process (PID=6962) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:02:06.022+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:02:06.022+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:02:06.022+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:02:06.885+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:02:06.883+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:02:06.886+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:02:06.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.902 seconds
[2023-07-07T02:02:37.194+0000] {processor.py:157} INFO - Started process (PID=6985) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:02:37.200+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:02:37.200+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:02:37.200+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:02:38.058+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:02:38.056+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:02:38.058+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:02:38.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.883 seconds
[2023-07-07T02:03:08.359+0000] {processor.py:157} INFO - Started process (PID=7008) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:03:08.367+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:03:08.368+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:03:08.367+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:03:09.220+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:03:09.218+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:03:09.220+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:03:09.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.881 seconds
[2023-07-07T02:03:39.514+0000] {processor.py:157} INFO - Started process (PID=7031) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:03:39.523+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:03:39.524+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:03:39.524+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:03:40.412+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:03:40.410+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:03:40.413+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:03:40.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.912 seconds
[2023-07-07T02:04:10.682+0000] {processor.py:157} INFO - Started process (PID=7054) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:04:10.689+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:04:10.689+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:04:10.689+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:04:11.543+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:04:11.541+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:04:11.544+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:04:11.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.880 seconds
[2023-07-07T02:04:41.845+0000] {processor.py:157} INFO - Started process (PID=7077) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:04:41.850+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:04:41.850+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:04:41.850+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:04:42.732+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:04:42.729+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:04:42.732+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:04:42.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.907 seconds
[2023-07-07T02:05:13.033+0000] {processor.py:157} INFO - Started process (PID=7100) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:05:13.039+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:05:13.040+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:05:13.040+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:05:13.900+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:05:13.898+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:05:13.901+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:05:13.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.885 seconds
[2023-07-07T02:05:44.219+0000] {processor.py:157} INFO - Started process (PID=7123) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:05:44.224+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:05:44.224+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:05:44.224+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:05:45.091+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:05:45.087+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:05:45.092+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:05:45.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.893 seconds
[2023-07-07T02:06:15.423+0000] {processor.py:157} INFO - Started process (PID=7146) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:06:15.428+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:06:15.428+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:06:15.428+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:06:16.311+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:06:16.308+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:06:16.312+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:06:16.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.908 seconds
[2023-07-07T02:06:46.600+0000] {processor.py:157} INFO - Started process (PID=7169) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:06:46.605+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:06:46.606+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:06:46.605+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:06:47.499+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:06:47.497+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:06:47.499+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:06:47.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.915 seconds
[2023-07-07T02:07:17.802+0000] {processor.py:157} INFO - Started process (PID=7192) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:07:17.803+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:07:17.803+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:07:17.803+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:07:18.669+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:07:18.667+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:07:18.670+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:07:18.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.886 seconds
[2023-07-07T02:07:48.986+0000] {processor.py:157} INFO - Started process (PID=7215) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:07:48.993+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:07:48.994+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:07:48.993+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:07:50.005+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:07:50.003+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:07:50.006+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:07:50.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.044 seconds
[2023-07-07T02:08:20.258+0000] {processor.py:157} INFO - Started process (PID=7238) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:08:20.264+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:08:20.265+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:08:20.265+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:08:21.130+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:08:21.128+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:08:21.131+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:08:21.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.890 seconds
[2023-07-07T02:08:51.418+0000] {processor.py:157} INFO - Started process (PID=7261) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:08:51.426+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:08:51.426+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:08:51.426+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:08:52.449+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:08:52.447+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:08:52.449+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:08:52.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.091 seconds
[2023-07-07T02:09:22.695+0000] {processor.py:157} INFO - Started process (PID=7291) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:09:22.701+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:09:22.702+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:09:22.702+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:09:23.645+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:09:23.642+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:09:23.645+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:09:23.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.970 seconds
[2023-07-07T02:09:51.785+0000] {processor.py:157} INFO - Started process (PID=32) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:09:51.786+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:09:51.786+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:09:51.786+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:09:53.463+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:09:53.460+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:09:53.463+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:09:53.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.693 seconds
[2023-07-07T02:10:24.155+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:10:24.165+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:10:24.166+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:10:24.166+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:10:24.992+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:10:24.990+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:10:24.993+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:10:25.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.853 seconds
[2023-07-07T02:10:55.360+0000] {processor.py:157} INFO - Started process (PID=80) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:10:55.366+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:10:55.367+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:10:55.367+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:10:56.219+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:10:56.217+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:10:56.220+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:10:56.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.879 seconds
[2023-07-07T02:11:26.548+0000] {processor.py:157} INFO - Started process (PID=103) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:11:26.561+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:11:26.561+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:11:26.561+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:11:27.397+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:11:27.395+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:11:27.397+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:11:27.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.864 seconds
[2023-07-07T02:11:57.772+0000] {processor.py:157} INFO - Started process (PID=126) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:11:57.779+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:11:57.779+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:11:57.779+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:11:58.563+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:11:58.561+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:11:58.563+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:11:58.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.810 seconds
[2023-07-07T02:12:28.974+0000] {processor.py:157} INFO - Started process (PID=149) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:12:28.979+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:12:28.980+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:12:28.980+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:12:29.779+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:12:29.777+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:12:29.780+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:12:29.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.824 seconds
[2023-07-07T02:13:00.255+0000] {processor.py:157} INFO - Started process (PID=172) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:13:00.260+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:13:00.260+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:13:00.260+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:13:01.051+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:13:01.049+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:13:01.052+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:13:01.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.816 seconds
[2023-07-07T02:13:31.395+0000] {processor.py:157} INFO - Started process (PID=195) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:13:31.400+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:13:31.401+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:13:31.401+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:13:32.202+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:13:32.199+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:13:32.203+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:13:32.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.828 seconds
[2023-07-07T02:14:02.679+0000] {processor.py:157} INFO - Started process (PID=218) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:14:02.684+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:14:02.684+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:14:02.684+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:14:03.533+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:14:03.530+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:14:03.533+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:14:03.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.871 seconds
[2023-07-07T02:14:33.832+0000] {processor.py:157} INFO - Started process (PID=241) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:14:33.843+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:14:33.844+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:14:33.844+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:14:34.657+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:14:34.655+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:14:34.657+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:14:34.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.845 seconds
[2023-07-07T02:15:04.898+0000] {processor.py:157} INFO - Started process (PID=264) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:15:04.903+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:15:04.904+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:15:04.903+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:15:05.697+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:15:05.695+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:15:05.697+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:15:05.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.820 seconds
[2023-07-07T02:15:36.105+0000] {processor.py:157} INFO - Started process (PID=287) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:15:36.106+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:15:36.106+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:15:36.106+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:15:36.930+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:15:36.928+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:15:36.931+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:15:36.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.839 seconds
[2023-07-07T02:16:07.328+0000] {processor.py:157} INFO - Started process (PID=310) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:16:07.335+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:16:07.335+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:16:07.335+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:16:08.147+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:16:08.145+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:16:08.147+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:16:08.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.838 seconds
[2023-07-07T02:16:38.592+0000] {processor.py:157} INFO - Started process (PID=333) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:16:38.597+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:16:38.598+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:16:38.598+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:16:39.388+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:16:39.386+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:16:39.388+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:16:39.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.816 seconds
[2023-07-07T02:17:09.836+0000] {processor.py:157} INFO - Started process (PID=356) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:17:09.846+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:17:09.846+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:17:09.846+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:17:10.632+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:17:10.629+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:17:10.632+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:17:10.646+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.813 seconds
[2023-07-07T02:17:40.847+0000] {processor.py:157} INFO - Started process (PID=379) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:17:40.858+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:17:40.859+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:17:40.859+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:17:41.674+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:17:41.672+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:17:41.675+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:17:41.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.846 seconds
[2023-07-07T02:18:12.045+0000] {processor.py:157} INFO - Started process (PID=402) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:18:12.050+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:18:12.051+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:18:12.050+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:18:12.852+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:18:12.850+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:18:12.853+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:18:12.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.827 seconds
[2023-07-07T02:18:43.221+0000] {processor.py:157} INFO - Started process (PID=425) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:18:43.233+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:18:43.234+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:18:43.234+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:18:44.024+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:18:44.022+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:18:44.025+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:18:44.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.822 seconds
[2023-07-07T02:19:14.417+0000] {processor.py:157} INFO - Started process (PID=448) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:19:14.429+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:19:14.429+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:19:14.429+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:19:15.230+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:19:15.228+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:19:15.231+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:19:15.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.834 seconds
[2023-07-07T02:19:45.704+0000] {processor.py:157} INFO - Started process (PID=471) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:19:45.710+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:19:45.710+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:19:45.710+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:19:46.523+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:19:46.521+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:19:46.524+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:19:46.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.836 seconds
[2023-07-07T02:20:16.767+0000] {processor.py:157} INFO - Started process (PID=494) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:20:16.777+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:20:16.777+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:20:16.777+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:20:17.604+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:20:17.602+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:20:17.605+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:20:17.616+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.851 seconds
[2023-07-07T02:20:47.958+0000] {processor.py:157} INFO - Started process (PID=524) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:20:47.964+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:20:47.964+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:20:47.964+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:20:48.760+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:20:48.757+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:20:48.761+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:20:48.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.823 seconds
[2023-07-07T02:21:19.223+0000] {processor.py:157} INFO - Started process (PID=547) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:21:19.228+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:21:19.228+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:21:19.228+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:21:20.023+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:21:20.021+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:21:20.023+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:21:20.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.817 seconds
[2023-07-07T02:21:50.251+0000] {processor.py:157} INFO - Started process (PID=570) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:21:50.258+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:21:50.259+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:21:50.259+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:21:51.058+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:21:51.055+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:21:51.058+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:21:51.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.821 seconds
[2023-07-07T02:22:21.446+0000] {processor.py:157} INFO - Started process (PID=593) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:22:21.452+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:22:21.453+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:22:21.452+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:22:22.280+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:22:22.277+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:22:22.280+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:22:22.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.853 seconds
[2023-07-07T02:22:52.743+0000] {processor.py:157} INFO - Started process (PID=616) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:22:52.748+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:22:52.749+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:22:52.749+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:22:53.539+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:22:53.537+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:22:53.539+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:22:53.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.815 seconds
[2023-07-07T02:23:23.783+0000] {processor.py:157} INFO - Started process (PID=639) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:23:23.788+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:23:23.788+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:23:23.788+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:23:24.585+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:23:24.583+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:23:24.585+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:23:24.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.821 seconds
[2023-07-07T02:23:55.075+0000] {processor.py:157} INFO - Started process (PID=662) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:23:55.080+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:23:55.080+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:23:55.080+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:23:55.883+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:23:55.880+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:23:55.884+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:23:55.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.829 seconds
[2023-07-07T02:24:26.216+0000] {processor.py:157} INFO - Started process (PID=685) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:24:26.221+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:24:26.222+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:24:26.222+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:24:27.013+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:24:27.011+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:24:27.013+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:24:27.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.816 seconds
[2023-07-07T02:24:57.245+0000] {processor.py:157} INFO - Started process (PID=708) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:24:57.251+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:24:57.251+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:24:57.251+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:24:58.046+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:24:58.044+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:24:58.047+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:24:58.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.817 seconds
[2023-07-07T02:25:28.610+0000] {processor.py:157} INFO - Started process (PID=733) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:25:28.616+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:25:28.616+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:25:28.616+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:25:29.408+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:25:29.404+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:25:29.408+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:25:29.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.817 seconds
[2023-07-07T02:25:59.706+0000] {processor.py:157} INFO - Started process (PID=756) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:25:59.712+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:25:59.712+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:25:59.712+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:26:00.511+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:26:00.509+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:26:00.511+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:26:00.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.821 seconds
[2023-07-07T02:26:30.904+0000] {processor.py:157} INFO - Started process (PID=779) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:26:30.909+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:26:30.909+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:26:30.909+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:26:31.703+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:26:31.701+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:26:31.703+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:26:31.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.815 seconds
[2023-07-07T02:27:02.116+0000] {processor.py:157} INFO - Started process (PID=802) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:27:02.127+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:27:02.127+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:27:02.127+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:27:02.921+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:27:02.919+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:27:02.921+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:27:02.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.820 seconds
[2023-07-07T02:27:33.313+0000] {processor.py:157} INFO - Started process (PID=825) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:27:33.319+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:27:33.320+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:27:33.320+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:27:34.111+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:27:34.108+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:27:34.112+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:27:34.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.818 seconds
[2023-07-07T02:28:04.523+0000] {processor.py:157} INFO - Started process (PID=848) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:28:04.534+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:28:04.534+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:28:04.534+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:28:05.403+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:28:05.401+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:28:05.403+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:28:05.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.904 seconds
[2023-07-07T02:28:35.695+0000] {processor.py:157} INFO - Started process (PID=871) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:28:35.700+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:28:35.701+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:28:35.700+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:28:36.491+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:28:36.489+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:28:36.492+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:28:36.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.815 seconds
[2023-07-07T02:29:06.855+0000] {processor.py:157} INFO - Started process (PID=894) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:29:06.862+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:29:06.862+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:29:06.862+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:29:07.656+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:29:07.652+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:29:07.656+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:29:07.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.818 seconds
[2023-07-07T02:29:38.038+0000] {processor.py:157} INFO - Started process (PID=917) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:29:38.044+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:29:38.045+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:29:38.045+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:29:38.835+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:29:38.833+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:29:38.835+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:29:38.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.819 seconds
[2023-07-07T02:30:09.242+0000] {processor.py:157} INFO - Started process (PID=940) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:30:09.248+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:30:09.248+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:30:09.248+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:30:10.112+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:30:10.110+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:30:10.112+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:30:10.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.890 seconds
[2023-07-07T02:30:40.425+0000] {processor.py:157} INFO - Started process (PID=963) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:30:40.431+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:30:40.431+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:30:40.431+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:30:41.226+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:30:41.223+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:30:41.227+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:30:41.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.816 seconds
[2023-07-07T02:31:11.629+0000] {processor.py:157} INFO - Started process (PID=986) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:31:11.630+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:31:11.631+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:31:11.631+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:31:12.428+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:31:12.426+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:31:12.429+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:31:12.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.814 seconds
[2023-07-07T02:31:42.824+0000] {processor.py:157} INFO - Started process (PID=1009) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:31:42.829+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:31:42.830+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:31:42.830+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:31:43.622+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:31:43.620+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:31:43.623+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:31:43.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.814 seconds
[2023-07-07T02:32:14.104+0000] {processor.py:157} INFO - Started process (PID=1032) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:32:14.109+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:32:14.110+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:32:14.109+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:32:14.979+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:32:14.977+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:32:14.980+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:32:14.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.893 seconds
[2023-07-07T02:32:45.267+0000] {processor.py:157} INFO - Started process (PID=1055) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:32:45.279+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:32:45.279+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:32:45.279+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:32:46.067+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:32:46.064+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:32:46.068+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:32:46.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.814 seconds
[2023-07-07T02:33:16.443+0000] {processor.py:157} INFO - Started process (PID=1078) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:33:16.455+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:33:16.455+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:33:16.455+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:33:17.253+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:33:17.251+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:33:17.254+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:33:17.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.830 seconds
[2023-07-07T02:33:47.627+0000] {processor.py:157} INFO - Started process (PID=1101) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:33:47.632+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:33:47.632+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:33:47.632+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:33:48.431+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:33:48.429+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:33:48.431+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:33:48.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.823 seconds
[2023-07-07T02:34:18.875+0000] {processor.py:157} INFO - Started process (PID=1124) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:34:18.880+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:34:18.880+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:34:18.880+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:34:19.743+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:34:19.740+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:34:19.743+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:34:19.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.888 seconds
[2023-07-07T02:34:49.984+0000] {processor.py:157} INFO - Started process (PID=1147) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:34:49.989+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:34:49.989+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:34:49.989+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:34:50.785+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:34:50.783+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:34:50.786+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:34:50.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.821 seconds
[2023-07-07T02:35:21.273+0000] {processor.py:157} INFO - Started process (PID=1177) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:35:21.278+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:35:21.278+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:35:21.278+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:35:22.062+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:35:22.059+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:35:22.062+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:35:22.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.809 seconds
[2023-07-07T02:35:52.271+0000] {processor.py:157} INFO - Started process (PID=1200) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:35:52.277+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:35:52.277+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:35:52.277+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:35:53.097+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:35:53.095+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:35:53.098+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:35:53.109+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.841 seconds
[2023-07-07T02:36:23.442+0000] {processor.py:157} INFO - Started process (PID=1223) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:36:23.448+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:36:23.448+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:36:23.448+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:36:24.320+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:36:24.318+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:36:24.320+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:36:24.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.899 seconds
[2023-07-07T02:36:54.633+0000] {processor.py:157} INFO - Started process (PID=1246) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:36:54.638+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:36:54.639+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:36:54.639+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:36:55.426+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:36:55.424+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:36:55.427+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:36:55.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.807 seconds
[2023-07-07T02:37:25.808+0000] {processor.py:157} INFO - Started process (PID=1269) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:37:25.815+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:37:25.815+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:37:25.815+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:37:26.604+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:37:26.602+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:37:26.604+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:37:26.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.815 seconds
[2023-07-07T02:37:56.997+0000] {processor.py:157} INFO - Started process (PID=1292) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:37:57.002+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:37:57.002+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:37:57.002+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:37:57.804+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:37:57.802+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:37:57.805+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:37:57.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.823 seconds
[2023-07-07T02:38:28.157+0000] {processor.py:157} INFO - Started process (PID=1314) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:38:28.168+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:38:28.168+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:38:28.168+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:38:29.072+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:38:29.069+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:38:29.072+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:38:29.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.930 seconds
[2023-07-07T02:38:59.383+0000] {processor.py:157} INFO - Started process (PID=1337) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:38:59.390+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:38:59.390+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:38:59.390+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:39:00.180+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:39:00.176+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:39:00.180+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:39:00.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.815 seconds
[2023-07-07T02:39:30.496+0000] {processor.py:157} INFO - Started process (PID=1360) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:39:30.502+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:39:30.502+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:39:30.502+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:39:31.292+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:39:31.288+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:39:31.292+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:39:31.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.814 seconds
[2023-07-07T02:40:01.547+0000] {processor.py:157} INFO - Started process (PID=1383) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:40:01.553+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:40:01.553+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:40:01.553+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:40:02.360+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:40:02.358+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:40:02.360+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:40:02.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.834 seconds
[2023-07-07T02:40:32.746+0000] {processor.py:157} INFO - Started process (PID=1406) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:40:32.757+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:40:32.757+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:40:32.757+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:40:33.625+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:40:33.623+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:40:33.625+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:40:33.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.899 seconds
[2023-07-07T02:41:04.036+0000] {processor.py:157} INFO - Started process (PID=1431) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:41:04.041+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:41:04.042+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:41:04.042+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:41:04.831+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:41:04.829+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:41:04.832+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:41:04.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.814 seconds
[2023-07-07T02:41:35.241+0000] {processor.py:157} INFO - Started process (PID=1454) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:41:35.247+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:41:35.248+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:41:35.248+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:41:36.049+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:41:36.046+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:41:36.050+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:41:36.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.830 seconds
[2023-07-07T02:42:06.447+0000] {processor.py:157} INFO - Started process (PID=1477) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:42:06.455+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:42:06.455+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:42:06.455+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:42:07.326+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:42:07.324+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:42:07.327+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:42:07.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.898 seconds
[2023-07-07T02:42:37.558+0000] {processor.py:157} INFO - Started process (PID=1500) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:42:37.567+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:42:37.568+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:42:37.568+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:42:38.441+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:42:38.439+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:42:38.442+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:42:38.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.898 seconds
[2023-07-07T02:43:08.730+0000] {processor.py:157} INFO - Started process (PID=1523) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:43:08.740+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:43:08.741+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:43:08.741+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:43:09.646+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:43:09.643+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:43:09.646+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:43:09.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.929 seconds
[2023-07-07T02:43:39.943+0000] {processor.py:157} INFO - Started process (PID=1546) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:43:39.954+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:43:39.954+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:43:39.954+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:43:40.735+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:43:40.732+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:43:40.735+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:43:40.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.806 seconds
[2023-07-07T02:44:11.096+0000] {processor.py:157} INFO - Started process (PID=1569) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:44:11.102+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:44:11.102+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:44:11.102+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:44:11.974+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:44:11.972+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:44:11.974+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:44:11.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.896 seconds
[2023-07-07T02:44:42.283+0000] {processor.py:157} INFO - Started process (PID=1592) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:44:42.291+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:44:42.292+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:44:42.291+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:44:43.192+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:44:43.190+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:44:43.193+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:44:43.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.924 seconds
[2023-07-07T02:45:13.433+0000] {processor.py:157} INFO - Started process (PID=1615) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:45:13.440+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:45:13.440+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:45:13.440+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:45:14.312+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:45:14.310+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:45:14.313+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:45:14.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.898 seconds
[2023-07-07T02:45:44.615+0000] {processor.py:157} INFO - Started process (PID=1638) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:45:44.616+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:45:44.616+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:45:44.616+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:45:45.450+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:45:45.448+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:45:45.451+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:45:45.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.855 seconds
[2023-07-07T02:46:15.681+0000] {processor.py:157} INFO - Started process (PID=1661) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:46:15.686+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:46:15.687+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:46:15.687+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:46:16.541+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:46:16.539+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:46:16.542+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:46:16.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.876 seconds
[2023-07-07T02:46:46.978+0000] {processor.py:157} INFO - Started process (PID=1684) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:46:46.984+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:46:46.984+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:46:46.984+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:46:47.978+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:46:47.975+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:46:47.979+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:46:47.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.018 seconds
[2023-07-07T02:47:18.193+0000] {processor.py:157} INFO - Started process (PID=1707) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:47:18.198+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:47:18.198+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:47:18.198+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:47:19.087+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:47:19.085+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:47:19.088+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:47:19.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.915 seconds
[2023-07-07T02:47:49.372+0000] {processor.py:157} INFO - Started process (PID=1730) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:47:49.378+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:47:49.378+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:47:49.378+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:47:50.204+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:47:50.202+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:47:50.205+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:47:50.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.847 seconds
[2023-07-07T02:48:20.416+0000] {processor.py:157} INFO - Started process (PID=1753) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:48:20.422+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:48:20.422+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:48:20.422+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:48:21.305+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:48:21.303+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:48:21.305+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:48:21.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.908 seconds
[2023-07-07T02:48:51.607+0000] {processor.py:157} INFO - Started process (PID=1776) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:48:51.612+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:48:51.613+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:48:51.612+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:48:52.424+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:48:52.421+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:48:52.424+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:48:52.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.831 seconds
[2023-07-07T02:49:22.739+0000] {processor.py:157} INFO - Started process (PID=1799) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:49:22.745+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:49:22.746+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:49:22.746+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:49:23.682+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:49:23.680+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:49:23.683+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:49:23.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.956 seconds
[2023-07-07T02:49:53.907+0000] {processor.py:157} INFO - Started process (PID=1829) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:49:53.912+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:49:53.913+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:49:53.913+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:49:54.740+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:49:54.737+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:49:54.740+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:49:54.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.848 seconds
[2023-07-07T02:50:25.097+0000] {processor.py:157} INFO - Started process (PID=1852) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:50:25.106+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:50:25.106+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:50:25.106+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:50:26.075+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:50:26.072+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:50:26.076+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:50:26.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.994 seconds
[2023-07-07T02:50:56.316+0000] {processor.py:157} INFO - Started process (PID=1875) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:50:56.323+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:50:56.324+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:50:56.324+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:50:57.148+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:50:57.146+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:50:57.148+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:50:57.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.851 seconds
[2023-07-07T02:51:27.508+0000] {processor.py:157} INFO - Started process (PID=1898) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:51:27.509+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:51:27.509+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:51:27.509+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:51:28.393+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:51:28.391+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:51:28.394+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:51:28.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.902 seconds
[2023-07-07T02:51:58.692+0000] {processor.py:157} INFO - Started process (PID=1921) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:51:58.699+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:51:58.699+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:51:58.699+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:51:59.486+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:51:59.484+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:51:59.486+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:51:59.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.812 seconds
[2023-07-07T02:52:29.971+0000] {processor.py:157} INFO - Started process (PID=1944) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:52:29.976+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:52:29.977+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:52:29.977+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:52:30.858+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:52:30.856+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:52:30.858+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:52:30.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.904 seconds
[2023-07-07T02:53:01.195+0000] {processor.py:157} INFO - Started process (PID=1967) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:53:01.205+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:53:01.206+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:53:01.206+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:53:02.011+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:53:02.008+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:53:02.012+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:53:02.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.834 seconds
[2023-07-07T02:53:32.253+0000] {processor.py:157} INFO - Started process (PID=1990) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:53:32.259+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:53:32.259+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:53:32.259+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:53:33.129+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:53:33.127+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:53:33.129+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:53:33.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.896 seconds
[2023-07-07T02:54:03.372+0000] {processor.py:157} INFO - Started process (PID=2013) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:54:03.378+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:54:03.378+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:54:03.378+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:54:04.188+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:54:04.184+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:54:04.188+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:54:04.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.836 seconds
[2023-07-07T02:54:34.595+0000] {processor.py:157} INFO - Started process (PID=2036) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:54:34.600+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:54:34.601+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:54:34.601+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:54:35.473+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:54:35.471+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:54:35.473+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:54:35.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.897 seconds
[2023-07-07T02:55:05.726+0000] {processor.py:157} INFO - Started process (PID=2059) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:55:05.732+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:55:05.732+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:55:05.732+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:55:06.540+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:55:06.538+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:55:06.541+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:55:06.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.833 seconds
[2023-07-07T02:55:37.036+0000] {processor.py:157} INFO - Started process (PID=2082) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:55:37.041+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:55:37.041+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:55:37.041+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:55:37.916+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:55:37.914+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:55:37.917+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:55:37.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.899 seconds
[2023-07-07T02:56:08.150+0000] {processor.py:157} INFO - Started process (PID=2105) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:56:08.157+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:56:08.158+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:56:08.158+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:56:08.996+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:56:08.993+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:56:08.997+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:56:09.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.870 seconds
[2023-07-07T02:56:39.453+0000] {processor.py:157} INFO - Started process (PID=2130) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:56:39.458+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:56:39.458+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:56:39.458+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:56:40.353+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:56:40.351+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:56:40.354+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:56:40.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.920 seconds
[2023-07-07T02:57:10.636+0000] {processor.py:157} INFO - Started process (PID=2153) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:57:10.643+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:57:10.644+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:57:10.644+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:57:11.469+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:57:11.466+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:57:11.469+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:57:11.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.853 seconds
[2023-07-07T02:57:41.687+0000] {processor.py:157} INFO - Started process (PID=2176) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:57:41.698+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:57:41.698+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:57:41.698+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:57:42.613+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:57:42.611+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:57:42.614+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:57:42.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.940 seconds
[2023-07-07T02:58:12.860+0000] {processor.py:157} INFO - Started process (PID=2199) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:58:12.868+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:58:12.868+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:58:12.868+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:58:13.747+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:58:13.744+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:58:13.748+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:58:13.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.902 seconds
[2023-07-07T02:58:44.035+0000] {processor.py:157} INFO - Started process (PID=2222) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:58:44.041+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:58:44.042+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:58:44.042+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:58:44.909+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:58:44.907+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:58:44.910+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:58:44.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.893 seconds
[2023-07-07T02:59:15.216+0000] {processor.py:157} INFO - Started process (PID=2245) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:59:15.224+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:59:15.225+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:59:15.224+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:59:16.015+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:59:16.013+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:59:16.015+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:59:16.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.819 seconds
[2023-07-07T02:59:46.316+0000] {processor.py:157} INFO - Started process (PID=2268) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:59:46.323+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T02:59:46.323+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:59:46.323+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:59:47.226+0000] {logging_mixin.py:149} INFO - [2023-07-07T02:59:47.224+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T02:59:47.227+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T02:59:47.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.930 seconds
[2023-07-07T03:00:17.508+0000] {processor.py:157} INFO - Started process (PID=2291) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:00:17.518+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:00:17.518+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:00:17.518+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:00:18.405+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:00:18.403+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:00:18.406+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:00:18.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.911 seconds
[2023-07-07T03:00:48.641+0000] {processor.py:157} INFO - Started process (PID=2314) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:00:48.652+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:00:48.652+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:00:48.652+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:00:49.525+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:00:49.523+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:00:49.525+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:00:49.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.905 seconds
[2023-07-07T03:01:19.820+0000] {processor.py:157} INFO - Started process (PID=2337) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:01:19.825+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:01:19.826+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:01:19.826+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:01:20.663+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:01:20.661+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:01:20.664+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:01:20.675+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.857 seconds
[2023-07-07T03:01:50.882+0000] {processor.py:157} INFO - Started process (PID=2360) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:01:50.888+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:01:50.888+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:01:50.888+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:01:51.813+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:01:51.811+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:01:51.814+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:01:51.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.946 seconds
[2023-07-07T03:02:22.064+0000] {processor.py:157} INFO - Started process (PID=2383) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:02:22.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:02:22.071+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:02:22.071+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:02:22.963+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:02:22.961+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:02:22.964+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:02:22.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.919 seconds
[2023-07-07T03:02:53.257+0000] {processor.py:157} INFO - Started process (PID=2406) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:02:53.262+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:02:53.263+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:02:53.263+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:02:54.169+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:02:54.167+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:02:54.169+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:02:54.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.929 seconds
[2023-07-07T03:03:24.494+0000] {processor.py:157} INFO - Started process (PID=2429) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:03:24.503+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:03:24.503+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:03:24.503+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:03:25.323+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:03:25.321+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:03:25.324+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:03:25.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.853 seconds
[2023-07-07T03:03:55.540+0000] {processor.py:157} INFO - Started process (PID=2452) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:03:55.546+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:03:55.547+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:03:55.547+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:03:56.415+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:03:56.412+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:03:56.416+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:03:56.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.893 seconds
[2023-07-07T03:04:26.624+0000] {processor.py:157} INFO - Started process (PID=2475) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:04:26.631+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:04:26.631+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:04:26.631+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:04:27.497+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:04:27.495+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:04:27.497+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:04:27.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.888 seconds
[2023-07-07T03:04:57.730+0000] {processor.py:157} INFO - Started process (PID=2505) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:04:57.737+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:04:57.737+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:04:57.737+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:04:58.615+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:04:58.613+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:04:58.615+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:04:58.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.904 seconds
[2023-07-07T03:05:28.885+0000] {processor.py:157} INFO - Started process (PID=2528) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:05:28.892+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:05:28.892+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:05:28.892+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:05:29.680+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:05:29.678+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:05:29.681+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:05:29.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.813 seconds
[2023-07-07T03:06:00.133+0000] {processor.py:157} INFO - Started process (PID=2551) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:06:00.139+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:06:00.139+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:06:00.139+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:06:01.011+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:06:01.009+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:06:01.011+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:06:01.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.896 seconds
[2023-07-07T03:06:31.301+0000] {processor.py:157} INFO - Started process (PID=2574) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:06:31.308+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:06:31.309+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:06:31.309+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:06:32.185+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:06:32.182+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:06:32.185+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:06:32.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.898 seconds
[2023-07-07T03:07:02.466+0000] {processor.py:157} INFO - Started process (PID=2597) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:07:02.472+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:07:02.473+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:07:02.473+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:07:03.340+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:07:03.338+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:07:03.341+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:07:03.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.894 seconds
[2023-07-07T03:07:33.567+0000] {processor.py:157} INFO - Started process (PID=2620) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:07:33.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:07:33.572+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:07:33.572+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:07:34.374+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:07:34.372+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:07:34.375+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:07:34.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.827 seconds
[2023-07-07T03:08:04.737+0000] {processor.py:157} INFO - Started process (PID=2643) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:08:04.738+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:08:04.738+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:08:04.738+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:08:05.606+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:08:05.604+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:08:05.607+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:08:05.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.889 seconds
[2023-07-07T03:08:36.026+0000] {processor.py:157} INFO - Started process (PID=2675) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:08:36.032+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:08:36.032+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:08:36.032+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:08:36.894+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:08:36.892+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:08:36.894+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:08:36.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.889 seconds
[2023-07-07T03:09:07.139+0000] {processor.py:157} INFO - Started process (PID=2716) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:09:07.145+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:09:07.145+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:09:07.145+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:09:08.040+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:09:08.037+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:09:08.040+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:09:08.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.914 seconds
[2023-07-07T03:09:38.343+0000] {processor.py:157} INFO - Started process (PID=2739) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:09:38.349+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:09:38.350+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:09:38.350+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:09:39.144+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:09:39.141+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:09:39.144+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:09:39.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.820 seconds
[2023-07-07T03:10:09.407+0000] {processor.py:157} INFO - Started process (PID=2763) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:10:09.418+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:10:09.419+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:10:09.419+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:10:10.283+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:10:10.280+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:10:10.284+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:10:10.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.891 seconds
[2023-07-07T03:10:40.581+0000] {processor.py:157} INFO - Started process (PID=2786) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:10:40.588+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:10:40.588+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:10:40.588+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:10:41.455+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:10:41.452+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:10:41.455+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:10:41.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.888 seconds
[2023-07-07T03:11:11.671+0000] {processor.py:157} INFO - Started process (PID=2809) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:11:11.684+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:11:11.685+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:11:11.684+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:11:12.569+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:11:12.567+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:11:12.569+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:11:12.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.912 seconds
[2023-07-07T03:11:42.786+0000] {processor.py:157} INFO - Started process (PID=2832) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:11:42.791+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:11:42.792+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:11:42.792+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:11:43.577+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:11:43.575+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:11:43.577+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:11:43.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.810 seconds
[2023-07-07T03:12:14.089+0000] {processor.py:157} INFO - Started process (PID=2858) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:12:14.094+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:12:14.094+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:12:14.094+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:12:14.963+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:12:14.961+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:12:14.964+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:12:14.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.890 seconds
[2023-07-07T03:12:45.276+0000] {processor.py:157} INFO - Started process (PID=2882) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:12:45.281+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:12:45.282+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:12:45.282+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:12:46.147+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:12:46.145+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:12:46.147+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:12:46.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.891 seconds
[2023-07-07T03:13:16.449+0000] {processor.py:157} INFO - Started process (PID=2909) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:13:16.454+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:13:16.454+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:13:16.454+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:13:17.326+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:13:17.323+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:13:17.326+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:13:17.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.897 seconds
[2023-07-07T03:13:47.565+0000] {processor.py:157} INFO - Started process (PID=2932) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:13:47.566+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:13:47.566+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:13:47.566+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:13:48.481+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:13:48.478+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:13:48.481+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:13:48.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.930 seconds
[2023-07-07T03:14:18.736+0000] {processor.py:157} INFO - Started process (PID=2955) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:14:18.779+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:14:18.779+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:14:18.779+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:14:21.030+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:14:21.028+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:14:21.030+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:14:21.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.311 seconds
[2023-07-07T03:14:51.934+0000] {processor.py:157} INFO - Started process (PID=2978) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:14:51.934+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:14:51.935+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:14:51.935+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:14:52.833+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:14:52.831+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:14:52.834+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:14:52.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.914 seconds
[2023-07-07T03:15:23.040+0000] {processor.py:157} INFO - Started process (PID=3001) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:15:23.046+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:15:23.047+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:15:23.047+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:15:23.929+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:15:23.926+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:15:23.930+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:15:23.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.909 seconds
[2023-07-07T03:15:54.232+0000] {processor.py:157} INFO - Started process (PID=3024) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:15:54.239+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:15:54.239+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:15:54.239+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:15:55.116+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:15:55.113+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:15:55.116+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:15:55.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.903 seconds
[2023-07-07T03:16:25.371+0000] {processor.py:157} INFO - Started process (PID=3047) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:16:25.377+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:16:25.377+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:16:25.377+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:16:26.244+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:16:26.241+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:16:26.244+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:16:26.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.891 seconds
[2023-07-07T03:16:56.531+0000] {processor.py:157} INFO - Started process (PID=3070) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:16:56.536+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:16:56.537+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:16:56.537+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:16:57.409+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:16:57.407+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:16:57.410+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:16:57.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.898 seconds
[2023-07-07T03:17:27.665+0000] {processor.py:157} INFO - Started process (PID=3093) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:17:27.679+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:17:27.680+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:17:27.679+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:17:28.621+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:17:28.618+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:17:28.621+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:17:28.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.971 seconds
[2023-07-07T03:17:58.869+0000] {processor.py:157} INFO - Started process (PID=3116) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:17:58.878+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:17:58.878+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:17:58.878+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:17:59.760+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:17:59.757+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:17:59.761+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:17:59.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.911 seconds
[2023-07-07T03:18:30.057+0000] {processor.py:157} INFO - Started process (PID=3139) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:18:30.069+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:18:30.070+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:18:30.069+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:18:30.993+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:18:30.991+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:18:30.993+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:18:31.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.952 seconds
[2023-07-07T03:19:01.228+0000] {processor.py:157} INFO - Started process (PID=3169) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:19:01.234+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:19:01.234+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:19:01.234+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:19:02.134+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:19:02.132+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:19:02.134+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:19:02.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.926 seconds
[2023-07-07T03:19:32.389+0000] {processor.py:157} INFO - Started process (PID=3192) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:19:32.395+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:19:32.396+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:19:32.395+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:19:33.385+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:19:33.382+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:19:33.385+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:19:33.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.012 seconds
[2023-07-07T03:20:03.616+0000] {processor.py:157} INFO - Started process (PID=3215) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:20:03.621+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:20:03.621+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:20:03.621+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:20:04.475+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:20:04.473+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:20:04.476+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:20:04.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.958 seconds
[2023-07-07T03:20:34.882+0000] {processor.py:157} INFO - Started process (PID=3238) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:20:34.889+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:20:34.889+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:20:34.889+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:20:35.779+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:20:35.777+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:20:35.780+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:20:35.791+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.911 seconds
[2023-07-07T03:21:06.073+0000] {processor.py:157} INFO - Started process (PID=3261) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:21:06.078+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:21:06.078+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:21:06.078+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:21:06.953+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:21:06.950+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:21:06.953+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:21:06.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.901 seconds
[2023-07-07T03:21:37.267+0000] {processor.py:157} INFO - Started process (PID=3284) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:21:37.273+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:21:37.273+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:21:37.273+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:21:38.147+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:21:38.145+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:21:38.148+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:21:38.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.899 seconds
[2023-07-07T03:22:08.456+0000] {processor.py:157} INFO - Started process (PID=3307) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:22:08.461+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:22:08.462+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:22:08.462+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:22:09.368+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:22:09.366+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:22:09.369+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:22:09.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.938 seconds
[2023-07-07T03:22:39.638+0000] {processor.py:157} INFO - Started process (PID=3330) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:22:39.643+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:22:39.643+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:22:39.643+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:22:40.610+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:22:40.607+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:22:40.610+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:22:40.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.990 seconds
[2023-07-07T03:23:10.859+0000] {processor.py:157} INFO - Started process (PID=3353) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:23:10.860+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:23:10.860+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:23:10.860+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:23:12.014+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:23:12.011+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:23:12.015+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:23:12.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.171 seconds
[2023-07-07T03:23:42.169+0000] {processor.py:157} INFO - Started process (PID=3376) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:23:42.175+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:23:42.176+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:23:42.176+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:23:43.212+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:23:43.209+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:23:43.212+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:23:43.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.058 seconds
[2023-07-07T03:24:13.425+0000] {processor.py:157} INFO - Started process (PID=3399) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:24:13.432+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:24:13.432+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:24:13.432+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:24:14.407+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:24:14.405+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:24:14.407+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:24:14.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.003 seconds
[2023-07-07T03:24:44.602+0000] {processor.py:157} INFO - Started process (PID=3422) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:24:44.607+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:24:44.607+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:24:44.607+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:24:45.614+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:24:45.612+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:24:45.614+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:24:45.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.032 seconds
[2023-07-07T03:25:15.826+0000] {processor.py:157} INFO - Started process (PID=3445) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:25:15.836+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:25:15.837+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:25:15.837+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:25:16.816+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:25:16.814+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:25:16.817+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:25:16.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.013 seconds
[2023-07-07T03:25:47.021+0000] {processor.py:157} INFO - Started process (PID=3468) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:25:47.032+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:25:47.032+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:25:47.032+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:25:48.023+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:25:48.020+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:25:48.023+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:25:48.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.021 seconds
[2023-07-07T03:26:18.297+0000] {processor.py:157} INFO - Started process (PID=3491) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:26:18.303+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:26:18.304+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:26:18.303+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:26:19.312+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:26:19.310+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:26:19.313+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:26:19.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.035 seconds
[2023-07-07T03:26:49.565+0000] {processor.py:157} INFO - Started process (PID=3516) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:26:49.570+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:26:49.571+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:26:49.571+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:26:50.554+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:26:50.551+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:26:50.554+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:26:50.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.010 seconds
[2023-07-07T03:27:20.761+0000] {processor.py:157} INFO - Started process (PID=3539) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:27:20.768+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:27:20.768+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:27:20.768+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:27:21.667+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:27:21.665+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:27:21.667+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:27:21.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.926 seconds
[2023-07-07T03:27:51.929+0000] {processor.py:157} INFO - Started process (PID=3562) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:27:51.934+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:27:51.935+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:27:51.934+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:27:52.846+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:27:52.844+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:27:52.846+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:27:52.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.940 seconds
[2023-07-07T03:28:23.071+0000] {processor.py:157} INFO - Started process (PID=3585) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:28:23.076+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:28:23.077+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:28:23.077+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:28:23.977+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:28:23.975+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:28:23.978+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:28:23.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.926 seconds
[2023-07-07T03:28:54.259+0000] {processor.py:157} INFO - Started process (PID=3608) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:28:54.259+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:28:54.260+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:28:54.260+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:28:55.141+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:28:55.138+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:28:55.141+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:28:55.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.896 seconds
[2023-07-07T03:29:25.391+0000] {processor.py:157} INFO - Started process (PID=3631) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:29:25.396+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:29:25.397+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:29:25.397+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:29:26.265+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:29:26.263+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:29:26.266+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:29:26.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.895 seconds
[2023-07-07T03:29:56.548+0000] {processor.py:157} INFO - Started process (PID=3654) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:29:56.553+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:29:56.554+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:29:56.554+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:29:57.435+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:29:57.433+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:29:57.435+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:29:57.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.905 seconds
[2023-07-07T03:30:27.679+0000] {processor.py:157} INFO - Started process (PID=3677) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:30:27.685+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:30:27.686+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:30:27.686+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:30:28.574+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:30:28.572+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:30:28.574+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:30:28.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.914 seconds
[2023-07-07T03:30:58.779+0000] {processor.py:157} INFO - Started process (PID=3700) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:30:58.785+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:30:58.785+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:30:58.785+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:30:59.666+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:30:59.664+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:30:59.667+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:30:59.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.902 seconds
[2023-07-07T03:31:29.963+0000] {processor.py:157} INFO - Started process (PID=3723) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:31:29.974+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:31:29.974+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:31:29.974+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:31:30.863+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:31:30.861+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:31:30.864+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:31:30.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.916 seconds
[2023-07-07T03:32:01.151+0000] {processor.py:157} INFO - Started process (PID=3746) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:32:01.158+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:32:01.159+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:32:01.159+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:32:02.067+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:32:02.065+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:32:02.068+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:32:02.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.930 seconds
[2023-07-07T03:32:32.288+0000] {processor.py:157} INFO - Started process (PID=3770) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:32:32.292+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:32:32.293+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:32:32.293+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:32:33.162+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:32:33.160+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:32:33.163+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:32:33.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.889 seconds
[2023-07-07T03:33:03.481+0000] {processor.py:157} INFO - Started process (PID=3793) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:33:03.487+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:33:03.487+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:33:03.487+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:33:04.372+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:33:04.370+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:33:04.373+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:33:04.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.904 seconds
[2023-07-07T03:33:34.663+0000] {processor.py:157} INFO - Started process (PID=3823) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:33:34.671+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:33:34.671+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:33:34.671+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:33:35.599+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:33:35.597+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:33:35.599+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:33:35.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.951 seconds
[2023-07-07T03:34:05.900+0000] {processor.py:157} INFO - Started process (PID=3846) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:34:05.909+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:34:05.910+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:34:05.910+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:34:06.808+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:34:06.806+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:34:06.809+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:34:06.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.928 seconds
[2023-07-07T03:34:37.045+0000] {processor.py:157} INFO - Started process (PID=3869) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:34:37.050+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:34:37.050+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:34:37.050+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:34:37.963+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:34:37.960+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:34:37.963+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:34:37.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.939 seconds
[2023-07-07T03:35:08.199+0000] {processor.py:157} INFO - Started process (PID=3892) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:35:08.204+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:35:08.205+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:35:08.205+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:35:09.110+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:35:09.108+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:35:09.110+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:35:09.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.932 seconds
[2023-07-07T03:35:39.376+0000] {processor.py:157} INFO - Started process (PID=3915) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:35:39.382+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:35:39.382+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:35:39.382+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:35:40.321+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:35:40.319+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:35:40.322+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:35:40.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.960 seconds
[2023-07-07T03:36:10.552+0000] {processor.py:157} INFO - Started process (PID=3938) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:36:10.557+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:36:10.557+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:36:10.557+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:36:11.481+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:36:11.478+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:36:11.481+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:36:11.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.948 seconds
[2023-07-07T03:36:41.733+0000] {processor.py:157} INFO - Started process (PID=3961) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:36:41.744+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:36:41.745+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:36:41.745+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:36:42.650+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:36:42.648+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:36:42.651+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:36:42.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.936 seconds
[2023-07-07T03:37:12.959+0000] {processor.py:157} INFO - Started process (PID=3984) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:37:12.967+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:37:12.967+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:37:12.967+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:37:13.901+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:37:13.898+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:37:13.901+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:37:13.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.955 seconds
[2023-07-07T03:37:44.215+0000] {processor.py:157} INFO - Started process (PID=4007) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:37:44.220+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:37:44.221+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:37:44.220+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:37:45.166+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:37:45.164+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:37:45.167+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:37:45.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.967 seconds
[2023-07-07T03:38:15.396+0000] {processor.py:157} INFO - Started process (PID=4030) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:38:15.407+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:38:15.407+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:38:15.407+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:38:16.339+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:38:16.337+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:38:16.340+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:38:16.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.964 seconds
[2023-07-07T03:38:46.598+0000] {processor.py:157} INFO - Started process (PID=4053) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:38:46.605+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:38:46.605+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:38:46.605+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:38:47.527+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:38:47.524+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:38:47.528+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:38:47.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.948 seconds
[2023-07-07T03:39:17.837+0000] {processor.py:157} INFO - Started process (PID=4076) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:39:17.842+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:39:17.843+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:39:17.843+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:39:18.802+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:39:18.800+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:39:18.803+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:39:18.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.981 seconds
[2023-07-07T03:39:49.036+0000] {processor.py:157} INFO - Started process (PID=4099) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:39:49.041+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:39:49.042+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:39:49.042+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:39:49.993+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:39:49.991+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:39:49.994+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:39:50.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.973 seconds
[2023-07-07T03:40:20.219+0000] {processor.py:157} INFO - Started process (PID=4122) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:40:20.230+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:40:20.231+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:40:20.231+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:40:21.090+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:40:21.088+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:40:21.090+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:40:21.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.891 seconds
[2023-07-07T03:40:51.315+0000] {processor.py:157} INFO - Started process (PID=4145) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:40:51.320+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:40:51.320+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:40:51.320+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:40:52.180+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:40:52.178+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:40:52.181+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:40:52.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.883 seconds
[2023-07-07T03:41:22.520+0000] {processor.py:157} INFO - Started process (PID=4168) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:41:22.525+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:41:22.526+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:41:22.526+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:41:23.412+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:41:23.410+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:41:23.413+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:41:23.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.911 seconds
[2023-07-07T03:41:53.633+0000] {processor.py:157} INFO - Started process (PID=4191) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:41:53.638+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:41:53.639+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:41:53.639+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:41:54.524+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:41:54.522+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:41:54.525+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:41:54.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.910 seconds
[2023-07-07T03:42:24.925+0000] {processor.py:157} INFO - Started process (PID=4216) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:42:24.930+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:42:24.931+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:42:24.931+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:42:25.824+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:42:25.822+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:42:25.825+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:42:25.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.918 seconds
[2023-07-07T03:42:56.047+0000] {processor.py:157} INFO - Started process (PID=4239) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:42:56.052+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:42:56.052+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:42:56.052+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:42:56.909+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:42:56.907+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:42:56.910+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:42:56.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.879 seconds
[2023-07-07T03:43:27.229+0000] {processor.py:157} INFO - Started process (PID=4262) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:43:27.241+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:43:27.242+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:43:27.242+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:43:28.104+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:43:28.102+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:43:28.104+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:43:28.121+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.895 seconds
[2023-07-07T03:43:58.325+0000] {processor.py:157} INFO - Started process (PID=4285) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:43:58.331+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:43:58.332+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:43:58.332+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:43:59.242+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:43:59.240+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:43:59.242+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:43:59.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.932 seconds
[2023-07-07T03:44:29.523+0000] {processor.py:157} INFO - Started process (PID=4308) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:44:29.528+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:44:29.529+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:44:29.529+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:44:30.400+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:44:30.398+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:44:30.401+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:44:30.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.896 seconds
[2023-07-07T03:45:00.648+0000] {processor.py:157} INFO - Started process (PID=4331) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:45:00.653+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:45:00.653+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:45:00.653+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:45:01.520+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:45:01.518+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:45:01.520+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:45:01.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.888 seconds
[2023-07-07T03:45:31.828+0000] {processor.py:157} INFO - Started process (PID=4354) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:45:31.836+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:45:31.837+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:45:31.837+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:45:32.738+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:45:32.736+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:45:32.738+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:45:32.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.931 seconds
[2023-07-07T03:46:02.985+0000] {processor.py:157} INFO - Started process (PID=4377) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:46:02.991+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:46:02.991+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:46:02.991+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:46:03.848+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:46:03.846+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:46:03.849+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:46:03.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.884 seconds
[2023-07-07T03:46:34.168+0000] {processor.py:157} INFO - Started process (PID=4400) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:46:34.175+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:46:34.176+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:46:34.176+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:46:35.035+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:46:35.033+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:46:35.036+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:46:35.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.883 seconds
[2023-07-07T03:47:05.338+0000] {processor.py:157} INFO - Started process (PID=4423) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:47:05.347+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:47:05.347+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:47:05.347+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:47:06.201+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:47:06.198+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:47:06.201+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:47:06.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.883 seconds
[2023-07-07T03:47:36.515+0000] {processor.py:157} INFO - Started process (PID=4446) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:47:36.524+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:47:36.525+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:47:36.525+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:47:37.414+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:47:37.412+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:47:37.414+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:47:37.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.918 seconds
[2023-07-07T03:48:07.699+0000] {processor.py:157} INFO - Started process (PID=4476) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:48:07.704+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:48:07.704+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:48:07.704+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:48:08.561+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:48:08.559+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:48:08.561+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:48:08.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.882 seconds
[2023-07-07T03:48:38.842+0000] {processor.py:157} INFO - Started process (PID=4499) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:48:38.847+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:48:38.848+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:48:38.848+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:48:39.703+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:48:39.701+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:48:39.704+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:48:39.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.875 seconds
[2023-07-07T03:49:09.994+0000] {processor.py:157} INFO - Started process (PID=4522) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:49:10.000+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:49:10.000+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:49:10.000+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:49:10.856+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:49:10.854+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:49:10.857+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:49:10.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.878 seconds
[2023-07-07T03:49:41.129+0000] {processor.py:157} INFO - Started process (PID=4545) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:49:41.136+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:49:41.136+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:49:41.136+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:49:42.027+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:49:42.024+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:49:42.027+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:49:42.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.913 seconds
[2023-07-07T03:50:12.355+0000] {processor.py:157} INFO - Started process (PID=4568) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:50:12.366+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:50:12.366+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:50:12.366+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:50:13.272+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:50:13.270+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:50:13.273+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:50:13.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.932 seconds
[2023-07-07T03:50:31.334+0000] {processor.py:157} INFO - Started process (PID=32) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:50:31.335+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:50:31.335+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:50:31.335+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:50:32.899+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:50:32.895+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:50:32.899+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:50:32.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.580 seconds
[2023-07-07T03:51:03.724+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:51:03.731+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:51:03.731+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:51:03.731+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:51:04.562+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:51:04.560+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:51:04.562+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:51:04.575+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.853 seconds
[2023-07-07T03:51:34.749+0000] {processor.py:157} INFO - Started process (PID=80) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:51:34.754+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:51:34.754+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:51:34.754+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:51:35.645+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:51:35.642+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:51:35.645+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:51:35.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.910 seconds
[2023-07-07T03:52:05.939+0000] {processor.py:157} INFO - Started process (PID=103) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:52:05.951+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:52:05.952+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:52:05.952+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:52:06.784+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:52:06.782+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:52:06.784+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:52:06.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.865 seconds
[2023-07-07T03:52:37.139+0000] {processor.py:157} INFO - Started process (PID=126) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:52:37.145+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:52:37.145+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:52:37.145+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:52:37.933+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:52:37.931+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:52:37.934+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:52:37.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.814 seconds
[2023-07-07T03:53:08.349+0000] {processor.py:157} INFO - Started process (PID=149) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:53:08.354+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:53:08.355+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:53:08.355+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:53:09.235+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:53:09.233+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:53:09.235+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:53:09.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.905 seconds
[2023-07-07T03:53:39.527+0000] {processor.py:157} INFO - Started process (PID=172) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:53:39.532+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:53:39.533+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:53:39.533+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:53:40.370+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:53:40.368+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:53:40.371+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:53:40.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.862 seconds
[2023-07-07T03:54:10.734+0000] {processor.py:157} INFO - Started process (PID=195) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:54:10.740+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:54:10.740+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:54:10.740+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:54:11.585+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:54:11.581+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:54:11.586+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:54:11.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.867 seconds
[2023-07-07T03:54:41.935+0000] {processor.py:157} INFO - Started process (PID=219) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:54:41.940+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:54:41.940+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:54:41.940+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:54:42.759+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:54:42.757+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:54:42.760+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:54:42.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.844 seconds
[2023-07-07T03:55:13.198+0000] {processor.py:157} INFO - Started process (PID=242) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:55:13.203+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:55:13.203+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:55:13.203+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:55:14.041+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:55:14.039+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:55:14.042+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:55:14.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.863 seconds
[2023-07-07T03:55:44.258+0000] {processor.py:157} INFO - Started process (PID=265) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:55:44.263+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:55:44.264+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:55:44.264+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:55:45.093+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:55:45.091+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:55:45.093+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:55:45.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.854 seconds
[2023-07-07T03:56:15.436+0000] {processor.py:157} INFO - Started process (PID=288) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:56:15.442+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:56:15.442+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:56:15.442+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:56:16.285+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:56:16.282+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:56:16.286+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:56:16.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.869 seconds
[2023-07-07T03:56:46.625+0000] {processor.py:157} INFO - Started process (PID=311) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:56:46.631+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:56:46.631+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:56:46.631+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:56:47.450+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:56:47.448+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:56:47.451+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:56:47.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.849 seconds
[2023-07-07T03:57:17.793+0000] {processor.py:157} INFO - Started process (PID=334) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:57:17.799+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:57:17.799+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:57:17.799+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:57:18.580+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:57:18.576+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:57:18.580+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:57:18.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.806 seconds
[2023-07-07T03:57:49.009+0000] {processor.py:157} INFO - Started process (PID=357) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:57:49.016+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:57:49.017+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:57:49.017+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:57:49.804+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:57:49.802+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:57:49.805+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:57:49.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.808 seconds
[2023-07-07T03:58:20.198+0000] {processor.py:157} INFO - Started process (PID=379) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:58:20.207+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:58:20.207+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:58:20.207+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:58:21.040+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:58:21.037+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:58:21.040+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:58:21.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.857 seconds
[2023-07-07T03:58:51.373+0000] {processor.py:157} INFO - Started process (PID=402) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:58:51.384+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:58:51.384+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:58:51.384+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:58:52.208+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:58:52.206+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:58:52.208+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:58:52.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.854 seconds
[2023-07-07T03:59:22.554+0000] {processor.py:157} INFO - Started process (PID=425) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:59:22.561+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:59:22.561+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:59:22.561+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:59:23.383+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:59:23.381+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:59:23.383+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:59:23.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.848 seconds
[2023-07-07T03:59:53.752+0000] {processor.py:157} INFO - Started process (PID=448) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:59:53.759+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T03:59:53.759+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:59:53.759+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:59:54.599+0000] {logging_mixin.py:149} INFO - [2023-07-07T03:59:54.596+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T03:59:54.599+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T03:59:54.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.863 seconds
[2023-07-07T04:00:25.044+0000] {processor.py:157} INFO - Started process (PID=471) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:00:25.053+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:00:25.054+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:00:25.054+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:00:25.865+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:00:25.863+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:00:25.865+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:00:25.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.840 seconds
[2023-07-07T04:00:56.170+0000] {processor.py:157} INFO - Started process (PID=494) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:00:56.177+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:00:56.177+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:00:56.177+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:00:57.042+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:00:57.039+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:00:57.042+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:00:57.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.893 seconds
[2023-07-07T04:01:27.327+0000] {processor.py:157} INFO - Started process (PID=524) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:01:27.332+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:01:27.333+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:01:27.333+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:01:28.267+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:01:28.264+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:01:28.267+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:01:28.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.957 seconds
[2023-07-07T04:01:58.560+0000] {processor.py:157} INFO - Started process (PID=547) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:01:58.561+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:01:58.561+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:01:58.561+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:01:59.413+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:01:59.411+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:01:59.414+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:01:59.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.867 seconds
[2023-07-07T04:02:29.603+0000] {processor.py:157} INFO - Started process (PID=570) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:02:29.608+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:02:29.609+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:02:29.609+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:02:30.487+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:02:30.484+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:02:30.487+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:02:30.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.899 seconds
[2023-07-07T04:03:00.808+0000] {processor.py:157} INFO - Started process (PID=593) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:03:00.814+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:03:00.815+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:03:00.815+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:03:01.629+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:03:01.627+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:03:01.630+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:03:01.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.842 seconds
[2023-07-07T04:03:31.975+0000] {processor.py:157} INFO - Started process (PID=616) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:03:31.985+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:03:31.985+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:03:31.985+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:03:32.778+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:03:32.776+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:03:32.778+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:03:32.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.817 seconds
[2023-07-07T04:04:03.220+0000] {processor.py:157} INFO - Started process (PID=639) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:04:03.226+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:04:03.226+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:04:03.226+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:04:04.027+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:04:04.024+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:04:04.027+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:04:04.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.822 seconds
[2023-07-07T04:04:34.432+0000] {processor.py:157} INFO - Started process (PID=662) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:04:34.443+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:04:34.443+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:04:34.443+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:04:35.240+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:04:35.237+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:04:35.240+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:04:35.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.831 seconds
[2023-07-07T04:05:05.642+0000] {processor.py:157} INFO - Started process (PID=685) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:05:05.648+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:05:05.648+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:05:05.648+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:05:06.433+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:05:06.431+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:05:06.434+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:05:06.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.809 seconds
[2023-07-07T04:05:36.850+0000] {processor.py:157} INFO - Started process (PID=708) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:05:36.855+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:05:36.856+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:05:36.855+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:05:37.666+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:05:37.664+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:05:37.666+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:05:37.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.833 seconds
[2023-07-07T04:06:08.217+0000] {processor.py:157} INFO - Started process (PID=733) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:06:08.222+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:06:08.222+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:06:08.222+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:06:09.002+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:06:09.000+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:06:09.003+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:06:09.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.805 seconds
[2023-07-07T04:06:39.371+0000] {processor.py:157} INFO - Started process (PID=756) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:06:39.376+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:06:39.377+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:06:39.377+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:06:40.180+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:06:40.178+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:06:40.181+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:06:40.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.824 seconds
[2023-07-07T04:07:10.567+0000] {processor.py:157} INFO - Started process (PID=779) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:07:10.573+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:07:10.573+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:07:10.573+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:07:11.360+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:07:11.358+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:07:11.361+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:07:11.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.813 seconds
[2023-07-07T04:07:41.752+0000] {processor.py:157} INFO - Started process (PID=802) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:07:41.757+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:07:41.757+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:07:41.757+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:07:42.545+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:07:42.543+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:07:42.545+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:07:42.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.808 seconds
[2023-07-07T04:08:12.946+0000] {processor.py:157} INFO - Started process (PID=825) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:08:12.952+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:08:12.952+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:08:12.952+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:08:13.842+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:08:13.839+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:08:13.842+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:08:13.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.911 seconds
[2023-07-07T04:08:44.057+0000] {processor.py:157} INFO - Started process (PID=848) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:08:44.062+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:08:44.063+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:08:44.063+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:08:45.000+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:08:44.998+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:08:45.000+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:08:45.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.960 seconds
[2023-07-07T04:09:15.295+0000] {processor.py:157} INFO - Started process (PID=871) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:09:15.300+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:09:15.300+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:09:15.300+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:09:16.147+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:09:16.144+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:09:16.147+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:09:16.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.868 seconds
[2023-07-07T04:09:46.435+0000] {processor.py:157} INFO - Started process (PID=894) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:09:46.442+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:09:46.443+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:09:46.443+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:09:47.249+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:09:47.246+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:09:47.249+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:09:47.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.828 seconds
[2023-07-07T04:10:17.579+0000] {processor.py:157} INFO - Started process (PID=917) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:10:17.584+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:10:17.585+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:10:17.585+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:10:18.392+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:10:18.390+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:10:18.392+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:10:18.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.828 seconds
[2023-07-07T04:10:48.793+0000] {processor.py:157} INFO - Started process (PID=940) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:10:48.804+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:10:48.805+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:10:48.805+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:10:49.696+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:10:49.694+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:10:49.696+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:10:49.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.924 seconds
[2023-07-07T04:11:19.999+0000] {processor.py:157} INFO - Started process (PID=963) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:11:20.004+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:11:20.005+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:11:20.005+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:11:20.827+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:11:20.824+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:11:20.827+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:11:20.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.846 seconds
[2023-07-07T04:11:51.032+0000] {processor.py:157} INFO - Started process (PID=986) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:11:51.037+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:11:51.037+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:11:51.037+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:11:51.828+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:11:51.826+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:11:51.829+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:11:51.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.811 seconds
[2023-07-07T04:12:22.230+0000] {processor.py:157} INFO - Started process (PID=1009) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:12:22.235+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:12:22.235+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:12:22.235+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:12:23.043+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:12:23.041+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:12:23.043+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:12:23.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.834 seconds
[2023-07-07T04:12:53.398+0000] {processor.py:157} INFO - Started process (PID=1032) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:12:53.403+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:12:53.404+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:12:53.404+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:12:54.286+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:12:54.284+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:12:54.286+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:12:54.298+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.903 seconds
[2023-07-07T04:13:24.591+0000] {processor.py:157} INFO - Started process (PID=1055) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:13:24.598+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:13:24.599+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:13:24.599+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:13:25.400+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:13:25.398+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:13:25.401+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:13:25.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.829 seconds
[2023-07-07T04:13:55.765+0000] {processor.py:157} INFO - Started process (PID=1078) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:13:55.771+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:13:55.772+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:13:55.772+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:13:56.583+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:13:56.581+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:13:56.584+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:13:56.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.836 seconds
[2023-07-07T04:14:26.932+0000] {processor.py:157} INFO - Started process (PID=1101) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:14:26.937+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:14:26.938+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:14:26.938+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:14:27.756+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:14:27.754+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:14:27.756+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:14:27.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.842 seconds
[2023-07-07T04:14:58.132+0000] {processor.py:157} INFO - Started process (PID=1124) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:14:58.138+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:14:58.139+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:14:58.139+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:14:59.021+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:14:59.018+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:14:59.021+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:14:59.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.908 seconds
[2023-07-07T04:15:29.286+0000] {processor.py:157} INFO - Started process (PID=1147) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:15:29.293+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:15:29.294+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:15:29.293+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:15:30.103+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:15:30.101+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:15:30.104+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:15:30.115+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.830 seconds
[2023-07-07T04:16:00.324+0000] {processor.py:157} INFO - Started process (PID=1177) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:16:00.331+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:16:00.331+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:16:00.331+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:16:01.123+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:16:01.121+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:16:01.123+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:16:01.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.814 seconds
[2023-07-07T04:16:31.501+0000] {processor.py:157} INFO - Started process (PID=1200) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:16:31.512+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:16:31.513+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:16:31.513+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:16:32.316+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:16:32.314+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:16:32.317+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:16:32.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.830 seconds
[2023-07-07T04:17:02.773+0000] {processor.py:157} INFO - Started process (PID=1223) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:17:02.780+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:17:02.781+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:17:02.781+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:17:03.653+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:17:03.651+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:17:03.653+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:17:03.671+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.901 seconds
[2023-07-07T04:17:33.936+0000] {processor.py:157} INFO - Started process (PID=1246) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:17:33.941+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:17:33.942+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:17:33.942+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:17:34.730+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:17:34.728+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:17:34.731+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:17:34.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.813 seconds
[2023-07-07T04:18:05.039+0000] {processor.py:157} INFO - Started process (PID=1269) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:18:05.045+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:18:05.045+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:18:05.045+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:18:05.834+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:18:05.832+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:18:05.835+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:18:05.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.810 seconds
[2023-07-07T04:18:36.124+0000] {processor.py:157} INFO - Started process (PID=1292) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:18:36.130+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:18:36.131+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:18:36.130+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:18:36.945+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:18:36.943+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:18:36.946+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:18:36.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.836 seconds
[2023-07-07T04:19:07.217+0000] {processor.py:157} INFO - Started process (PID=1315) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:19:07.224+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:19:07.224+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:19:07.224+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:19:08.097+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:19:08.094+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:19:08.097+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:19:08.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.897 seconds
[2023-07-07T04:19:38.395+0000] {processor.py:157} INFO - Started process (PID=1338) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:19:38.402+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:19:38.402+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:19:38.402+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:19:39.226+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:19:39.224+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:19:39.227+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:19:39.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.851 seconds
[2023-07-07T04:20:09.531+0000] {processor.py:157} INFO - Started process (PID=1361) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:20:09.532+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:20:09.532+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:20:09.532+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:20:10.337+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:20:10.335+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:20:10.337+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:20:10.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.831 seconds
[2023-07-07T04:20:40.688+0000] {processor.py:157} INFO - Started process (PID=1384) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:20:40.693+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:20:40.693+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:20:40.693+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:20:41.485+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:20:41.483+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:20:41.485+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:20:41.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.817 seconds
[2023-07-07T04:21:11.818+0000] {processor.py:157} INFO - Started process (PID=1407) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:21:11.824+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:21:11.824+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:21:11.824+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:21:12.715+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:21:12.712+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:21:12.715+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:21:12.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.915 seconds
[2023-07-07T04:21:42.996+0000] {processor.py:157} INFO - Started process (PID=1432) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:21:43.002+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:21:43.002+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:21:43.002+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:21:43.782+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:21:43.780+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:21:43.782+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:21:43.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.803 seconds
[2023-07-07T04:22:14.087+0000] {processor.py:157} INFO - Started process (PID=1455) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:22:14.094+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:22:14.094+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:22:14.094+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:22:14.879+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:22:14.877+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:22:14.879+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:22:14.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.808 seconds
[2023-07-07T04:22:45.160+0000] {processor.py:157} INFO - Started process (PID=1478) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:22:45.172+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:22:45.172+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:22:45.172+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:22:46.024+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:22:46.022+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:22:46.025+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:22:46.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.878 seconds
[2023-07-07T04:23:16.303+0000] {processor.py:157} INFO - Started process (PID=1501) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:23:16.308+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:23:16.309+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:23:16.308+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:23:17.175+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:23:17.173+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:23:17.175+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:23:17.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.891 seconds
[2023-07-07T04:23:47.422+0000] {processor.py:157} INFO - Started process (PID=1524) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:23:47.433+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:23:47.433+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:23:47.433+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:23:48.291+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:23:48.288+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:23:48.291+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:23:48.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.888 seconds
[2023-07-07T04:24:18.598+0000] {processor.py:157} INFO - Started process (PID=1547) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:24:18.603+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:24:18.603+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:24:18.603+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:24:19.388+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:24:19.386+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:24:19.389+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:24:19.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.806 seconds
[2023-07-07T04:24:49.747+0000] {processor.py:157} INFO - Started process (PID=1570) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:24:49.752+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:24:49.752+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:24:49.752+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:24:50.606+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:24:50.604+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:24:50.607+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:24:50.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.879 seconds
[2023-07-07T04:25:20.842+0000] {processor.py:157} INFO - Started process (PID=1593) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:25:20.847+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:25:20.848+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:25:20.848+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:25:21.708+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:25:21.706+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:25:21.709+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:25:21.726+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.886 seconds
[2023-07-07T04:25:52.021+0000] {processor.py:157} INFO - Started process (PID=1616) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:25:52.026+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:25:52.026+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:25:52.026+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:25:52.877+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:25:52.874+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:25:52.877+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:25:52.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.876 seconds
[2023-07-07T04:26:23.167+0000] {processor.py:157} INFO - Started process (PID=1639) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:26:23.173+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:26:23.174+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:26:23.174+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:26:23.957+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:26:23.955+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:26:23.957+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:26:23.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.809 seconds
[2023-07-07T04:26:54.334+0000] {processor.py:157} INFO - Started process (PID=1662) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:26:54.341+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:26:54.341+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:26:54.341+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:26:55.201+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:26:55.199+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:26:55.202+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:26:55.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.887 seconds
[2023-07-07T04:27:25.501+0000] {processor.py:157} INFO - Started process (PID=1692) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:27:25.507+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:27:25.508+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:27:25.508+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:27:26.371+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:27:26.368+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:27:26.372+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:27:26.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.891 seconds
[2023-07-07T04:27:56.653+0000] {processor.py:157} INFO - Started process (PID=1716) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:27:56.659+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:27:56.659+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:27:56.659+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:27:57.536+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:27:57.534+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:27:57.536+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:27:57.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.900 seconds
[2023-07-07T04:28:27.840+0000] {processor.py:157} INFO - Started process (PID=1739) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:28:27.846+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:28:27.847+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:28:27.846+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:28:28.665+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:28:28.663+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:28:28.665+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:28:28.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.840 seconds
[2023-07-07T04:28:58.978+0000] {processor.py:157} INFO - Started process (PID=1763) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:28:58.984+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:28:58.984+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:28:58.984+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:28:59.852+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:28:59.849+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:28:59.852+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:28:59.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.894 seconds
[2023-07-07T04:29:30.163+0000] {processor.py:157} INFO - Started process (PID=1786) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:29:30.165+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:29:30.166+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:29:30.166+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:29:30.992+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:29:30.990+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:29:30.993+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:29:31.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.858 seconds
[2023-07-07T04:30:01.239+0000] {processor.py:157} INFO - Started process (PID=1809) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:30:01.247+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:30:01.247+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:30:01.247+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:30:02.132+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:30:02.129+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:30:02.132+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:30:02.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.913 seconds
[2023-07-07T04:30:32.462+0000] {processor.py:157} INFO - Started process (PID=1832) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:30:32.469+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:30:32.469+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:30:32.469+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:30:33.257+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:30:33.255+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:30:33.257+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:30:33.272+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.812 seconds
[2023-07-07T04:31:03.489+0000] {processor.py:157} INFO - Started process (PID=1865) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:31:03.496+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:31:03.496+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:31:03.496+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:31:04.347+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:31:04.345+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:31:04.347+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:31:04.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.877 seconds
[2023-07-07T04:31:34.595+0000] {processor.py:157} INFO - Started process (PID=1888) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:31:34.601+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:31:34.601+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:31:34.601+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:31:35.392+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:31:35.390+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:31:35.392+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:31:35.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.816 seconds
[2023-07-07T04:32:05.868+0000] {processor.py:157} INFO - Started process (PID=1935) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:32:05.877+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:32:05.877+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:32:05.877+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:32:06.734+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:32:06.732+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:32:06.735+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:32:06.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.887 seconds
[2023-07-07T04:32:37.042+0000] {processor.py:157} INFO - Started process (PID=1958) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:32:37.048+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:32:37.048+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:32:37.048+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:32:37.843+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:32:37.841+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:32:37.844+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:32:37.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.817 seconds
[2023-07-07T04:33:08.089+0000] {processor.py:157} INFO - Started process (PID=2000) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:33:08.100+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:33:08.101+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:33:08.101+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:33:08.975+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:33:08.972+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:33:08.975+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:33:09.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.915 seconds
[2023-07-07T04:33:39.309+0000] {processor.py:157} INFO - Started process (PID=2025) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:33:39.314+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:33:39.315+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:33:39.314+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:33:40.099+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:33:40.097+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:33:40.099+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:33:40.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.811 seconds
[2023-07-07T04:34:10.336+0000] {processor.py:157} INFO - Started process (PID=2048) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:34:10.343+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:34:10.343+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:34:10.343+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:34:11.188+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:34:11.186+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:34:11.188+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:34:11.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.866 seconds
[2023-07-07T04:34:41.539+0000] {processor.py:157} INFO - Started process (PID=2071) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:34:41.546+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:34:41.546+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:34:41.546+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:34:42.349+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:34:42.346+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:34:42.349+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:34:42.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.833 seconds
[2023-07-07T04:35:12.848+0000] {processor.py:157} INFO - Started process (PID=2094) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:35:12.854+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:35:12.854+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:35:12.854+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:35:13.717+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:35:13.715+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:35:13.717+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:35:13.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.892 seconds
[2023-07-07T04:35:44.033+0000] {processor.py:157} INFO - Started process (PID=2119) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:35:44.039+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:35:44.040+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:35:44.039+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:35:44.832+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:35:44.828+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:35:44.832+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:35:44.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.815 seconds
[2023-07-07T04:36:15.050+0000] {processor.py:157} INFO - Started process (PID=2144) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:36:15.055+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:36:15.055+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:36:15.055+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:36:15.919+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:36:15.917+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:36:15.919+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:36:15.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.889 seconds
[2023-07-07T04:36:46.222+0000] {processor.py:157} INFO - Started process (PID=2167) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:36:46.229+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:36:46.229+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:36:46.229+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:36:47.047+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:36:47.045+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:36:47.048+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:36:47.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.844 seconds
[2023-07-07T04:37:17.516+0000] {processor.py:157} INFO - Started process (PID=2194) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:37:17.517+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:37:17.517+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:37:17.517+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:37:18.367+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:37:18.365+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 115, in run
    output = json.loads(stdout)
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 42, in get_path
    path = SeleniumManager().driver_location(options) if path is None else path
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 96, in driver_location
    result = self.run(args)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py", line 118, in run
    raise WebDriverException(f"Unsuccessful command executed: {command}; {err}")
selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 47, in __init__
    self.service.path = DriverFinder.get_path(self.service, self.options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/driver_finder.py", line 44, in get_path
    raise NoSuchDriverException(f"Unable to obtain {service.path} using Selenium Manager; {err}")
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain chromedriver using Selenium Manager; Message: Unsuccessful command executed: /home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome --output json; Expecting value: line 1 column 1 (char 0)
; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2023-07-07T04:37:18.368+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:37:18.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.872 seconds
[2023-07-07T04:37:55.837+0000] {processor.py:157} INFO - Started process (PID=32) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:37:55.837+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:37:55.838+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:37:55.838+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:37:57.911+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:37:57.909+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55bf66a564e3 <unknown>
#1 0x55bf66785c76 <unknown>
#2 0x55bf667aed78 <unknown>
#3 0x55bf667ab029 <unknown>
#4 0x55bf667e9ccc <unknown>
#5 0x55bf667e947f <unknown>
#6 0x55bf667e0de3 <unknown>
#7 0x55bf667b62dd <unknown>
#8 0x55bf667b734e <unknown>
#9 0x55bf66a163e4 <unknown>
#10 0x55bf66a1a3d7 <unknown>
#11 0x55bf66a24b20 <unknown>
#12 0x55bf66a1b023 <unknown>
#13 0x55bf669e91aa <unknown>
#14 0x55bf66a3f6b8 <unknown>
#15 0x55bf66a3f847 <unknown>
#16 0x55bf66a4f243 <unknown>
#17 0x7f59519c5ea7 start_thread
[2023-07-07T04:37:57.911+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:37:57.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.089 seconds
[2023-07-07T04:38:28.154+0000] {processor.py:157} INFO - Started process (PID=84) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:38:28.164+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:38:28.165+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:38:28.165+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:38:29.547+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:38:29.546+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5556bfc7b4e3 <unknown>
#1 0x5556bf9aac76 <unknown>
#2 0x5556bf9d3d78 <unknown>
#3 0x5556bf9d0029 <unknown>
#4 0x5556bfa0eccc <unknown>
#5 0x5556bfa0e47f <unknown>
#6 0x5556bfa05de3 <unknown>
#7 0x5556bf9db2dd <unknown>
#8 0x5556bf9dc34e <unknown>
#9 0x5556bfc3b3e4 <unknown>
#10 0x5556bfc3f3d7 <unknown>
#11 0x5556bfc49b20 <unknown>
#12 0x5556bfc40023 <unknown>
#13 0x5556bfc0e1aa <unknown>
#14 0x5556bfc646b8 <unknown>
#15 0x5556bfc64847 <unknown>
#16 0x5556bfc74243 <unknown>
#17 0x7fdbe792eea7 start_thread
[2023-07-07T04:38:29.548+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:38:29.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.415 seconds
[2023-07-07T04:39:00.449+0000] {processor.py:157} INFO - Started process (PID=131) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:39:00.460+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:39:00.460+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:39:00.460+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:39:01.881+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:39:01.879+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x558a513614e3 <unknown>
#1 0x558a51090c76 <unknown>
#2 0x558a510b9d78 <unknown>
#3 0x558a510b6029 <unknown>
#4 0x558a510f4ccc <unknown>
#5 0x558a510f447f <unknown>
#6 0x558a510ebde3 <unknown>
#7 0x558a510c12dd <unknown>
#8 0x558a510c234e <unknown>
#9 0x558a513213e4 <unknown>
#10 0x558a513253d7 <unknown>
#11 0x558a5132fb20 <unknown>
#12 0x558a51326023 <unknown>
#13 0x558a512f41aa <unknown>
#14 0x558a5134a6b8 <unknown>
#15 0x558a5134a847 <unknown>
#16 0x558a5135a243 <unknown>
#17 0x7f909ebc0ea7 start_thread
[2023-07-07T04:39:01.882+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:39:01.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.450 seconds
[2023-07-07T04:39:32.635+0000] {processor.py:157} INFO - Started process (PID=193) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:39:32.642+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:39:32.642+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:39:32.642+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:39:34.205+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:39:34.204+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55ef5ad7c4e3 <unknown>
#1 0x55ef5aaabc76 <unknown>
#2 0x55ef5aad4d78 <unknown>
#3 0x55ef5aad1029 <unknown>
#4 0x55ef5ab0fccc <unknown>
#5 0x55ef5ab0f47f <unknown>
#6 0x55ef5ab06de3 <unknown>
#7 0x55ef5aadc2dd <unknown>
#8 0x55ef5aadd34e <unknown>
#9 0x55ef5ad3c3e4 <unknown>
#10 0x55ef5ad403d7 <unknown>
#11 0x55ef5ad4ab20 <unknown>
#12 0x55ef5ad41023 <unknown>
#13 0x55ef5ad0f1aa <unknown>
#14 0x55ef5ad656b8 <unknown>
#15 0x55ef5ad65847 <unknown>
#16 0x55ef5ad75243 <unknown>
#17 0x7fa92a72eea7 start_thread
[2023-07-07T04:39:34.206+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:39:34.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.586 seconds
[2023-07-07T04:40:04.838+0000] {processor.py:157} INFO - Started process (PID=234) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:40:04.844+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:40:04.845+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:40:04.845+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:40:06.252+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:40:06.250+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5559fee8a4e3 <unknown>
#1 0x5559febb9c76 <unknown>
#2 0x5559febe2d78 <unknown>
#3 0x5559febdf029 <unknown>
#4 0x5559fec1dccc <unknown>
#5 0x5559fec1d47f <unknown>
#6 0x5559fec14de3 <unknown>
#7 0x5559febea2dd <unknown>
#8 0x5559febeb34e <unknown>
#9 0x5559fee4a3e4 <unknown>
#10 0x5559fee4e3d7 <unknown>
#11 0x5559fee58b20 <unknown>
#12 0x5559fee4f023 <unknown>
#13 0x5559fee1d1aa <unknown>
#14 0x5559fee736b8 <unknown>
#15 0x5559fee73847 <unknown>
#16 0x5559fee83243 <unknown>
#17 0x7fe408f16ea7 start_thread
[2023-07-07T04:40:06.252+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:40:06.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.427 seconds
[2023-07-07T04:40:37.065+0000] {processor.py:157} INFO - Started process (PID=275) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:40:37.076+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:40:37.076+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:40:37.076+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:40:38.481+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:40:38.480+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55a3986564e3 <unknown>
#1 0x55a398385c76 <unknown>
#2 0x55a3983aed78 <unknown>
#3 0x55a3983ab029 <unknown>
#4 0x55a3983e9ccc <unknown>
#5 0x55a3983e947f <unknown>
#6 0x55a3983e0de3 <unknown>
#7 0x55a3983b62dd <unknown>
#8 0x55a3983b734e <unknown>
#9 0x55a3986163e4 <unknown>
#10 0x55a39861a3d7 <unknown>
#11 0x55a398624b20 <unknown>
#12 0x55a39861b023 <unknown>
#13 0x55a3985e91aa <unknown>
#14 0x55a39863f6b8 <unknown>
#15 0x55a39863f847 <unknown>
#16 0x55a39864f243 <unknown>
#17 0x7f3de225dea7 start_thread
[2023-07-07T04:40:38.482+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:40:38.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.434 seconds
[2023-07-07T04:41:09.361+0000] {processor.py:157} INFO - Started process (PID=316) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:41:09.367+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:41:09.368+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:41:09.368+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:41:10.753+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:41:10.751+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55e9903dd4e3 <unknown>
#1 0x55e99010cc76 <unknown>
#2 0x55e990135d78 <unknown>
#3 0x55e990132029 <unknown>
#4 0x55e990170ccc <unknown>
#5 0x55e99017047f <unknown>
#6 0x55e990167de3 <unknown>
#7 0x55e99013d2dd <unknown>
#8 0x55e99013e34e <unknown>
#9 0x55e99039d3e4 <unknown>
#10 0x55e9903a13d7 <unknown>
#11 0x55e9903abb20 <unknown>
#12 0x55e9903a2023 <unknown>
#13 0x55e9903701aa <unknown>
#14 0x55e9903c66b8 <unknown>
#15 0x55e9903c6847 <unknown>
#16 0x55e9903d6243 <unknown>
#17 0x7f1a669ccea7 start_thread
[2023-07-07T04:41:10.754+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:41:10.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.411 seconds
[2023-07-07T04:41:41.617+0000] {processor.py:157} INFO - Started process (PID=483) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:41:41.618+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:41:41.618+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:41:41.618+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:41:43.029+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:41:43.027+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5595428484e3 <unknown>
#1 0x559542577c76 <unknown>
#2 0x5595425a0d78 <unknown>
#3 0x55954259d029 <unknown>
#4 0x5595425dbccc <unknown>
#5 0x5595425db47f <unknown>
#6 0x5595425d2de3 <unknown>
#7 0x5595425a82dd <unknown>
#8 0x5595425a934e <unknown>
#9 0x5595428083e4 <unknown>
#10 0x55954280c3d7 <unknown>
#11 0x559542816b20 <unknown>
#12 0x55954280d023 <unknown>
#13 0x5595427db1aa <unknown>
#14 0x5595428316b8 <unknown>
#15 0x559542831847 <unknown>
#16 0x559542841243 <unknown>
#17 0x7f10c8a5aea7 start_thread
[2023-07-07T04:41:43.030+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:41:43.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.440 seconds
[2023-07-07T04:42:13.796+0000] {processor.py:157} INFO - Started process (PID=524) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:42:13.805+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:42:13.805+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:42:13.805+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:42:15.211+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:42:15.210+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55b5cbc0b4e3 <unknown>
#1 0x55b5cb93ac76 <unknown>
#2 0x55b5cb963d78 <unknown>
#3 0x55b5cb960029 <unknown>
#4 0x55b5cb99eccc <unknown>
#5 0x55b5cb99e47f <unknown>
#6 0x55b5cb995de3 <unknown>
#7 0x55b5cb96b2dd <unknown>
#8 0x55b5cb96c34e <unknown>
#9 0x55b5cbbcb3e4 <unknown>
#10 0x55b5cbbcf3d7 <unknown>
#11 0x55b5cbbd9b20 <unknown>
#12 0x55b5cbbd0023 <unknown>
#13 0x55b5cbb9e1aa <unknown>
#14 0x55b5cbbf46b8 <unknown>
#15 0x55b5cbbf4847 <unknown>
#16 0x55b5cbc04243 <unknown>
#17 0x7f68d47dcea7 start_thread
[2023-07-07T04:42:15.212+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:42:15.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.433 seconds
[2023-07-07T04:42:45.990+0000] {processor.py:157} INFO - Started process (PID=565) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:42:45.995+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:42:45.995+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:42:45.995+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:42:47.383+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:42:47.382+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x558f647494e3 <unknown>
#1 0x558f64478c76 <unknown>
#2 0x558f644a1d78 <unknown>
#3 0x558f6449e029 <unknown>
#4 0x558f644dcccc <unknown>
#5 0x558f644dc47f <unknown>
#6 0x558f644d3de3 <unknown>
#7 0x558f644a92dd <unknown>
#8 0x558f644aa34e <unknown>
#9 0x558f647093e4 <unknown>
#10 0x558f6470d3d7 <unknown>
#11 0x558f64717b20 <unknown>
#12 0x558f6470e023 <unknown>
#13 0x558f646dc1aa <unknown>
#14 0x558f647326b8 <unknown>
#15 0x558f64732847 <unknown>
#16 0x558f64742243 <unknown>
#17 0x7fc8a078dea7 start_thread
[2023-07-07T04:42:47.384+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:42:47.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.414 seconds
[2023-07-07T04:43:18.285+0000] {processor.py:157} INFO - Started process (PID=606) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:43:18.292+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:43:18.292+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:43:18.292+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:43:19.681+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:43:19.679+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x56311867b4e3 <unknown>
#1 0x5631183aac76 <unknown>
#2 0x5631183d3d78 <unknown>
#3 0x5631183d0029 <unknown>
#4 0x56311840eccc <unknown>
#5 0x56311840e47f <unknown>
#6 0x563118405de3 <unknown>
#7 0x5631183db2dd <unknown>
#8 0x5631183dc34e <unknown>
#9 0x56311863b3e4 <unknown>
#10 0x56311863f3d7 <unknown>
#11 0x563118649b20 <unknown>
#12 0x563118640023 <unknown>
#13 0x56311860e1aa <unknown>
#14 0x5631186646b8 <unknown>
#15 0x563118664847 <unknown>
#16 0x563118674243 <unknown>
#17 0x7f670e05bea7 start_thread
[2023-07-07T04:43:19.681+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:43:19.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.413 seconds
[2023-07-07T04:43:50.585+0000] {processor.py:157} INFO - Started process (PID=647) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:43:50.590+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:43:50.591+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:43:50.591+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:43:51.988+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:43:51.986+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5654eb17b4e3 <unknown>
#1 0x5654eaeaac76 <unknown>
#2 0x5654eaed3d78 <unknown>
#3 0x5654eaed0029 <unknown>
#4 0x5654eaf0eccc <unknown>
#5 0x5654eaf0e47f <unknown>
#6 0x5654eaf05de3 <unknown>
#7 0x5654eaedb2dd <unknown>
#8 0x5654eaedc34e <unknown>
#9 0x5654eb13b3e4 <unknown>
#10 0x5654eb13f3d7 <unknown>
#11 0x5654eb149b20 <unknown>
#12 0x5654eb140023 <unknown>
#13 0x5654eb10e1aa <unknown>
#14 0x5654eb1646b8 <unknown>
#15 0x5654eb164847 <unknown>
#16 0x5654eb174243 <unknown>
#17 0x7f8396344ea7 start_thread
[2023-07-07T04:43:51.988+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:43:52.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.418 seconds
[2023-07-07T04:44:22.793+0000] {processor.py:157} INFO - Started process (PID=695) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:44:22.802+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:44:22.802+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:44:22.802+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:44:24.194+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:44:24.193+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5643510104e3 <unknown>
#1 0x564350d3fc76 <unknown>
#2 0x564350d68d78 <unknown>
#3 0x564350d65029 <unknown>
#4 0x564350da3ccc <unknown>
#5 0x564350da347f <unknown>
#6 0x564350d9ade3 <unknown>
#7 0x564350d702dd <unknown>
#8 0x564350d7134e <unknown>
#9 0x564350fd03e4 <unknown>
#10 0x564350fd43d7 <unknown>
#11 0x564350fdeb20 <unknown>
#12 0x564350fd5023 <unknown>
#13 0x564350fa31aa <unknown>
#14 0x564350ff96b8 <unknown>
#15 0x564350ff9847 <unknown>
#16 0x564351009243 <unknown>
#17 0x7f43ebeedea7 start_thread
[2023-07-07T04:44:24.195+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:44:24.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.417 seconds
[2023-07-07T04:44:54.988+0000] {processor.py:157} INFO - Started process (PID=736) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:44:54.995+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:44:54.995+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:44:54.995+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:44:56.384+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:44:56.382+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5625384394e3 <unknown>
#1 0x562538168c76 <unknown>
#2 0x562538191d78 <unknown>
#3 0x56253818e029 <unknown>
#4 0x5625381ccccc <unknown>
#5 0x5625381cc47f <unknown>
#6 0x5625381c3de3 <unknown>
#7 0x5625381992dd <unknown>
#8 0x56253819a34e <unknown>
#9 0x5625383f93e4 <unknown>
#10 0x5625383fd3d7 <unknown>
#11 0x562538407b20 <unknown>
#12 0x5625383fe023 <unknown>
#13 0x5625383cc1aa <unknown>
#14 0x5625384226b8 <unknown>
#15 0x562538422847 <unknown>
#16 0x562538432243 <unknown>
#17 0x7fd9a79c7ea7 start_thread
[2023-07-07T04:44:56.385+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:44:56.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.413 seconds
[2023-07-07T04:45:27.277+0000] {processor.py:157} INFO - Started process (PID=777) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:45:27.288+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:45:27.289+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:45:27.289+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:45:28.676+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:45:28.674+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55860d68a4e3 <unknown>
#1 0x55860d3b9c76 <unknown>
#2 0x55860d3e2d78 <unknown>
#3 0x55860d3df029 <unknown>
#4 0x55860d41dccc <unknown>
#5 0x55860d41d47f <unknown>
#6 0x55860d414de3 <unknown>
#7 0x55860d3ea2dd <unknown>
#8 0x55860d3eb34e <unknown>
#9 0x55860d64a3e4 <unknown>
#10 0x55860d64e3d7 <unknown>
#11 0x55860d658b20 <unknown>
#12 0x55860d64f023 <unknown>
#13 0x55860d61d1aa <unknown>
#14 0x55860d6736b8 <unknown>
#15 0x55860d673847 <unknown>
#16 0x55860d683243 <unknown>
#17 0x7fa9a0c60ea7 start_thread
[2023-07-07T04:45:28.677+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:45:28.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.419 seconds
[2023-07-07T04:45:59.477+0000] {processor.py:157} INFO - Started process (PID=850) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:45:59.482+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:45:59.483+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:45:59.483+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:46:00.888+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:46:00.886+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5596c1c604e3 <unknown>
#1 0x5596c198fc76 <unknown>
#2 0x5596c19b8d78 <unknown>
#3 0x5596c19b5029 <unknown>
#4 0x5596c19f3ccc <unknown>
#5 0x5596c19f347f <unknown>
#6 0x5596c19eade3 <unknown>
#7 0x5596c19c02dd <unknown>
#8 0x5596c19c134e <unknown>
#9 0x5596c1c203e4 <unknown>
#10 0x5596c1c243d7 <unknown>
#11 0x5596c1c2eb20 <unknown>
#12 0x5596c1c25023 <unknown>
#13 0x5596c1bf31aa <unknown>
#14 0x5596c1c496b8 <unknown>
#15 0x5596c1c49847 <unknown>
#16 0x5596c1c59243 <unknown>
#17 0x7f605bd5cea7 start_thread
[2023-07-07T04:46:00.888+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:46:00.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.427 seconds
[2023-07-07T04:46:31.811+0000] {processor.py:157} INFO - Started process (PID=914) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:46:31.811+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:46:31.812+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:46:31.812+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:46:33.220+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:46:33.218+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55be953f34e3 <unknown>
#1 0x55be95122c76 <unknown>
#2 0x55be9514bd78 <unknown>
#3 0x55be95148029 <unknown>
#4 0x55be95186ccc <unknown>
#5 0x55be9518647f <unknown>
#6 0x55be9517dde3 <unknown>
#7 0x55be951532dd <unknown>
#8 0x55be9515434e <unknown>
#9 0x55be953b33e4 <unknown>
#10 0x55be953b73d7 <unknown>
#11 0x55be953c1b20 <unknown>
#12 0x55be953b8023 <unknown>
#13 0x55be953861aa <unknown>
#14 0x55be953dc6b8 <unknown>
#15 0x55be953dc847 <unknown>
#16 0x55be953ec243 <unknown>
#17 0x7f6519f10ea7 start_thread
[2023-07-07T04:46:33.220+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:46:33.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.429 seconds
[2023-07-07T04:47:04.049+0000] {processor.py:157} INFO - Started process (PID=959) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:47:04.055+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:47:04.055+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:47:04.055+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:47:05.457+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:47:05.455+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x56223d9664e3 <unknown>
#1 0x56223d695c76 <unknown>
#2 0x56223d6bed78 <unknown>
#3 0x56223d6bb029 <unknown>
#4 0x56223d6f9ccc <unknown>
#5 0x56223d6f947f <unknown>
#6 0x56223d6f0de3 <unknown>
#7 0x56223d6c62dd <unknown>
#8 0x56223d6c734e <unknown>
#9 0x56223d9263e4 <unknown>
#10 0x56223d92a3d7 <unknown>
#11 0x56223d934b20 <unknown>
#12 0x56223d92b023 <unknown>
#13 0x56223d8f91aa <unknown>
#14 0x56223d94f6b8 <unknown>
#15 0x56223d94f847 <unknown>
#16 0x56223d95f243 <unknown>
#17 0x7f55ebd1dea7 start_thread
[2023-07-07T04:47:05.457+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:47:05.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.427 seconds
[2023-07-07T04:47:36.288+0000] {processor.py:157} INFO - Started process (PID=1000) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:47:36.293+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:47:36.294+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:47:36.294+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:47:37.808+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:47:37.807+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55861cac74e3 <unknown>
#1 0x55861c7f6c76 <unknown>
#2 0x55861c81fd78 <unknown>
#3 0x55861c81c029 <unknown>
#4 0x55861c85accc <unknown>
#5 0x55861c85a47f <unknown>
#6 0x55861c851de3 <unknown>
#7 0x55861c8272dd <unknown>
#8 0x55861c82834e <unknown>
#9 0x55861ca873e4 <unknown>
#10 0x55861ca8b3d7 <unknown>
#11 0x55861ca95b20 <unknown>
#12 0x55861ca8c023 <unknown>
#13 0x55861ca5a1aa <unknown>
#14 0x55861cab06b8 <unknown>
#15 0x55861cab0847 <unknown>
#16 0x55861cac0243 <unknown>
#17 0x7f79aa685ea7 start_thread
[2023-07-07T04:47:37.809+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:47:37.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.539 seconds
[2023-07-07T04:48:08.617+0000] {processor.py:157} INFO - Started process (PID=1041) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:48:08.624+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:48:08.624+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:48:08.624+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:48:10.024+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:48:10.022+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55700e1a34e3 <unknown>
#1 0x55700ded2c76 <unknown>
#2 0x55700defbd78 <unknown>
#3 0x55700def8029 <unknown>
#4 0x55700df36ccc <unknown>
#5 0x55700df3647f <unknown>
#6 0x55700df2dde3 <unknown>
#7 0x55700df032dd <unknown>
#8 0x55700df0434e <unknown>
#9 0x55700e1633e4 <unknown>
#10 0x55700e1673d7 <unknown>
#11 0x55700e171b20 <unknown>
#12 0x55700e168023 <unknown>
#13 0x55700e1361aa <unknown>
#14 0x55700e18c6b8 <unknown>
#15 0x55700e18c847 <unknown>
#16 0x55700e19c243 <unknown>
#17 0x7fc4f70a4ea7 start_thread
[2023-07-07T04:48:10.025+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:48:10.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.427 seconds
[2023-07-07T04:48:40.814+0000] {processor.py:157} INFO - Started process (PID=1082) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:48:40.827+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:48:40.828+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:48:40.827+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:48:42.226+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:48:42.224+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55a5b65af4e3 <unknown>
#1 0x55a5b62dec76 <unknown>
#2 0x55a5b6307d78 <unknown>
#3 0x55a5b6304029 <unknown>
#4 0x55a5b6342ccc <unknown>
#5 0x55a5b634247f <unknown>
#6 0x55a5b6339de3 <unknown>
#7 0x55a5b630f2dd <unknown>
#8 0x55a5b631034e <unknown>
#9 0x55a5b656f3e4 <unknown>
#10 0x55a5b65733d7 <unknown>
#11 0x55a5b657db20 <unknown>
#12 0x55a5b6574023 <unknown>
#13 0x55a5b65421aa <unknown>
#14 0x55a5b65986b8 <unknown>
#15 0x55a5b6598847 <unknown>
#16 0x55a5b65a8243 <unknown>
#17 0x7f4090673ea7 start_thread
[2023-07-07T04:48:42.227+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:48:42.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.425 seconds
[2023-07-07T04:49:13.036+0000] {processor.py:157} INFO - Started process (PID=1123) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:49:13.046+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:49:13.046+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:49:13.046+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:49:14.449+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:49:14.448+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55f8e31b34e3 <unknown>
#1 0x55f8e2ee2c76 <unknown>
#2 0x55f8e2f0bd78 <unknown>
#3 0x55f8e2f08029 <unknown>
#4 0x55f8e2f46ccc <unknown>
#5 0x55f8e2f4647f <unknown>
#6 0x55f8e2f3dde3 <unknown>
#7 0x55f8e2f132dd <unknown>
#8 0x55f8e2f1434e <unknown>
#9 0x55f8e31733e4 <unknown>
#10 0x55f8e31773d7 <unknown>
#11 0x55f8e3181b20 <unknown>
#12 0x55f8e3178023 <unknown>
#13 0x55f8e31461aa <unknown>
#14 0x55f8e319c6b8 <unknown>
#15 0x55f8e319c847 <unknown>
#16 0x55f8e31ac243 <unknown>
#17 0x7f11ae405ea7 start_thread
[2023-07-07T04:49:14.450+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:49:14.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.431 seconds
[2023-07-07T04:49:45.330+0000] {processor.py:157} INFO - Started process (PID=1172) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:49:45.336+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:49:45.336+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:49:45.336+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:49:46.745+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:49:46.743+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5585c73074e3 <unknown>
#1 0x5585c7036c76 <unknown>
#2 0x5585c705fd78 <unknown>
#3 0x5585c705c029 <unknown>
#4 0x5585c709accc <unknown>
#5 0x5585c709a47f <unknown>
#6 0x5585c7091de3 <unknown>
#7 0x5585c70672dd <unknown>
#8 0x5585c706834e <unknown>
#9 0x5585c72c73e4 <unknown>
#10 0x5585c72cb3d7 <unknown>
#11 0x5585c72d5b20 <unknown>
#12 0x5585c72cc023 <unknown>
#13 0x5585c729a1aa <unknown>
#14 0x5585c72f06b8 <unknown>
#15 0x5585c72f0847 <unknown>
#16 0x5585c7300243 <unknown>
#17 0x7f344ef2eea7 start_thread
[2023-07-07T04:49:46.745+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:49:46.761+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.432 seconds
[2023-07-07T04:50:17.523+0000] {processor.py:157} INFO - Started process (PID=1213) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:50:17.529+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:50:17.529+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:50:17.529+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:50:18.951+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:50:18.949+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x562e811af4e3 <unknown>
#1 0x562e80edec76 <unknown>
#2 0x562e80f07d78 <unknown>
#3 0x562e80f04029 <unknown>
#4 0x562e80f42ccc <unknown>
#5 0x562e80f4247f <unknown>
#6 0x562e80f39de3 <unknown>
#7 0x562e80f0f2dd <unknown>
#8 0x562e80f1034e <unknown>
#9 0x562e8116f3e4 <unknown>
#10 0x562e811733d7 <unknown>
#11 0x562e8117db20 <unknown>
#12 0x562e81174023 <unknown>
#13 0x562e811421aa <unknown>
#14 0x562e811986b8 <unknown>
#15 0x562e81198847 <unknown>
#16 0x562e811a8243 <unknown>
#17 0x7f379aeb4ea7 start_thread
[2023-07-07T04:50:18.952+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:50:18.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.447 seconds
[2023-07-07T04:50:49.738+0000] {processor.py:157} INFO - Started process (PID=1254) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:50:49.749+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:50:49.749+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:50:49.749+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:50:51.161+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:50:51.159+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5639287004e3 <unknown>
#1 0x56392842fc76 <unknown>
#2 0x563928458d78 <unknown>
#3 0x563928455029 <unknown>
#4 0x563928493ccc <unknown>
#5 0x56392849347f <unknown>
#6 0x56392848ade3 <unknown>
#7 0x5639284602dd <unknown>
#8 0x56392846134e <unknown>
#9 0x5639286c03e4 <unknown>
#10 0x5639286c43d7 <unknown>
#11 0x5639286ceb20 <unknown>
#12 0x5639286c5023 <unknown>
#13 0x5639286931aa <unknown>
#14 0x5639286e96b8 <unknown>
#15 0x5639286e9847 <unknown>
#16 0x5639286f9243 <unknown>
#17 0x7fd077483ea7 start_thread
[2023-07-07T04:50:51.161+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:50:51.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.437 seconds
[2023-07-07T04:51:21.929+0000] {processor.py:157} INFO - Started process (PID=1295) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:51:21.934+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:51:21.935+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:51:21.935+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:51:23.382+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:51:23.381+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x555c8a5264e3 <unknown>
#1 0x555c8a255c76 <unknown>
#2 0x555c8a27ed78 <unknown>
#3 0x555c8a27b029 <unknown>
#4 0x555c8a2b9ccc <unknown>
#5 0x555c8a2b947f <unknown>
#6 0x555c8a2b0de3 <unknown>
#7 0x555c8a2862dd <unknown>
#8 0x555c8a28734e <unknown>
#9 0x555c8a4e63e4 <unknown>
#10 0x555c8a4ea3d7 <unknown>
#11 0x555c8a4f4b20 <unknown>
#12 0x555c8a4eb023 <unknown>
#13 0x555c8a4b91aa <unknown>
#14 0x555c8a50f6b8 <unknown>
#15 0x555c8a50f847 <unknown>
#16 0x555c8a51f243 <unknown>
#17 0x7f676bc4aea7 start_thread
[2023-07-07T04:51:23.383+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:51:23.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.468 seconds
[2023-07-07T04:51:54.130+0000] {processor.py:157} INFO - Started process (PID=1343) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:51:54.137+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:51:54.138+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:51:54.138+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:51:55.542+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:51:55.541+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55b7bc8c54e3 <unknown>
#1 0x55b7bc5f4c76 <unknown>
#2 0x55b7bc61dd78 <unknown>
#3 0x55b7bc61a029 <unknown>
#4 0x55b7bc658ccc <unknown>
#5 0x55b7bc65847f <unknown>
#6 0x55b7bc64fde3 <unknown>
#7 0x55b7bc6252dd <unknown>
#8 0x55b7bc62634e <unknown>
#9 0x55b7bc8853e4 <unknown>
#10 0x55b7bc8893d7 <unknown>
#11 0x55b7bc893b20 <unknown>
#12 0x55b7bc88a023 <unknown>
#13 0x55b7bc8581aa <unknown>
#14 0x55b7bc8ae6b8 <unknown>
#15 0x55b7bc8ae847 <unknown>
#16 0x55b7bc8be243 <unknown>
#17 0x7fb326e11ea7 start_thread
[2023-07-07T04:51:55.543+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:51:55.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.433 seconds
[2023-07-07T04:52:26.443+0000] {processor.py:157} INFO - Started process (PID=1384) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:52:26.455+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:52:26.455+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:52:26.455+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:52:27.858+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:52:27.856+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55654b9634e3 <unknown>
#1 0x55654b692c76 <unknown>
#2 0x55654b6bbd78 <unknown>
#3 0x55654b6b8029 <unknown>
#4 0x55654b6f6ccc <unknown>
#5 0x55654b6f647f <unknown>
#6 0x55654b6edde3 <unknown>
#7 0x55654b6c32dd <unknown>
#8 0x55654b6c434e <unknown>
#9 0x55654b9233e4 <unknown>
#10 0x55654b9273d7 <unknown>
#11 0x55654b931b20 <unknown>
#12 0x55654b928023 <unknown>
#13 0x55654b8f61aa <unknown>
#14 0x55654b94c6b8 <unknown>
#15 0x55654b94c847 <unknown>
#16 0x55654b95c243 <unknown>
#17 0x7f63f3a91ea7 start_thread
[2023-07-07T04:52:27.858+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:52:27.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.437 seconds
[2023-07-07T04:52:58.643+0000] {processor.py:157} INFO - Started process (PID=1425) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:52:58.651+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:52:58.651+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:52:58.651+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:53:00.055+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:53:00.053+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x560e489e74e3 <unknown>
#1 0x560e48716c76 <unknown>
#2 0x560e4873fd78 <unknown>
#3 0x560e4873c029 <unknown>
#4 0x560e4877accc <unknown>
#5 0x560e4877a47f <unknown>
#6 0x560e48771de3 <unknown>
#7 0x560e487472dd <unknown>
#8 0x560e4874834e <unknown>
#9 0x560e489a73e4 <unknown>
#10 0x560e489ab3d7 <unknown>
#11 0x560e489b5b20 <unknown>
#12 0x560e489ac023 <unknown>
#13 0x560e4897a1aa <unknown>
#14 0x560e489d06b8 <unknown>
#15 0x560e489d0847 <unknown>
#16 0x560e489e0243 <unknown>
#17 0x7f38de2ebea7 start_thread
[2023-07-07T04:53:00.055+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:53:00.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.430 seconds
[2023-07-07T04:53:30.863+0000] {processor.py:157} INFO - Started process (PID=1566) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:53:30.869+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:53:30.870+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:53:30.870+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:53:32.276+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:53:32.274+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x564ae9f0c4e3 <unknown>
#1 0x564ae9c3bc76 <unknown>
#2 0x564ae9c64d78 <unknown>
#3 0x564ae9c61029 <unknown>
#4 0x564ae9c9fccc <unknown>
#5 0x564ae9c9f47f <unknown>
#6 0x564ae9c96de3 <unknown>
#7 0x564ae9c6c2dd <unknown>
#8 0x564ae9c6d34e <unknown>
#9 0x564ae9ecc3e4 <unknown>
#10 0x564ae9ed03d7 <unknown>
#11 0x564ae9edab20 <unknown>
#12 0x564ae9ed1023 <unknown>
#13 0x564ae9e9f1aa <unknown>
#14 0x564ae9ef56b8 <unknown>
#15 0x564ae9ef5847 <unknown>
#16 0x564ae9f05243 <unknown>
#17 0x7fdf0059cea7 start_thread
[2023-07-07T04:53:32.277+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:53:32.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.432 seconds
[2023-07-07T04:54:03.102+0000] {processor.py:157} INFO - Started process (PID=1633) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:54:03.109+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:54:03.109+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:54:03.109+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:54:04.514+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:54:04.513+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55915e67e4e3 <unknown>
#1 0x55915e3adc76 <unknown>
#2 0x55915e3d6d78 <unknown>
#3 0x55915e3d3029 <unknown>
#4 0x55915e411ccc <unknown>
#5 0x55915e41147f <unknown>
#6 0x55915e408de3 <unknown>
#7 0x55915e3de2dd <unknown>
#8 0x55915e3df34e <unknown>
#9 0x55915e63e3e4 <unknown>
#10 0x55915e6423d7 <unknown>
#11 0x55915e64cb20 <unknown>
#12 0x55915e643023 <unknown>
#13 0x55915e6111aa <unknown>
#14 0x55915e6676b8 <unknown>
#15 0x55915e667847 <unknown>
#16 0x55915e677243 <unknown>
#17 0x7f80668bcea7 start_thread
[2023-07-07T04:54:04.515+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:54:04.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.430 seconds
[2023-07-07T04:54:35.432+0000] {processor.py:157} INFO - Started process (PID=1676) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:54:35.438+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:54:35.439+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:54:35.439+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:54:36.837+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:54:36.836+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x559d20b0e4e3 <unknown>
#1 0x559d2083dc76 <unknown>
#2 0x559d20866d78 <unknown>
#3 0x559d20863029 <unknown>
#4 0x559d208a1ccc <unknown>
#5 0x559d208a147f <unknown>
#6 0x559d20898de3 <unknown>
#7 0x559d2086e2dd <unknown>
#8 0x559d2086f34e <unknown>
#9 0x559d20ace3e4 <unknown>
#10 0x559d20ad23d7 <unknown>
#11 0x559d20adcb20 <unknown>
#12 0x559d20ad3023 <unknown>
#13 0x559d20aa11aa <unknown>
#14 0x559d20af76b8 <unknown>
#15 0x559d20af7847 <unknown>
#16 0x559d20b07243 <unknown>
#17 0x7fdc90fdfea7 start_thread
[2023-07-07T04:54:36.838+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:54:36.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.420 seconds
[2023-07-07T04:55:07.739+0000] {processor.py:157} INFO - Started process (PID=1717) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:55:07.740+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:55:07.740+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:55:07.740+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:55:09.137+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:55:09.135+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x563d53e844e3 <unknown>
#1 0x563d53bb3c76 <unknown>
#2 0x563d53bdcd78 <unknown>
#3 0x563d53bd9029 <unknown>
#4 0x563d53c17ccc <unknown>
#5 0x563d53c1747f <unknown>
#6 0x563d53c0ede3 <unknown>
#7 0x563d53be42dd <unknown>
#8 0x563d53be534e <unknown>
#9 0x563d53e443e4 <unknown>
#10 0x563d53e483d7 <unknown>
#11 0x563d53e52b20 <unknown>
#12 0x563d53e49023 <unknown>
#13 0x563d53e171aa <unknown>
#14 0x563d53e6d6b8 <unknown>
#15 0x563d53e6d847 <unknown>
#16 0x563d53e7d243 <unknown>
#17 0x7fecd9e07ea7 start_thread
[2023-07-07T04:55:09.137+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:55:09.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.416 seconds
[2023-07-07T04:55:39.912+0000] {processor.py:157} INFO - Started process (PID=1758) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:55:39.921+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:55:39.921+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:55:39.921+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:55:41.345+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:55:41.340+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 222, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 44, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5628359ac4e3 <unknown>
#1 0x5628356dbc76 <unknown>
#2 0x562835704d78 <unknown>
#3 0x562835701029 <unknown>
#4 0x56283573fccc <unknown>
#5 0x56283573f47f <unknown>
#6 0x562835736de3 <unknown>
#7 0x56283570c2dd <unknown>
#8 0x56283570d34e <unknown>
#9 0x56283596c3e4 <unknown>
#10 0x5628359703d7 <unknown>
#11 0x56283597ab20 <unknown>
#12 0x562835971023 <unknown>
#13 0x56283593f1aa <unknown>
#14 0x5628359956b8 <unknown>
#15 0x562835995847 <unknown>
#16 0x5628359a5243 <unknown>
#17 0x7fbb83b96ea7 start_thread
[2023-07-07T04:55:41.346+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:55:41.358+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.448 seconds
[2023-07-07T04:55:47.015+0000] {processor.py:157} INFO - Started process (PID=1790) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:55:47.023+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:55:47.023+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:55:47.023+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:55:49.038+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:55:49.249+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:55:49.249+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:dag_scrap_biobio
[2023-07-07T04:55:49.256+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:55:49.256+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:dag_scrap_biobio
[2023-07-07T04:55:49.262+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:55:49.262+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:dag_scrap_biobio
[2023-07-07T04:55:49.276+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:55:49.275+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T04:55:49.286+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:55:49.286+0000] {dag.py:2747} INFO - Creating ORM DAG for dag_scrap_biobio
[2023-07-07T04:55:49.296+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:55:49.296+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T04:55:49.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.297 seconds
[2023-07-07T04:56:20.301+0000] {processor.py:157} INFO - Started process (PID=2012) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:56:20.307+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T04:56:20.307+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:56:20.307+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:56:22.290+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T04:56:22.310+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:56:22.310+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T04:56:22.329+0000] {logging_mixin.py:149} INFO - [2023-07-07T04:56:22.329+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T04:56:22.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.041 seconds
[2023-07-07T12:41:18.741+0000] {processor.py:157} INFO - Started process (PID=31) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:41:18.742+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:41:18.742+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:41:18.742+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:41:22.062+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:41:22.091+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:41:22.091+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:41:22.108+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:41:22.108+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:41:22.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 3.381 seconds
[2023-07-07T12:41:52.543+0000] {processor.py:157} INFO - Started process (PID=254) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:41:52.549+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:41:52.549+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:41:52.549+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:41:54.520+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:41:54.537+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:41:54.537+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:41:54.555+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:41:54.555+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:41:54.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.024 seconds
[2023-07-07T12:42:24.891+0000] {processor.py:157} INFO - Started process (PID=475) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:42:24.896+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:42:24.897+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:42:24.897+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:42:26.827+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:42:26.844+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:42:26.844+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:42:26.861+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:42:26.861+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:42:26.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.983 seconds
[2023-07-07T12:42:57.141+0000] {processor.py:157} INFO - Started process (PID=712) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:42:57.147+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:42:57.147+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:42:57.147+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:42:59.047+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:42:59.065+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:42:59.064+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:42:59.082+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:42:59.082+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:42:59.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.954 seconds
[2023-07-07T12:43:29.432+0000] {processor.py:157} INFO - Started process (PID=942) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:43:29.433+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:43:29.433+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:43:29.433+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:43:31.335+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:43:31.351+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:43:31.351+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:43:31.369+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:43:31.369+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:43:31.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.949 seconds
[2023-07-07T12:44:01.658+0000] {processor.py:157} INFO - Started process (PID=1178) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:44:01.664+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:44:01.664+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:44:01.664+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:44:03.566+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:44:03.584+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:44:03.584+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:44:03.601+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:44:03.601+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:44:03.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.956 seconds
[2023-07-07T12:44:33.969+0000] {processor.py:157} INFO - Started process (PID=1416) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:44:33.974+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:44:33.974+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:44:33.974+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:44:35.930+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:44:35.947+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:44:35.947+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:44:35.964+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:44:35.964+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:44:35.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.008 seconds
[2023-07-07T12:45:06.315+0000] {processor.py:157} INFO - Started process (PID=1653) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:45:06.321+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:45:06.321+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:45:06.321+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:45:08.225+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:45:08.242+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:45:08.242+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:45:08.259+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:45:08.259+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:45:08.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.957 seconds
[2023-07-07T12:45:38.549+0000] {processor.py:157} INFO - Started process (PID=1875) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:45:38.554+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:45:38.554+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:45:38.554+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:45:40.471+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:45:40.488+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:45:40.488+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:45:40.506+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:45:40.506+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:45:40.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.970 seconds
[2023-07-07T12:46:10.855+0000] {processor.py:157} INFO - Started process (PID=2110) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:46:10.861+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:46:10.861+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:46:10.861+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:46:12.804+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:46:12.821+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:46:12.821+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:46:12.839+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:46:12.838+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:46:12.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.995 seconds
[2023-07-07T12:46:43.201+0000] {processor.py:157} INFO - Started process (PID=2340) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:46:43.201+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:46:43.202+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:46:43.202+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:46:45.094+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:46:45.112+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:46:45.112+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:46:45.129+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:46:45.129+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:46:45.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.941 seconds
[2023-07-07T12:47:15.487+0000] {processor.py:157} INFO - Started process (PID=2576) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:47:15.492+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:47:15.493+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:47:15.492+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:47:17.468+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:47:17.485+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:47:17.485+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:47:17.502+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:47:17.502+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:47:17.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.029 seconds
[2023-07-07T12:47:47.770+0000] {processor.py:157} INFO - Started process (PID=2813) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:47:47.775+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:47:47.776+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:47:47.776+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:47:49.679+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:47:49.697+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:47:49.696+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:47:49.715+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:47:49.715+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:47:49.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.957 seconds
[2023-07-07T12:48:19.996+0000] {processor.py:157} INFO - Started process (PID=3034) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:48:19.997+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:48:19.997+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:48:19.997+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:48:21.921+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:48:21.938+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:48:21.937+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:48:21.955+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:48:21.955+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:48:21.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.972 seconds
[2023-07-07T12:48:52.308+0000] {processor.py:157} INFO - Started process (PID=3268) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:48:52.313+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:48:52.314+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:48:52.314+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:48:54.213+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:48:54.231+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:48:54.230+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:48:54.248+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:48:54.248+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:48:54.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.952 seconds
[2023-07-07T12:49:24.577+0000] {processor.py:157} INFO - Started process (PID=3499) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:49:24.582+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:49:24.583+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:49:24.583+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:49:26.493+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:49:26.511+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:49:26.511+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:49:26.529+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:49:26.528+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:49:26.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.964 seconds
[2023-07-07T12:49:56.799+0000] {processor.py:157} INFO - Started process (PID=3734) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:49:56.800+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:49:56.800+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:49:56.800+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:49:58.725+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:49:58.743+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:49:58.742+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:49:58.761+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:49:58.761+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:49:58.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.974 seconds
[2023-07-07T12:50:29.029+0000] {processor.py:157} INFO - Started process (PID=3972) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:50:29.029+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:50:29.030+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:50:29.030+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:50:30.970+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:50:30.987+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:50:30.987+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:50:31.005+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:50:31.005+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:50:31.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.989 seconds
[2023-07-07T12:51:01.290+0000] {processor.py:157} INFO - Started process (PID=4208) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:51:01.296+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:51:01.297+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:51:01.297+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:51:03.216+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:51:03.233+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:51:03.233+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:51:03.250+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:51:03.250+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:51:03.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.973 seconds
[2023-07-07T12:51:33.549+0000] {processor.py:157} INFO - Started process (PID=4438) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:51:33.555+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:51:33.555+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:51:33.555+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:51:35.478+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:51:35.495+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:51:35.495+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:51:35.512+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:51:35.512+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:51:35.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.975 seconds
[2023-07-07T12:52:05.872+0000] {processor.py:157} INFO - Started process (PID=4668) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:52:05.873+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:52:05.873+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:52:05.873+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:52:07.803+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:52:07.820+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:52:07.820+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:52:07.838+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:52:07.838+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:52:07.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.978 seconds
[2023-07-07T12:52:38.129+0000] {processor.py:157} INFO - Started process (PID=4898) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:52:38.134+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:52:38.134+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:52:38.134+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:52:40.074+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:52:40.091+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:52:40.090+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:52:40.108+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:52:40.108+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:52:40.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.992 seconds
[2023-07-07T12:53:10.382+0000] {processor.py:157} INFO - Started process (PID=5125) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:53:10.387+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:53:10.388+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:53:10.388+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:53:12.295+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:53:12.312+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:53:12.312+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:53:12.329+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:53:12.329+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:53:12.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.960 seconds
[2023-07-07T12:53:42.608+0000] {processor.py:157} INFO - Started process (PID=5362) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:53:42.614+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:53:42.614+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:53:42.614+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:53:44.522+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:53:44.540+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:53:44.540+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:53:44.558+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:53:44.557+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:53:44.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.962 seconds
[2023-07-07T12:54:14.903+0000] {processor.py:157} INFO - Started process (PID=5598) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:54:14.909+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:54:14.909+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:54:14.909+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:54:16.848+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:54:16.865+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:54:16.864+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:54:16.882+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:54:16.882+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:54:16.893+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.992 seconds
[2023-07-07T12:54:47.236+0000] {processor.py:157} INFO - Started process (PID=5840) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:54:47.242+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:54:47.243+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:54:47.242+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:54:49.165+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:54:49.184+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:54:49.184+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:54:49.201+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:54:49.201+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:54:49.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.979 seconds
[2023-07-07T12:55:19.478+0000] {processor.py:157} INFO - Started process (PID=6069) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:55:19.483+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:55:19.484+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:55:19.484+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:55:21.409+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:55:21.426+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:55:21.426+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:55:21.443+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:55:21.443+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:55:21.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.978 seconds
[2023-07-07T12:55:51.723+0000] {processor.py:157} INFO - Started process (PID=6298) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:55:51.728+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:55:51.729+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:55:51.729+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:55:53.642+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:55:53.660+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:55:53.660+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:55:53.677+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:55:53.677+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:55:53.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.966 seconds
[2023-07-07T12:56:23.965+0000] {processor.py:157} INFO - Started process (PID=6528) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:56:23.966+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:56:23.966+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:56:23.966+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:56:25.868+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:56:25.885+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:56:25.885+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:56:25.902+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:56:25.902+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:56:25.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.950 seconds
[2023-07-07T12:56:56.215+0000] {processor.py:157} INFO - Started process (PID=6764) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:56:56.225+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:56:56.226+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:56:56.226+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:56:58.174+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:56:58.190+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:56:58.190+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:56:58.208+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:56:58.208+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:56:58.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.006 seconds
[2023-07-07T12:57:28.485+0000] {processor.py:157} INFO - Started process (PID=7002) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:57:28.490+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:57:28.491+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:57:28.491+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:57:30.403+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:57:30.421+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:57:30.421+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:57:30.438+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:57:30.438+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:57:30.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.966 seconds
[2023-07-07T12:58:00.777+0000] {processor.py:157} INFO - Started process (PID=7223) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:58:00.782+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:58:00.782+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:58:00.782+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:58:02.692+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:58:02.710+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:58:02.710+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:58:02.727+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:58:02.727+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:58:02.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.963 seconds
[2023-07-07T12:58:33.019+0000] {processor.py:157} INFO - Started process (PID=7459) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:58:33.025+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:58:33.026+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:58:33.026+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:58:34.931+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:58:35.001+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:58:35.000+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:58:35.019+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:58:35.019+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:58:35.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.015 seconds
[2023-07-07T12:59:05.295+0000] {processor.py:157} INFO - Started process (PID=7695) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:59:05.300+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:59:05.301+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:59:05.300+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:59:07.219+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:59:07.236+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:59:07.235+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:59:07.254+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:59:07.253+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:59:07.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.971 seconds
[2023-07-07T12:59:37.529+0000] {processor.py:157} INFO - Started process (PID=7930) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:59:37.535+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T12:59:37.536+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:59:37.536+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:59:39.478+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T12:59:39.496+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:59:39.496+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T12:59:39.513+0000] {logging_mixin.py:149} INFO - [2023-07-07T12:59:39.513+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T12:59:39.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.996 seconds
[2023-07-07T13:00:09.803+0000] {processor.py:157} INFO - Started process (PID=8162) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:00:09.809+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:00:09.809+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:00:09.809+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:00:11.736+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:00:11.754+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:00:11.754+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:00:11.771+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:00:11.771+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:00:11.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.980 seconds
[2023-07-07T13:00:42.063+0000] {processor.py:157} INFO - Started process (PID=8385) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:00:42.068+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:00:42.069+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:00:42.069+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:00:44.005+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:00:44.022+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:00:44.022+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:00:44.039+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:00:44.039+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:00:44.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.990 seconds
[2023-07-07T13:01:14.397+0000] {processor.py:157} INFO - Started process (PID=8617) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:01:14.402+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:01:14.402+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:01:14.402+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:01:16.373+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:01:16.390+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:01:16.390+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:01:16.408+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:01:16.408+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:01:16.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.024 seconds
[2023-07-07T13:01:46.687+0000] {processor.py:157} INFO - Started process (PID=8840) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:01:46.692+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:01:46.693+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:01:46.693+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:01:48.647+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:01:48.665+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:01:48.664+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:01:48.682+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:01:48.682+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:01:48.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.007 seconds
[2023-07-07T13:02:18.958+0000] {processor.py:157} INFO - Started process (PID=9065) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:02:18.963+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:02:18.964+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:02:18.964+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:02:20.895+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:02:20.913+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:02:20.913+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:02:20.930+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:02:20.930+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:02:20.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.985 seconds
[2023-07-07T13:02:51.224+0000] {processor.py:157} INFO - Started process (PID=9290) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:02:51.230+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:02:51.230+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:02:51.230+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:02:53.155+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:02:53.172+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:02:53.172+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:02:53.189+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:02:53.189+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:02:53.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.978 seconds
[2023-07-07T13:03:23.469+0000] {processor.py:157} INFO - Started process (PID=9515) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:03:23.475+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:03:23.476+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:03:23.475+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:03:25.428+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:03:25.444+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:03:25.444+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:03:25.462+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:03:25.462+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:03:25.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.006 seconds
[2023-07-07T13:03:55.752+0000] {processor.py:157} INFO - Started process (PID=9740) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:03:55.758+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:03:55.758+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:03:55.758+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:03:57.682+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:03:57.700+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:03:57.700+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:03:57.717+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:03:57.717+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:03:57.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.977 seconds
[2023-07-07T13:04:28.071+0000] {processor.py:157} INFO - Started process (PID=9958) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:04:28.077+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:04:28.077+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:04:28.077+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:04:30.001+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:04:30.019+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:04:30.019+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:04:30.036+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:04:30.036+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:04:30.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.978 seconds
[2023-07-07T13:05:00.399+0000] {processor.py:157} INFO - Started process (PID=10184) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:05:00.404+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:05:00.405+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:05:00.405+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:05:02.352+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:05:02.369+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:05:02.369+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:05:02.386+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:05:02.386+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:05:02.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.001 seconds
[2023-07-07T13:05:32.680+0000] {processor.py:157} INFO - Started process (PID=10410) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:05:32.687+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:05:32.687+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:05:32.687+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:05:34.608+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:05:34.625+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:05:34.625+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:05:34.643+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:05:34.643+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:05:34.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.975 seconds
[2023-07-07T13:06:04.934+0000] {processor.py:157} INFO - Started process (PID=10627) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:06:04.940+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:06:04.941+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:06:04.941+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:06:06.868+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:06:06.885+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:06:06.885+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:06:06.902+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:06:06.902+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:06:06.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.981 seconds
[2023-07-07T13:06:37.257+0000] {processor.py:157} INFO - Started process (PID=10853) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:06:37.262+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:06:37.263+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:06:37.263+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:06:39.173+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:06:39.191+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:06:39.191+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:06:39.208+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:06:39.208+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:06:39.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.964 seconds
[2023-07-07T13:07:09.551+0000] {processor.py:157} INFO - Started process (PID=11077) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:07:09.556+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:07:09.557+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:07:09.557+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:07:11.466+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:07:11.483+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:07:11.483+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:07:11.500+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:07:11.500+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:07:11.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.963 seconds
[2023-07-07T13:07:41.796+0000] {processor.py:157} INFO - Started process (PID=11309) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:07:41.802+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:07:41.802+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:07:41.802+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:07:43.750+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:07:43.767+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:07:43.767+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:07:43.785+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:07:43.785+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:07:43.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.001 seconds
[2023-07-07T13:08:14.124+0000] {processor.py:157} INFO - Started process (PID=11542) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:08:14.129+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:08:14.130+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:08:14.129+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:08:16.039+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:08:16.057+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:08:16.056+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:08:16.074+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:08:16.074+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:08:16.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.963 seconds
[2023-07-07T13:08:46.432+0000] {processor.py:157} INFO - Started process (PID=11774) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:08:46.438+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:08:46.438+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:08:46.438+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:08:48.414+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:08:48.452+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:08:48.452+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:08:48.470+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:08:48.470+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:08:48.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.050 seconds
[2023-07-07T13:09:18.716+0000] {processor.py:157} INFO - Started process (PID=12014) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:09:18.717+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:09:18.717+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:09:18.717+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:09:20.622+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:09:20.639+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:09:20.639+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:09:20.656+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:09:20.656+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:09:20.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.953 seconds
[2023-07-07T13:09:50.927+0000] {processor.py:157} INFO - Started process (PID=12240) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:09:50.927+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:09:50.928+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:09:50.928+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:09:52.853+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:09:52.870+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:09:52.870+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:09:52.888+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:09:52.888+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:09:52.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.974 seconds
[2023-07-07T13:10:23.196+0000] {processor.py:157} INFO - Started process (PID=12473) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:10:23.201+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:10:23.202+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:10:23.201+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:10:25.154+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:10:25.178+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:10:25.177+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:10:25.205+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:10:25.205+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:10:25.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.026 seconds
[2023-07-07T13:10:55.469+0000] {processor.py:157} INFO - Started process (PID=12698) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:10:55.475+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:10:55.476+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:10:55.476+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:10:57.400+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:10:57.418+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:10:57.418+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:10:57.435+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:10:57.435+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:10:57.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.989 seconds
[2023-07-07T13:11:27.741+0000] {processor.py:157} INFO - Started process (PID=12916) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:11:27.746+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:11:27.747+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:11:27.747+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:11:29.697+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:11:29.714+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:11:29.714+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:11:29.732+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:11:29.732+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:11:29.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.008 seconds
[2023-07-07T13:12:00.026+0000] {processor.py:157} INFO - Started process (PID=13141) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:12:00.032+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:12:00.032+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:12:00.032+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:12:01.967+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:12:01.985+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:12:01.984+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:12:02.003+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:12:02.003+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:12:02.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.997 seconds
[2023-07-07T13:12:32.296+0000] {processor.py:157} INFO - Started process (PID=13362) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:12:32.303+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:12:32.303+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:12:32.303+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:12:34.212+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:12:34.230+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:12:34.230+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:12:34.247+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:12:34.247+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:12:34.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.963 seconds
[2023-07-07T13:13:04.609+0000] {processor.py:157} INFO - Started process (PID=13588) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:13:04.614+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:13:04.615+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:13:04.615+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:13:06.524+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:13:06.542+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:13:06.541+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:13:06.559+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:13:06.559+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:13:06.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.962 seconds
[2023-07-07T13:13:36.828+0000] {processor.py:157} INFO - Started process (PID=13822) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:13:36.834+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:13:36.834+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:13:36.834+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:13:38.769+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:13:38.786+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:13:38.786+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:13:38.804+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:13:38.804+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:13:38.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.989 seconds
[2023-07-07T13:14:09.097+0000] {processor.py:157} INFO - Started process (PID=14056) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:14:09.104+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:14:09.104+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:14:09.104+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:14:11.016+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:14:11.035+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:14:11.034+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:14:11.052+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:14:11.052+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:14:11.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.968 seconds
[2023-07-07T13:14:41.323+0000] {processor.py:157} INFO - Started process (PID=14280) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:14:41.330+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:14:41.331+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:14:41.331+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:14:43.254+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:14:43.272+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:14:43.272+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:14:43.293+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:14:43.293+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:14:43.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.983 seconds
[2023-07-07T13:15:13.645+0000] {processor.py:157} INFO - Started process (PID=14512) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:15:13.650+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:15:13.651+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:15:13.651+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:15:15.575+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:15:15.593+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:15:15.592+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:15:15.609+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:15:15.609+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:15:15.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.977 seconds
[2023-07-07T13:15:45.897+0000] {processor.py:157} INFO - Started process (PID=14736) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:15:45.904+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:15:45.904+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:15:45.904+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:15:47.832+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:15:47.849+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:15:47.848+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:15:47.867+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:15:47.867+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:15:47.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.985 seconds
[2023-07-07T13:16:18.167+0000] {processor.py:157} INFO - Started process (PID=14961) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:16:18.172+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:16:18.173+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:16:18.172+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:16:20.085+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:16:20.103+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:16:20.102+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:16:20.120+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:16:20.120+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:16:20.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.967 seconds
[2023-07-07T13:16:50.416+0000] {processor.py:157} INFO - Started process (PID=15197) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:16:50.431+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:16:50.431+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:16:50.431+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:16:52.363+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:16:52.389+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:16:52.389+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:16:52.407+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:16:52.407+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:16:52.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.003 seconds
[2023-07-07T13:17:22.760+0000] {processor.py:157} INFO - Started process (PID=15428) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:17:22.761+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:17:22.761+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:17:22.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:17:24.804+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:17:24.821+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:17:24.821+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:17:24.838+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:17:24.838+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:17:24.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.096 seconds
[2023-07-07T13:17:55.049+0000] {processor.py:157} INFO - Started process (PID=15653) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:17:55.054+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:17:55.055+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:17:55.054+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:17:57.008+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:17:57.031+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:17:57.031+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:17:57.049+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:17:57.049+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:17:57.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.013 seconds
[2023-07-07T13:18:27.325+0000] {processor.py:157} INFO - Started process (PID=15872) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:18:27.331+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:18:27.332+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:18:27.332+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:18:29.279+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:18:29.299+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:18:29.298+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:18:29.316+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:18:29.316+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:18:29.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.004 seconds
[2023-07-07T13:18:59.596+0000] {processor.py:157} INFO - Started process (PID=16096) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:18:59.606+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:18:59.607+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:18:59.607+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:19:01.580+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:19:01.598+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:19:01.598+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:19:01.615+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:19:01.615+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:19:01.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.032 seconds
[2023-07-07T13:19:31.860+0000] {processor.py:157} INFO - Started process (PID=16321) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:19:31.865+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:19:31.866+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:19:31.866+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:19:33.808+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:19:33.829+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:19:33.829+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:19:33.847+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:19:33.847+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:19:33.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.005 seconds
[2023-07-07T13:20:04.132+0000] {processor.py:157} INFO - Started process (PID=16538) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:20:04.138+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:20:04.138+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:20:04.138+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:20:06.085+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:20:06.106+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:20:06.106+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:20:06.126+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:20:06.126+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:20:06.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.006 seconds
[2023-07-07T13:20:36.474+0000] {processor.py:157} INFO - Started process (PID=16764) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:20:36.484+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:20:36.485+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:20:36.485+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:20:38.449+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:20:38.467+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:20:38.466+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:20:38.485+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:20:38.484+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:20:38.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.023 seconds
[2023-07-07T13:21:08.840+0000] {processor.py:157} INFO - Started process (PID=16988) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:21:08.840+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:21:08.841+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:21:08.841+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:21:11.247+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:21:11.266+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:21:11.265+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:21:11.283+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:21:11.282+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:21:11.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.462 seconds
[2023-07-07T13:21:42.289+0000] {processor.py:157} INFO - Started process (PID=17216) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:21:42.294+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:21:42.294+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:21:42.294+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:21:44.292+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:21:44.310+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:21:44.309+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:21:44.327+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:21:44.327+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:21:44.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.056 seconds
[2023-07-07T13:22:14.649+0000] {processor.py:157} INFO - Started process (PID=17434) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:22:14.660+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:22:14.661+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:22:14.661+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:22:16.620+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:22:16.638+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:22:16.638+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:22:16.656+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:22:16.656+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:22:16.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.021 seconds
[2023-07-07T13:22:46.998+0000] {processor.py:157} INFO - Started process (PID=17664) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:22:46.998+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:22:46.999+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:22:46.999+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:22:48.952+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:22:48.971+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:22:48.970+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:22:48.988+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:22:48.988+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:22:48.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.003 seconds
[2023-07-07T13:23:19.359+0000] {processor.py:157} INFO - Started process (PID=17889) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:23:19.365+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:23:19.365+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:23:19.365+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:23:21.509+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:23:21.527+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:23:21.527+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:23:21.545+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:23:21.544+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:23:21.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.198 seconds
[2023-07-07T13:23:51.622+0000] {processor.py:157} INFO - Started process (PID=18121) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:23:51.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:23:51.634+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:23:51.634+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:23:53.594+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:23:53.611+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:23:53.611+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:23:53.630+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:23:53.630+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:23:53.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.021 seconds
[2023-07-07T13:24:23.981+0000] {processor.py:157} INFO - Started process (PID=18344) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:24:23.993+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:24:23.993+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:24:23.993+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:24:25.972+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:24:25.989+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:24:25.989+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:24:26.008+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:24:26.007+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:24:26.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.039 seconds
[2023-07-07T13:24:56.263+0000] {processor.py:157} INFO - Started process (PID=18569) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:24:56.269+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:24:56.270+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:24:56.270+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:24:58.244+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:24:58.262+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:24:58.261+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:24:58.280+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:24:58.280+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:24:58.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.030 seconds
[2023-07-07T13:25:28.530+0000] {processor.py:157} INFO - Started process (PID=18786) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:25:28.537+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:25:28.538+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:25:28.538+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:25:30.492+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:25:30.516+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:25:30.516+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:25:30.534+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:25:30.533+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:25:30.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.018 seconds
[2023-07-07T13:26:00.804+0000] {processor.py:157} INFO - Started process (PID=19004) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:26:00.816+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:26:00.817+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:26:00.816+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:26:02.793+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:26:02.818+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:26:02.818+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:26:02.837+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:26:02.837+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:26:02.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.046 seconds
[2023-07-07T13:26:33.105+0000] {processor.py:157} INFO - Started process (PID=19229) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:26:33.106+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:26:33.106+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:26:33.106+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:26:35.090+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:26:35.110+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:26:35.110+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:26:35.129+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:26:35.129+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:26:35.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.037 seconds
[2023-07-07T13:27:05.448+0000] {processor.py:157} INFO - Started process (PID=19446) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:27:05.453+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:27:05.454+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:27:05.454+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:27:07.458+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:27:07.478+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:27:07.478+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:27:07.498+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:27:07.498+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:27:07.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.065 seconds
[2023-07-07T13:27:37.806+0000] {processor.py:157} INFO - Started process (PID=19664) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:27:37.811+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:27:37.811+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:27:37.811+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:27:39.845+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:27:39.864+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:27:39.863+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:27:39.881+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:27:39.881+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:27:39.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.089 seconds
[2023-07-07T13:28:10.133+0000] {processor.py:157} INFO - Started process (PID=19887) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:28:10.133+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:28:10.134+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:28:10.134+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:28:12.124+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:28:12.144+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:28:12.144+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:28:12.162+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:28:12.162+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:28:12.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.041 seconds
[2023-07-07T13:28:42.423+0000] {processor.py:157} INFO - Started process (PID=20116) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:28:42.432+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:28:42.432+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:28:42.432+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:28:44.399+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:28:44.416+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:28:44.416+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:28:44.434+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:28:44.434+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:28:44.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.024 seconds
[2023-07-07T13:29:14.744+0000] {processor.py:157} INFO - Started process (PID=20334) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:29:14.745+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:29:14.745+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:29:14.745+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:29:16.725+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:29:16.743+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:29:16.743+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:29:16.760+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:29:16.760+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:29:16.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.035 seconds
[2023-07-07T13:29:47.047+0000] {processor.py:157} INFO - Started process (PID=20551) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:29:47.053+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:29:47.054+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:29:47.053+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:29:49.000+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:29:49.018+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:29:49.018+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:29:49.035+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:29:49.035+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:29:49.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.003 seconds
[2023-07-07T13:30:19.395+0000] {processor.py:157} INFO - Started process (PID=20769) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:30:19.400+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:30:19.401+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:30:19.401+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:30:21.375+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:30:21.394+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:30:21.394+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:30:21.412+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:30:21.412+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:30:21.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.030 seconds
[2023-07-07T13:30:51.678+0000] {processor.py:157} INFO - Started process (PID=20996) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:30:51.684+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:30:51.685+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:30:51.685+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:30:53.680+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:30:53.698+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:30:53.697+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:30:53.716+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:30:53.716+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:30:53.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.055 seconds
[2023-07-07T13:31:23.977+0000] {processor.py:157} INFO - Started process (PID=21227) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:31:23.982+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:31:23.983+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:31:23.983+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:31:25.932+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:31:25.950+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:31:25.950+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:31:25.975+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:31:25.975+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:31:25.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.016 seconds
[2023-07-07T13:31:56.253+0000] {processor.py:157} INFO - Started process (PID=21453) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:31:56.259+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:31:56.259+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:31:56.259+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:31:58.229+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:31:58.247+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:31:58.247+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:31:58.264+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:31:58.264+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:31:58.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.025 seconds
[2023-07-07T13:32:28.536+0000] {processor.py:157} INFO - Started process (PID=21679) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:32:28.541+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:32:28.542+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:32:28.542+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:32:30.512+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:32:30.529+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:32:30.529+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:32:30.548+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:32:30.548+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:32:30.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.034 seconds
[2023-07-07T13:33:00.816+0000] {processor.py:157} INFO - Started process (PID=21896) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:33:00.822+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:33:00.822+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:33:00.822+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:33:02.797+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:33:02.814+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:33:02.813+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:33:02.833+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:33:02.833+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:33:02.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.029 seconds
[2023-07-07T13:33:33.091+0000] {processor.py:157} INFO - Started process (PID=22112) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:33:33.097+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:33:33.097+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:33:33.097+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:33:35.068+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:33:35.086+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:33:35.086+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:33:35.104+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:33:35.104+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:33:35.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.029 seconds
[2023-07-07T13:34:05.436+0000] {processor.py:157} INFO - Started process (PID=22329) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:34:05.441+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:34:05.442+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:34:05.442+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:34:07.396+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:34:07.413+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:34:07.413+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:34:07.431+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:34:07.431+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:34:07.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.008 seconds
[2023-07-07T13:34:37.775+0000] {processor.py:157} INFO - Started process (PID=22554) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:34:37.786+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:34:37.786+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:34:37.786+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:34:39.759+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:34:39.776+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:34:39.776+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:34:39.794+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:34:39.794+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:34:39.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.032 seconds
[2023-07-07T13:35:10.052+0000] {processor.py:157} INFO - Started process (PID=22779) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:35:10.058+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:35:10.058+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:35:10.058+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:35:12.022+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:35:12.040+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:35:12.039+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:35:12.058+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:35:12.058+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:35:12.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.019 seconds
[2023-07-07T13:35:42.331+0000] {processor.py:157} INFO - Started process (PID=22996) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:35:42.341+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:35:42.341+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:35:42.341+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:35:44.325+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:35:44.351+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:35:44.351+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:35:44.368+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:35:44.368+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:35:44.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.051 seconds
[2023-07-07T13:36:14.662+0000] {processor.py:157} INFO - Started process (PID=23220) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:36:14.668+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:36:14.669+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:36:14.669+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:36:16.639+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:36:16.664+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:36:16.663+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:36:16.681+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:36:16.681+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:36:16.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.032 seconds
[2023-07-07T13:36:47.005+0000] {processor.py:157} INFO - Started process (PID=23437) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:36:47.010+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:36:47.010+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:36:47.010+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:36:48.990+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:36:49.008+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:36:49.007+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:36:49.028+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:36:49.028+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:36:49.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.037 seconds
[2023-07-07T13:37:19.348+0000] {processor.py:157} INFO - Started process (PID=23655) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:37:19.354+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:37:19.354+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:37:19.354+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:37:21.339+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:37:21.357+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:37:21.357+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:37:21.374+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:37:21.374+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:37:21.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.042 seconds
[2023-07-07T13:37:51.653+0000] {processor.py:157} INFO - Started process (PID=23882) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:37:51.654+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:37:51.655+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:37:51.655+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:37:53.634+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:37:53.652+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:37:53.652+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:37:53.671+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:37:53.670+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:37:53.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.036 seconds
[2023-07-07T13:38:23.923+0000] {processor.py:157} INFO - Started process (PID=24099) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:38:23.928+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:38:23.929+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:38:23.929+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:38:25.909+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:38:25.926+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:38:25.925+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:38:25.943+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:38:25.943+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:38:25.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.033 seconds
[2023-07-07T13:38:56.251+0000] {processor.py:157} INFO - Started process (PID=24321) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:38:56.257+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:38:56.258+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:38:56.258+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:38:58.235+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:38:58.252+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:38:58.252+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:38:58.271+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:38:58.271+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:38:58.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.033 seconds
[2023-07-07T13:39:28.519+0000] {processor.py:157} INFO - Started process (PID=24537) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:39:28.526+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:39:28.526+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:39:28.526+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:39:30.515+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:39:30.533+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:39:30.533+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:39:30.551+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:39:30.550+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:39:30.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.046 seconds
[2023-07-07T13:40:00.854+0000] {processor.py:157} INFO - Started process (PID=24756) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:40:00.859+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:40:00.859+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:40:00.859+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:40:02.839+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:40:02.857+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:40:02.856+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:40:02.874+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:40:02.873+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:40:02.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.032 seconds
[2023-07-07T13:40:33.183+0000] {processor.py:157} INFO - Started process (PID=24973) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:40:33.194+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:40:33.194+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:40:33.194+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:40:35.174+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:40:35.192+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:40:35.192+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:40:35.209+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:40:35.209+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:40:35.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.045 seconds
[2023-07-07T13:41:05.507+0000] {processor.py:157} INFO - Started process (PID=25198) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:41:05.513+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:41:05.513+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:41:05.513+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:41:07.534+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:41:07.551+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:41:07.551+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:41:07.569+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:41:07.569+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:41:07.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.076 seconds
[2023-07-07T13:41:37.789+0000] {processor.py:157} INFO - Started process (PID=25415) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:41:37.801+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:41:37.801+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:41:37.801+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:41:39.780+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:41:39.798+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:41:39.798+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:41:39.816+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:41:39.815+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:41:39.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.039 seconds
[2023-07-07T13:42:10.105+0000] {processor.py:157} INFO - Started process (PID=25631) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:42:10.112+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:42:10.112+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:42:10.112+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:42:12.072+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:42:12.090+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:42:12.090+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:42:12.108+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:42:12.108+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:42:12.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.016 seconds
[2023-07-07T13:42:42.375+0000] {processor.py:157} INFO - Started process (PID=25848) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:42:42.381+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:42:42.381+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:42:42.381+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:42:44.345+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:42:44.365+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:42:44.365+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:42:44.385+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:42:44.385+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:42:44.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.023 seconds
[2023-07-07T13:43:14.626+0000] {processor.py:157} INFO - Started process (PID=26073) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:43:14.637+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:43:14.637+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:43:14.637+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:43:16.608+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:43:16.625+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:43:16.625+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:43:16.643+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:43:16.643+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:43:16.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.036 seconds
[2023-07-07T13:43:46.879+0000] {processor.py:157} INFO - Started process (PID=26298) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:43:46.884+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:43:46.885+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:43:46.885+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:43:48.911+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:43:48.937+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:43:48.937+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:43:48.955+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:43:48.954+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:43:48.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.088 seconds
[2023-07-07T13:44:19.207+0000] {processor.py:157} INFO - Started process (PID=26515) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:44:19.214+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:44:19.214+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:44:19.214+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:44:21.207+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:44:21.226+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:44:21.226+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:44:21.243+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:44:21.243+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:44:21.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.050 seconds
[2023-07-07T13:44:51.517+0000] {processor.py:157} INFO - Started process (PID=26731) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:44:51.522+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:44:51.523+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:44:51.523+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:44:53.490+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:44:53.507+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:44:53.507+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:44:53.524+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:44:53.524+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:44:53.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.021 seconds
[2023-07-07T13:45:23.844+0000] {processor.py:157} INFO - Started process (PID=26957) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:45:23.854+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:45:23.854+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:45:23.854+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:45:25.804+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:45:25.827+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:45:25.827+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:45:25.845+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:45:25.845+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:45:25.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.014 seconds
[2023-07-07T13:45:56.185+0000] {processor.py:157} INFO - Started process (PID=27175) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:45:56.195+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:45:56.195+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:45:56.195+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:45:58.164+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:45:58.182+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:45:58.181+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:45:58.199+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:45:58.199+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:45:58.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.026 seconds
[2023-07-07T13:46:28.523+0000] {processor.py:157} INFO - Started process (PID=27414) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:46:28.535+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:46:28.535+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:46:28.535+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:46:30.506+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:46:30.524+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:46:30.524+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:46:30.541+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:46:30.541+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:46:30.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.031 seconds
[2023-07-07T13:47:00.865+0000] {processor.py:157} INFO - Started process (PID=27630) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:47:00.876+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:47:00.876+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:47:00.876+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:47:02.825+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:47:02.843+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:47:02.843+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:47:02.861+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:47:02.861+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:47:02.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.008 seconds
[2023-07-07T13:47:33.209+0000] {processor.py:157} INFO - Started process (PID=27846) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:47:33.220+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:47:33.220+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:47:33.220+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:47:35.191+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:47:35.208+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:47:35.207+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:47:35.226+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:47:35.226+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:47:35.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.030 seconds
[2023-07-07T13:48:05.547+0000] {processor.py:157} INFO - Started process (PID=28081) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:48:05.554+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:48:05.554+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:48:05.554+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:48:07.519+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:48:07.537+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:48:07.536+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:48:07.554+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:48:07.554+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:48:07.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.024 seconds
[2023-07-07T13:48:37.814+0000] {processor.py:157} INFO - Started process (PID=28305) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:48:37.820+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:48:37.821+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:48:37.821+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:48:39.776+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:48:39.795+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:48:39.795+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:48:39.812+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:48:39.812+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:48:39.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.012 seconds
[2023-07-07T13:49:10.145+0000] {processor.py:157} INFO - Started process (PID=28522) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:49:10.152+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:49:10.152+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:49:10.152+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:49:12.104+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:49:12.122+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:49:12.121+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:49:12.139+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:49:12.139+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:49:12.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.007 seconds
[2023-07-07T13:49:42.455+0000] {processor.py:157} INFO - Started process (PID=28747) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:49:42.464+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:49:42.465+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:49:42.465+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:49:44.440+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:49:44.458+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:49:44.458+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T13:49:44.476+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:49:44.476+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T13:49:44.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.034 seconds
[2023-07-07T13:50:14.731+0000] {processor.py:157} INFO - Started process (PID=28972) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:50:14.741+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:50:14.741+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:50:14.741+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:50:19.339+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:50:19.333+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 48, in ScrapAndStoreData
    browser2_links = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55c7ff7da4e3 <unknown>
#1 0x55c7ff509c76 <unknown>
#2 0x55c7ff532d78 <unknown>
#3 0x55c7ff52f029 <unknown>
#4 0x55c7ff56dccc <unknown>
#5 0x55c7ff56d47f <unknown>
#6 0x55c7ff564de3 <unknown>
#7 0x55c7ff53a2dd <unknown>
#8 0x55c7ff53b34e <unknown>
#9 0x55c7ff79a3e4 <unknown>
#10 0x55c7ff79e3d7 <unknown>
#11 0x55c7ff7a8b20 <unknown>
#12 0x55c7ff79f023 <unknown>
#13 0x55c7ff76d1aa <unknown>
#14 0x55c7ff7c36b8 <unknown>
#15 0x55c7ff7c3847 <unknown>
#16 0x55c7ff7d3243 <unknown>
#17 0x7fab8ec42ea7 start_thread
[2023-07-07T13:50:19.392+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:50:19.408+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 4.680 seconds
[2023-07-07T13:50:50.061+0000] {processor.py:157} INFO - Started process (PID=29319) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:50:50.062+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:50:50.062+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:50:50.062+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:50:58.584+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:50:58.580+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 48, in ScrapAndStoreData
    browser2_links = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x556545cae4e3 <unknown>
#1 0x5565459ddc76 <unknown>
#2 0x556545a06d78 <unknown>
#3 0x556545a03029 <unknown>
#4 0x556545a41ccc <unknown>
#5 0x556545a4147f <unknown>
#6 0x556545a38de3 <unknown>
#7 0x556545a0e2dd <unknown>
#8 0x556545a0f34e <unknown>
#9 0x556545c6e3e4 <unknown>
#10 0x556545c723d7 <unknown>
#11 0x556545c7cb20 <unknown>
#12 0x556545c73023 <unknown>
#13 0x556545c411aa <unknown>
#14 0x556545c976b8 <unknown>
#15 0x556545c97847 <unknown>
#16 0x556545ca7243 <unknown>
#17 0x7f8bb146fea7 start_thread
[2023-07-07T13:50:58.637+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:50:58.660+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 8.602 seconds
[2023-07-07T13:50:59.384+0000] {processor.py:157} INFO - Started process (PID=29672) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:50:59.384+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:50:59.385+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:50:59.385+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:51:05.340+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:51:05.336+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 48, in ScrapAndStoreData
    browser2_links = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x56231045b4e3 <unknown>
#1 0x56231018ac76 <unknown>
#2 0x5623101b3d78 <unknown>
#3 0x5623101b0029 <unknown>
#4 0x5623101eeccc <unknown>
#5 0x5623101ee47f <unknown>
#6 0x5623101e5de3 <unknown>
#7 0x5623101bb2dd <unknown>
#8 0x5623101bc34e <unknown>
#9 0x56231041b3e4 <unknown>
#10 0x56231041f3d7 <unknown>
#11 0x562310429b20 <unknown>
#12 0x562310420023 <unknown>
#13 0x5623103ee1aa <unknown>
#14 0x5623104446b8 <unknown>
#15 0x562310444847 <unknown>
#16 0x562310454243 <unknown>
#17 0x7f9592868ea7 start_thread
[2023-07-07T13:51:05.393+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:51:05.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 6.140 seconds
[2023-07-07T13:51:35.825+0000] {processor.py:157} INFO - Started process (PID=30020) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:51:35.836+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:51:35.837+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:51:35.836+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:51:40.055+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:51:40.052+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 48, in ScrapAndStoreData
    browser2_links = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x559eef24d4e3 <unknown>
#1 0x559eeef7cc76 <unknown>
#2 0x559eeefa5d78 <unknown>
#3 0x559eeefa2029 <unknown>
#4 0x559eeefe0ccc <unknown>
#5 0x559eeefe047f <unknown>
#6 0x559eeefd7de3 <unknown>
#7 0x559eeefad2dd <unknown>
#8 0x559eeefae34e <unknown>
#9 0x559eef20d3e4 <unknown>
#10 0x559eef2113d7 <unknown>
#11 0x559eef21bb20 <unknown>
#12 0x559eef212023 <unknown>
#13 0x559eef1e01aa <unknown>
#14 0x559eef2366b8 <unknown>
#15 0x559eef236847 <unknown>
#16 0x559eef246243 <unknown>
#17 0x7f020c0f0ea7 start_thread
[2023-07-07T13:51:40.108+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:51:40.167+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 4.344 seconds
[2023-07-07T13:52:11.160+0000] {processor.py:157} INFO - Started process (PID=30354) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:52:11.166+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:52:11.166+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:52:11.166+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:52:15.638+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:52:15.634+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 48, in ScrapAndStoreData
    browser2_links = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5557397a94e3 <unknown>
#1 0x5557394d8c76 <unknown>
#2 0x555739501d78 <unknown>
#3 0x5557394fe029 <unknown>
#4 0x55573953cccc <unknown>
#5 0x55573953c47f <unknown>
#6 0x555739533de3 <unknown>
#7 0x5557395092dd <unknown>
#8 0x55573950a34e <unknown>
#9 0x5557397693e4 <unknown>
#10 0x55573976d3d7 <unknown>
#11 0x555739777b20 <unknown>
#12 0x55573976e023 <unknown>
#13 0x55573973c1aa <unknown>
#14 0x5557397926b8 <unknown>
#15 0x555739792847 <unknown>
#16 0x5557397a2243 <unknown>
#17 0x7f96fc716ea7 start_thread
[2023-07-07T13:52:15.691+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:52:15.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 4.557 seconds
[2023-07-07T13:52:46.507+0000] {processor.py:157} INFO - Started process (PID=30700) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:52:46.513+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:52:46.513+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:52:46.513+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:52:51.011+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:52:51.008+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 48, in ScrapAndStoreData
    browser2_links = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x564a094704e3 <unknown>
#1 0x564a0919fc76 <unknown>
#2 0x564a091c8d78 <unknown>
#3 0x564a091c5029 <unknown>
#4 0x564a09203ccc <unknown>
#5 0x564a0920347f <unknown>
#6 0x564a091fade3 <unknown>
#7 0x564a091d02dd <unknown>
#8 0x564a091d134e <unknown>
#9 0x564a094303e4 <unknown>
#10 0x564a094343d7 <unknown>
#11 0x564a0943eb20 <unknown>
#12 0x564a09435023 <unknown>
#13 0x564a094031aa <unknown>
#14 0x564a094596b8 <unknown>
#15 0x564a09459847 <unknown>
#16 0x564a09469243 <unknown>
#17 0x7fec4e6caea7 start_thread
[2023-07-07T13:52:51.064+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:52:51.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 4.586 seconds
[2023-07-07T13:53:21.785+0000] {processor.py:157} INFO - Started process (PID=31046) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:53:21.796+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:53:21.796+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:53:21.796+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:53:27.195+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:53:27.192+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 48, in ScrapAndStoreData
    browser2_links = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x55b5047144e3 <unknown>
#1 0x55b504443c76 <unknown>
#2 0x55b50446cd78 <unknown>
#3 0x55b504469029 <unknown>
#4 0x55b5044a7ccc <unknown>
#5 0x55b5044a747f <unknown>
#6 0x55b50449ede3 <unknown>
#7 0x55b5044742dd <unknown>
#8 0x55b50447534e <unknown>
#9 0x55b5046d43e4 <unknown>
#10 0x55b5046d83d7 <unknown>
#11 0x55b5046e2b20 <unknown>
#12 0x55b5046d9023 <unknown>
#13 0x55b5046a71aa <unknown>
#14 0x55b5046fd6b8 <unknown>
#15 0x55b5046fd847 <unknown>
#16 0x55b50470d243 <unknown>
#17 0x7f3303758ea7 start_thread
[2023-07-07T13:53:27.251+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:53:27.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 6.141 seconds
[2023-07-07T13:53:58.167+0000] {processor.py:157} INFO - Started process (PID=31392) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:53:58.172+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:53:58.173+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:53:58.172+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:54:05.490+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:54:05.486+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 48, in ScrapAndStoreData
    browser2_links = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x5623d4a0a4e3 <unknown>
#1 0x5623d4739c76 <unknown>
#2 0x5623d4762d78 <unknown>
#3 0x5623d475f029 <unknown>
#4 0x5623d479dccc <unknown>
#5 0x5623d479d47f <unknown>
#6 0x5623d4794de3 <unknown>
#7 0x5623d476a2dd <unknown>
#8 0x5623d476b34e <unknown>
#9 0x5623d49ca3e4 <unknown>
#10 0x5623d49ce3d7 <unknown>
#11 0x5623d49d8b20 <unknown>
#12 0x5623d49cf023 <unknown>
#13 0x5623d499d1aa <unknown>
#14 0x5623d49f36b8 <unknown>
#15 0x5623d49f3847 <unknown>
#16 0x5623d4a03243 <unknown>
#17 0x7fbe35f43ea7 start_thread
[2023-07-07T13:54:05.543+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:54:06.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 8.408 seconds
[2023-07-07T13:54:10.836+0000] {processor.py:157} INFO - Started process (PID=31745) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:54:10.838+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:54:10.838+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:54:10.838+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:54:17.216+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:54:17.214+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 48, in ScrapAndStoreData
    browser2_links = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 346, in execute
    self.error_handler.check_response(response)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py", line 245, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
Stacktrace:
#0 0x561ee06454e3 <unknown>
#1 0x561ee0374c76 <unknown>
#2 0x561ee039dd78 <unknown>
#3 0x561ee039a029 <unknown>
#4 0x561ee03d8ccc <unknown>
#5 0x561ee03d847f <unknown>
#6 0x561ee03cfde3 <unknown>
#7 0x561ee03a52dd <unknown>
#8 0x561ee03a634e <unknown>
#9 0x561ee06053e4 <unknown>
#10 0x561ee06093d7 <unknown>
#11 0x561ee0613b20 <unknown>
#12 0x561ee060a023 <unknown>
#13 0x561ee05d81aa <unknown>
#14 0x561ee062e6b8 <unknown>
#15 0x561ee062e847 <unknown>
#16 0x561ee063e243 <unknown>
#17 0x7f3bb584aea7 start_thread
[2023-07-07T13:54:17.269+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:54:17.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 6.453 seconds
[2023-07-07T13:54:47.331+0000] {processor.py:157} INFO - Started process (PID=32081) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:54:47.343+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:54:47.344+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:54:47.344+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:55:17.346+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:55:17.345+0000] {timeout.py:68} ERROR - Process timed out, PID: 32081
[2023-07-07T13:55:28.046+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:55:27.351+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 62, in __init__
    options=self.options,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 206, in __init__
    self.start_session(capabilities)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 291, in start_session
    response = self.execute(Command.NEW_SESSION, caps)["value"]
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py", line 344, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/remote_connection.py", line 290, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/remote/remote_connection.py", line 311, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/request.py", line 79, in request
    method, url, fields=fields, headers=headers, **urlopen_kw
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 721, in urlopen
    chunked=chunked,
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 466, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/home/airflow/.local/lib/python3.7/site-packages/urllib3/connectionpool.py", line 461, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/lib/python3.7/http/client.py", line 1373, in getresponse
    response.begin()
  File "/usr/local/lib/python3.7/http/client.py", line 319, in begin
    version, status, reason = self._read_status()
  File "/usr/local/lib/python3.7/http/client.py", line 280, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/dag_scrap_biobio.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.6.2/best-practices.html#reducing-dag-complexity, PID: 32081
[2023-07-07T13:55:28.047+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:55:28.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 40.780 seconds
[2023-07-07T13:55:29.563+0000] {processor.py:157} INFO - Started process (PID=32683) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:55:29.563+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:55:29.564+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:55:29.564+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:55:30.454+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6663114c20>
[2023-07-07T13:55:30.454+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T13:55:30.455+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T13:55:30.455+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T13:55:30.455+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T13:55:30.455+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T13:55:30.455+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T13:56:50.439+0000] {processor.py:157} INFO - Started process (PID=32723) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:56:50.446+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:56:50.446+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:56:50.446+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:56:51.110+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630e1050>
[2023-07-07T13:56:51.110+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T13:56:51.110+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T13:56:51.111+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T13:56:51.111+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T13:56:51.111+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T13:56:51.111+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T13:56:51.980+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:56:51.977+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T13:56:51.982+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:56:51.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.557 seconds
[2023-07-07T13:57:22.759+0000] {processor.py:157} INFO - Started process (PID=32749) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:57:22.764+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:57:22.765+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:57:22.764+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:57:23.418+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630e4710>
[2023-07-07T13:57:23.418+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T13:57:23.418+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T13:57:23.419+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T13:57:23.419+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T13:57:23.419+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T13:57:23.419+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T13:57:24.277+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:57:24.276+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T13:57:24.279+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:57:24.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.537 seconds
[2023-07-07T13:57:55.079+0000] {processor.py:157} INFO - Started process (PID=32775) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:57:55.084+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:57:55.085+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:57:55.085+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:57:55.738+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630df9e0>
[2023-07-07T13:57:55.738+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T13:57:55.739+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T13:57:55.739+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T13:57:55.739+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T13:57:55.739+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T13:57:55.739+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T13:57:56.598+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:57:56.596+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T13:57:56.600+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:57:56.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.535 seconds
[2023-07-07T13:58:27.396+0000] {processor.py:157} INFO - Started process (PID=32801) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:58:27.403+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:58:27.404+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:58:27.403+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:58:28.058+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630e3b00>
[2023-07-07T13:58:28.058+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T13:58:28.058+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T13:58:28.059+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T13:58:28.059+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T13:58:28.059+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T13:58:28.059+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T13:58:28.917+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:58:28.915+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T13:58:28.918+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:58:28.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.540 seconds
[2023-07-07T13:58:59.719+0000] {processor.py:157} INFO - Started process (PID=32827) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:58:59.725+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:58:59.725+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:58:59.725+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:59:00.379+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630e4e60>
[2023-07-07T13:59:00.379+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T13:59:00.379+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T13:59:00.380+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T13:59:00.380+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T13:59:00.380+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T13:59:00.380+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T13:59:01.238+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:59:01.236+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T13:59:01.239+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:59:01.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.533 seconds
[2023-07-07T13:59:32.061+0000] {processor.py:157} INFO - Started process (PID=32853) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:59:32.067+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:59:32.067+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:59:32.067+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:59:32.718+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa4680>
[2023-07-07T13:59:32.718+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T13:59:32.718+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T13:59:32.718+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T13:59:32.718+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T13:59:32.719+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T13:59:32.719+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T13:59:33.575+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:59:33.573+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T13:59:33.576+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:59:33.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.529 seconds
[2023-07-07T13:59:33.674+0000] {processor.py:157} INFO - Started process (PID=32873) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:59:33.675+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T13:59:33.675+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:59:33.675+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:59:34.325+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fe8290>
[2023-07-07T13:59:34.325+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T13:59:34.325+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T13:59:34.326+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T13:59:34.326+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T13:59:34.326+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T13:59:34.326+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T13:59:35.181+0000] {logging_mixin.py:149} INFO - [2023-07-07T13:59:35.179+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T13:59:35.182+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T13:59:35.197+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.525 seconds
[2023-07-07T14:00:06.060+0000] {processor.py:157} INFO - Started process (PID=32909) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:00:06.065+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:00:06.066+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:00:06.066+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:00:06.720+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630d7cb0>
[2023-07-07T14:00:06.720+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:00:06.720+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:00:06.721+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:00:06.721+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:00:06.721+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:00:06.721+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:00:07.578+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:00:07.577+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:00:07.580+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:00:07.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.539 seconds
[2023-07-07T14:00:38.336+0000] {processor.py:157} INFO - Started process (PID=32935) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:00:38.337+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:00:38.337+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:00:38.337+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:00:38.989+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630dacb0>
[2023-07-07T14:00:38.989+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:00:38.989+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:00:38.989+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:00:38.990+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:00:38.990+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:00:38.990+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:00:39.895+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:00:39.894+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:00:39.897+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:00:39.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.579 seconds
[2023-07-07T14:01:10.712+0000] {processor.py:157} INFO - Started process (PID=32961) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:01:10.722+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:01:10.722+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:01:10.722+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:01:11.379+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630df4d0>
[2023-07-07T14:01:11.379+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:01:11.379+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:01:11.380+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:01:11.380+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:01:11.380+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:01:11.380+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:01:12.235+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:01:12.233+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:01:12.237+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:01:12.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.545 seconds
[2023-07-07T14:01:42.991+0000] {processor.py:157} INFO - Started process (PID=32987) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:01:42.993+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:01:42.993+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:01:42.993+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:01:43.646+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630e1d40>
[2023-07-07T14:01:43.646+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:01:43.646+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:01:43.647+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:01:43.647+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:01:43.647+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:01:43.647+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:01:44.504+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:01:44.502+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:01:44.506+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:01:44.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.535 seconds
[2023-07-07T14:02:15.269+0000] {processor.py:157} INFO - Started process (PID=33013) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:02:15.275+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:02:15.276+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:02:15.276+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:02:15.929+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630e03b0>
[2023-07-07T14:02:15.929+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:02:15.929+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:02:15.929+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:02:15.930+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:02:15.930+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:02:15.930+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:02:16.783+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:02:16.782+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:02:16.785+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:02:16.802+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.534 seconds
[2023-07-07T14:02:47.564+0000] {processor.py:157} INFO - Started process (PID=33039) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:02:47.573+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:02:47.573+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:02:47.573+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:02:48.224+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630e27a0>
[2023-07-07T14:02:48.224+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:02:48.224+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:02:48.225+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:02:48.225+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:02:48.225+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:02:48.225+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:02:49.078+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:02:49.077+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:02:49.080+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:02:49.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.530 seconds
[2023-07-07T14:03:19.962+0000] {processor.py:157} INFO - Started process (PID=33065) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:03:19.971+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:03:19.971+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:03:19.971+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:03:20.622+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630e4d40>
[2023-07-07T14:03:20.622+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:03:20.622+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:03:20.622+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:03:20.622+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:03:20.623+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:03:20.623+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:03:21.478+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:03:21.476+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:03:21.480+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:03:21.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.544 seconds
[2023-07-07T14:03:52.196+0000] {processor.py:157} INFO - Started process (PID=33091) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:03:52.201+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:03:52.201+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:03:52.201+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:03:52.858+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa44d0>
[2023-07-07T14:03:52.859+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:03:52.859+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:03:52.859+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:03:52.859+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:03:52.859+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:03:52.860+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:03:53.714+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:03:53.712+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:03:53.716+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:03:53.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.540 seconds
[2023-07-07T14:04:24.439+0000] {processor.py:157} INFO - Started process (PID=33117) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:04:24.450+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:04:24.451+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:04:24.451+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:04:25.109+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630e5710>
[2023-07-07T14:04:25.109+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:04:25.109+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:04:25.110+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:04:25.110+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:04:25.110+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:04:25.110+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:04:25.964+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:04:25.962+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:04:25.966+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:04:25.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.541 seconds
[2023-07-07T14:04:56.790+0000] {processor.py:157} INFO - Started process (PID=33143) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:04:56.800+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:04:56.800+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:04:56.800+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:04:57.460+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630e6320>
[2023-07-07T14:04:57.460+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:04:57.460+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:04:57.460+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:04:57.460+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:04:57.461+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:04:57.461+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:04:58.315+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:04:58.313+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:04:58.317+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:04:58.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.551 seconds
[2023-07-07T14:05:29.103+0000] {processor.py:157} INFO - Started process (PID=33169) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:05:29.108+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:05:29.108+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:05:29.108+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:05:29.759+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630e7d40>
[2023-07-07T14:05:29.760+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:05:29.760+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:05:29.760+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:05:29.760+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:05:29.760+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:05:29.760+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:05:30.615+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:05:30.613+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:05:30.617+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:05:30.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.533 seconds
[2023-07-07T14:06:01.363+0000] {processor.py:157} INFO - Started process (PID=33195) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:06:01.372+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:06:01.372+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:06:01.372+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:06:02.025+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa74d0>
[2023-07-07T14:06:02.025+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:06:02.026+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:06:02.026+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:06:02.026+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:06:02.026+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:06:02.026+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:06:02.887+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:06:02.885+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:06:02.888+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:06:02.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.549 seconds
[2023-07-07T14:06:33.625+0000] {processor.py:157} INFO - Started process (PID=33221) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:06:33.635+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:06:33.636+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:06:33.636+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:06:34.289+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa68c0>
[2023-07-07T14:06:34.289+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:06:34.289+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:06:34.290+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:06:34.290+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:06:34.290+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:06:34.290+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:06:35.143+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:06:35.141+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:06:35.145+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:06:35.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.538 seconds
[2023-07-07T14:07:05.894+0000] {processor.py:157} INFO - Started process (PID=33247) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:07:05.900+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:07:05.900+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:07:05.900+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:07:06.549+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa8200>
[2023-07-07T14:07:06.549+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:07:06.549+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:07:06.549+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:07:06.550+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:07:06.550+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:07:06.550+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:07:07.402+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:07:07.401+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:07:07.404+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:07:07.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.531 seconds
[2023-07-07T14:07:38.161+0000] {processor.py:157} INFO - Started process (PID=33280) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:07:38.166+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:07:38.167+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:07:38.167+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:07:38.816+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662faa560>
[2023-07-07T14:07:38.816+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:07:38.816+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:07:38.817+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:07:38.817+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:07:38.817+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:07:38.817+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:07:39.673+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:07:39.671+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:07:39.674+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:07:39.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.534 seconds
[2023-07-07T14:08:10.604+0000] {processor.py:157} INFO - Started process (PID=33308) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:08:10.610+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:08:10.610+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:08:10.610+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:08:11.263+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa99e0>
[2023-07-07T14:08:11.263+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:08:11.263+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:08:11.263+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:08:11.264+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:08:11.264+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:08:11.264+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:08:12.121+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:08:12.120+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:08:12.123+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:08:12.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.541 seconds
[2023-07-07T14:08:42.801+0000] {processor.py:157} INFO - Started process (PID=33334) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:08:42.813+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:08:42.813+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:08:42.813+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:08:43.463+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa7950>
[2023-07-07T14:08:43.463+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:08:43.463+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:08:43.464+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:08:43.464+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:08:43.464+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:08:43.464+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:08:44.319+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:08:44.318+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:08:44.321+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:08:44.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.541 seconds
[2023-07-07T14:09:15.102+0000] {processor.py:157} INFO - Started process (PID=33360) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:09:15.109+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:09:15.109+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:09:15.109+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:09:15.764+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa7290>
[2023-07-07T14:09:15.764+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:09:15.764+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:09:15.765+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:09:15.765+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:09:15.765+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:09:15.765+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:09:16.622+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:09:16.620+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:09:16.623+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:09:16.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.539 seconds
[2023-07-07T14:09:47.318+0000] {processor.py:157} INFO - Started process (PID=33386) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:09:47.324+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:09:47.324+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:09:47.324+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:09:47.976+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa8560>
[2023-07-07T14:09:47.976+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:09:47.976+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:09:47.977+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:09:47.977+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:09:47.977+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:09:47.977+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:09:48.831+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:09:48.829+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:09:48.833+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:09:48.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.534 seconds
[2023-07-07T14:10:19.667+0000] {processor.py:157} INFO - Started process (PID=33412) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:10:19.672+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:10:19.673+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:10:19.673+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:10:20.319+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa9ef0>
[2023-07-07T14:10:20.319+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:10:20.319+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:10:20.320+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:10:20.320+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:10:20.320+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:10:20.320+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:10:21.175+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:10:21.173+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:10:21.176+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:10:21.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.534 seconds
[2023-07-07T14:10:51.957+0000] {processor.py:157} INFO - Started process (PID=33438) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:10:51.964+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:10:51.965+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:10:51.965+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:10:52.616+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa9320>
[2023-07-07T14:10:52.616+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:10:52.616+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:10:52.617+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:10:52.617+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:10:52.617+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:10:52.617+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:10:53.467+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:10:53.466+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:10:53.469+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:10:53.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.531 seconds
[2023-07-07T14:11:24.241+0000] {processor.py:157} INFO - Started process (PID=33464) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:11:24.246+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:11:24.246+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:11:24.246+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:11:24.894+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662faa7a0>
[2023-07-07T14:11:24.895+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:11:24.895+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:11:24.895+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:11:24.895+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:11:24.895+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:11:24.895+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:11:25.754+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:11:25.752+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:11:25.755+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:11:25.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.536 seconds
[2023-07-07T14:11:56.463+0000] {processor.py:157} INFO - Started process (PID=33490) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:11:56.469+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:11:56.470+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:11:56.470+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:11:57.118+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa9dd0>
[2023-07-07T14:11:57.118+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:11:57.118+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:11:57.118+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:11:57.118+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:11:57.119+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:11:57.119+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:11:57.975+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:11:57.973+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:11:57.977+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:11:57.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.539 seconds
[2023-07-07T14:12:28.781+0000] {processor.py:157} INFO - Started process (PID=33516) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:12:28.793+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:12:28.794+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:12:28.794+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:12:29.444+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fad3b0>
[2023-07-07T14:12:29.444+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:12:29.444+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:12:29.445+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:12:29.445+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:12:29.445+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:12:29.445+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:12:30.299+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:12:30.298+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:12:30.301+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:12:30.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.540 seconds
[2023-07-07T14:13:01.023+0000] {processor.py:157} INFO - Started process (PID=33542) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:13:01.029+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:13:01.029+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:13:01.029+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:13:01.684+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662faa7a0>
[2023-07-07T14:13:01.684+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:13:01.684+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:13:01.685+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:13:01.685+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:13:01.685+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:13:01.685+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:13:02.538+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:13:02.536+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:13:02.540+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:13:02.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.536 seconds
[2023-07-07T14:13:33.356+0000] {processor.py:157} INFO - Started process (PID=33568) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:13:33.365+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:13:33.366+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:13:33.366+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:13:34.016+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa9dd0>
[2023-07-07T14:13:34.016+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:13:34.016+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:13:34.017+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:13:34.017+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:13:34.017+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:13:34.017+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:13:34.871+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:13:34.869+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:13:34.872+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:13:34.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.541 seconds
[2023-07-07T14:14:05.593+0000] {processor.py:157} INFO - Started process (PID=33594) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:14:05.598+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:14:05.599+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:14:05.599+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:14:06.246+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fac200>
[2023-07-07T14:14:06.247+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:14:06.247+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:14:06.247+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:14:06.247+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:14:06.247+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:14:06.247+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:14:07.101+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:14:07.099+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:14:07.103+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:14:07.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.526 seconds
[2023-07-07T14:14:37.873+0000] {processor.py:157} INFO - Started process (PID=33620) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:14:37.879+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:14:37.879+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:14:37.879+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:14:38.531+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fabd40>
[2023-07-07T14:14:38.532+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:14:38.532+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:14:38.532+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:14:38.532+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:14:38.532+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:14:38.532+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:14:38.888+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:14:38.885+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 93, in start
    self._start_process(self._path)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 202, in _start_process
    **self.popen_kw,
  File "/usr/local/lib/python3.7/subprocess.py", line 800, in __init__
    restore_signals, start_new_session)
  File "/usr/local/lib/python3.7/subprocess.py", line 1498, in _execute_child
    restore_signals, start_new_session, preexec_fn)
BlockingIOError: [Errno 11] Resource temporarily unavailable
[2023-07-07T14:14:38.888+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:14:38.898+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.027 seconds
[2023-07-07T14:15:09.158+0000] {processor.py:157} INFO - Started process (PID=33650) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:15:09.165+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:15:09.166+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:15:09.166+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:15:09.818+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fab8c0>
[2023-07-07T14:15:09.818+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:15:09.818+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:15:09.818+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:15:09.818+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:15:09.819+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:15:09.819+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:15:10.673+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:15:10.671+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:15:10.675+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:15:10.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.540 seconds
[2023-07-07T14:15:41.436+0000] {processor.py:157} INFO - Started process (PID=33676) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:15:41.443+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:15:41.443+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:15:41.443+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:15:42.103+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662faaef0>
[2023-07-07T14:15:42.103+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:15:42.103+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:15:42.104+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:15:42.104+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:15:42.104+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:15:42.104+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:15:42.958+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:15:42.956+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:15:42.959+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:15:42.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.548 seconds
[2023-07-07T14:15:43.783+0000] {processor.py:157} INFO - Started process (PID=33695) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:15:43.783+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:15:43.784+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:15:43.784+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:15:44.360+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6663043b00>
[2023-07-07T14:15:44.360+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:15:44.361+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:15:44.361+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:15:44.361+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:15:44.361+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:15:44.361+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:15:45.230+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:15:45.228+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:15:45.232+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:15:45.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.469 seconds
[2023-07-07T14:16:16.168+0000] {processor.py:157} INFO - Started process (PID=33723) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:16:16.173+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:16:16.174+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:16:16.173+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:16:16.746+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fe8290>
[2023-07-07T14:16:16.746+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:16:16.746+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:16:16.747+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:16:16.747+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:16:16.747+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:16:16.747+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:16:17.616+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:16:17.614+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:16:17.617+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:16:17.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.471 seconds
[2023-07-07T14:16:48.482+0000] {processor.py:157} INFO - Started process (PID=33749) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:16:48.489+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:16:48.489+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:16:48.489+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:16:49.059+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fe83b0>
[2023-07-07T14:16:49.059+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:16:49.059+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:16:49.059+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:16:49.060+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:16:49.060+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:16:49.060+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:16:49.936+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:16:49.934+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:16:49.937+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:16:49.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.478 seconds
[2023-07-07T14:17:20.693+0000] {processor.py:157} INFO - Started process (PID=33775) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:17:20.698+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:17:20.698+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:17:20.698+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:17:21.267+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662feb4d0>
[2023-07-07T14:17:21.267+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:17:21.268+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:17:21.268+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:17:21.268+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:17:21.268+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:17:21.269+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:17:22.134+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:17:22.133+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:17:22.136+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:17:22.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.464 seconds
[2023-07-07T14:17:52.941+0000] {processor.py:157} INFO - Started process (PID=33801) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:17:52.948+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:17:52.948+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:17:52.948+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:17:53.519+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fe9ef0>
[2023-07-07T14:17:53.519+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:17:53.519+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:17:53.520+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:17:53.520+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:17:53.520+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:17:53.520+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:17:54.390+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:17:54.388+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:17:54.391+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:17:54.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.475 seconds
[2023-07-07T14:18:25.199+0000] {processor.py:157} INFO - Started process (PID=33863) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:18:25.205+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:18:25.205+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:18:25.205+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:18:25.774+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fec560>
[2023-07-07T14:18:25.775+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:18:25.775+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:18:25.775+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:18:25.775+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:18:25.775+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:18:25.776+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:18:26.646+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:18:26.644+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:18:26.647+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:18:26.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.483 seconds
[2023-07-07T14:18:57.445+0000] {processor.py:157} INFO - Started process (PID=33889) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:18:57.451+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:18:57.451+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:18:57.451+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:18:58.019+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fec8c0>
[2023-07-07T14:18:58.019+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:18:58.019+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:18:58.020+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:18:58.020+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:18:58.020+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:18:58.020+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:18:58.890+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:18:58.888+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:18:58.891+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:18:58.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.471 seconds
[2023-07-07T14:19:29.666+0000] {processor.py:157} INFO - Started process (PID=33915) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:19:29.672+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:19:29.672+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:19:29.672+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:19:30.249+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fee050>
[2023-07-07T14:19:30.249+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:19:30.250+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:19:30.250+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:19:30.250+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:19:30.250+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:19:30.250+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:19:31.123+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:19:31.121+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:19:31.124+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:19:31.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.486 seconds
[2023-07-07T14:20:01.913+0000] {processor.py:157} INFO - Started process (PID=33941) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:20:01.919+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:20:01.919+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:20:01.919+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:20:02.501+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fee050>
[2023-07-07T14:20:02.501+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:20:02.501+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:20:02.502+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:20:02.502+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:20:02.502+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:20:02.502+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:20:03.371+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:20:03.369+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:20:03.372+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:20:03.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.480 seconds
[2023-07-07T14:20:34.154+0000] {processor.py:157} INFO - Started process (PID=33967) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:20:34.160+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:20:34.160+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:20:34.160+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:20:34.730+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fef5f0>
[2023-07-07T14:20:34.730+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:20:34.730+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:20:34.730+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:20:34.730+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:20:34.731+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:20:34.731+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:20:35.609+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:20:35.607+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:20:35.610+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:20:35.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.476 seconds
[2023-07-07T14:21:06.473+0000] {processor.py:157} INFO - Started process (PID=33993) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:21:06.478+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:21:06.479+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:21:06.478+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:21:07.052+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fedf80>
[2023-07-07T14:21:07.053+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:21:07.053+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:21:07.053+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:21:07.053+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:21:07.053+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:21:07.053+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:21:07.922+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:21:07.920+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:21:07.924+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:21:07.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.465 seconds
[2023-07-07T14:21:38.746+0000] {processor.py:157} INFO - Started process (PID=34019) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:21:38.747+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:21:38.748+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:21:38.747+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:21:39.758+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662ff0d40>
[2023-07-07T14:21:39.758+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:21:39.758+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:21:39.759+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:21:39.759+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:21:39.759+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:21:39.759+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:21:41.164+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:21:41.161+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:21:41.166+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:21:41.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 2.441 seconds
[2023-07-07T14:22:12.043+0000] {processor.py:157} INFO - Started process (PID=34113) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:22:12.044+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:22:12.044+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:22:12.044+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:22:12.649+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662ff2830>
[2023-07-07T14:22:12.649+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:22:12.649+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:22:12.649+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:22:12.649+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:22:12.650+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:22:12.650+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:22:13.701+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:22:13.697+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:22:13.702+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:22:13.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.673 seconds
[2023-07-07T14:22:44.346+0000] {processor.py:157} INFO - Started process (PID=34139) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:22:44.356+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:22:44.356+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:22:44.356+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:22:44.928+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662ff3d40>
[2023-07-07T14:22:44.928+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:22:44.928+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:22:44.929+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:22:44.929+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:22:44.929+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:22:44.929+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:22:45.812+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:22:45.811+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:22:45.814+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:22:45.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.481 seconds
[2023-07-07T14:23:16.591+0000] {processor.py:157} INFO - Started process (PID=34165) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:23:16.600+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:23:16.600+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:23:16.600+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:23:17.170+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662ff50e0>
[2023-07-07T14:23:17.170+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:23:17.170+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:23:17.171+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:23:17.171+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:23:17.171+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:23:17.171+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:23:18.049+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:23:18.047+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:23:18.050+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:23:18.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.478 seconds
[2023-07-07T14:23:18.211+0000] {processor.py:157} INFO - Started process (PID=34184) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:23:18.212+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:23:18.212+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:23:18.212+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:23:18.800+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f666304ff80>
[2023-07-07T14:23:18.800+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:23:18.801+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:23:18.801+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:23:18.801+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:23:18.801+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:23:18.801+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:23:19.685+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:23:19.684+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:23:19.687+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:23:19.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.490 seconds
[2023-07-07T14:23:50.542+0000] {processor.py:157} INFO - Started process (PID=34213) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:23:50.542+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:23:50.543+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:23:50.543+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:23:51.115+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630007a0>
[2023-07-07T14:23:51.115+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:23:51.115+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:23:51.115+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:23:51.116+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:23:51.116+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:23:51.116+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:23:51.985+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:23:51.983+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:23:51.987+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:23:52.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.465 seconds
[2023-07-07T14:24:22.783+0000] {processor.py:157} INFO - Started process (PID=34239) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:24:22.784+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:24:22.785+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:24:22.785+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:24:23.358+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662ffce60>
[2023-07-07T14:24:23.358+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:24:23.358+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:24:23.358+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:24:23.359+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:24:23.359+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:24:23.359+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:24:24.235+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:24:24.233+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:24:24.236+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:24:24.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.472 seconds
[2023-07-07T14:24:54.977+0000] {processor.py:157} INFO - Started process (PID=34265) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:24:54.984+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:24:54.985+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:24:54.985+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:24:55.592+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6663000dd0>
[2023-07-07T14:24:55.592+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:24:55.592+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:24:55.593+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:24:55.593+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:24:55.593+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:24:55.593+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:24:56.479+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:24:56.477+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:24:56.481+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:24:56.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.527 seconds
[2023-07-07T14:25:27.210+0000] {processor.py:157} INFO - Started process (PID=34291) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:25:27.216+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:25:27.216+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:25:27.216+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:25:27.784+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630044d0>
[2023-07-07T14:25:27.785+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:25:27.785+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:25:27.785+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:25:27.785+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:25:27.785+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:25:27.786+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:25:28.663+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:25:28.661+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:25:28.664+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:25:28.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.478 seconds
[2023-07-07T14:25:59.424+0000] {processor.py:157} INFO - Started process (PID=34317) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:25:59.429+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:25:59.430+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:25:59.430+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:26:00.007+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6663007d40>
[2023-07-07T14:26:00.007+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:26:00.007+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:26:00.008+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:26:00.008+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:26:00.008+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:26:00.008+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:26:00.882+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:26:00.880+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:26:00.883+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:26:00.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.473 seconds
[2023-07-07T14:26:31.700+0000] {processor.py:157} INFO - Started process (PID=34343) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:26:31.705+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:26:31.706+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:26:31.706+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:26:32.282+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6663002f80>
[2023-07-07T14:26:32.282+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:26:32.282+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:26:32.282+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:26:32.282+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:26:32.283+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:26:32.283+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:26:33.154+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:26:33.152+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:26:33.156+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:26:33.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.473 seconds
[2023-07-07T14:27:03.957+0000] {processor.py:157} INFO - Started process (PID=34369) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:27:03.969+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:27:03.969+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:27:03.969+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:27:04.559+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6663006170>
[2023-07-07T14:27:04.559+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:27:04.559+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:27:04.559+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:27:04.559+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:27:04.560+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:27:04.560+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:27:05.438+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:27:05.435+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:27:05.439+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:27:05.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.502 seconds
[2023-07-07T14:27:36.120+0000] {processor.py:157} INFO - Started process (PID=34395) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:27:36.126+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:27:36.127+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:27:36.127+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:27:36.702+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6663008710>
[2023-07-07T14:27:36.702+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:27:36.702+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:27:36.703+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:27:36.703+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:27:36.703+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:27:36.703+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:27:37.591+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:27:37.589+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:27:37.592+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:27:37.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.489 seconds
[2023-07-07T14:28:08.318+0000] {processor.py:157} INFO - Started process (PID=34421) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:28:08.324+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:28:08.324+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:28:08.324+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:28:08.901+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f666300bd40>
[2023-07-07T14:28:08.901+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:28:08.901+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:28:08.902+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:28:08.902+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:28:08.902+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:28:08.902+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:28:09.782+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:28:09.780+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:28:09.784+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:28:09.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.480 seconds
[2023-07-07T14:28:40.534+0000] {processor.py:157} INFO - Started process (PID=34447) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:28:40.541+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:28:40.541+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:28:40.541+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:28:41.163+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630075f0>
[2023-07-07T14:28:41.163+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:28:41.164+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:28:41.164+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:28:41.164+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:28:41.164+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:28:41.164+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:28:42.062+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:28:42.060+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:28:42.064+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:28:42.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.548 seconds
[2023-07-07T14:29:12.730+0000] {processor.py:157} INFO - Started process (PID=34473) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:29:12.731+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:29:12.731+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:29:12.731+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:29:13.394+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630093b0>
[2023-07-07T14:29:13.394+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:29:13.394+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:29:13.395+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:29:13.395+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:29:13.395+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:29:13.395+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:29:14.194+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:29:14.192+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:29:14.195+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:29:14.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.480 seconds
[2023-07-07T14:29:45.001+0000] {processor.py:157} INFO - Started process (PID=34506) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:29:45.007+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:29:45.007+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:29:45.007+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:29:45.588+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f666300b710>
[2023-07-07T14:29:45.588+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:29:45.588+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:29:45.589+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:29:45.589+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:29:45.589+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:29:45.589+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:29:46.492+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:29:46.489+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:29:46.494+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:29:46.507+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.508 seconds
[2023-07-07T14:30:17.276+0000] {processor.py:157} INFO - Started process (PID=34532) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:30:17.281+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:30:17.281+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:30:17.281+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:30:17.933+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630d2dd0>
[2023-07-07T14:30:17.933+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:30:17.933+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:30:17.933+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:30:17.934+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:30:17.934+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:30:17.934+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:30:18.724+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:30:18.722+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:30:18.725+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:30:18.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.466 seconds
[2023-07-07T14:30:49.501+0000] {processor.py:157} INFO - Started process (PID=34558) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:30:49.507+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:30:49.507+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:30:49.507+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:30:50.082+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f666300a050>
[2023-07-07T14:30:50.082+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:30:50.082+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:30:50.082+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:30:50.082+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:30:50.083+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:30:50.083+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:30:50.957+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:30:50.955+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:30:50.958+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:30:50.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.480 seconds
[2023-07-07T14:31:21.743+0000] {processor.py:157} INFO - Started process (PID=34584) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:31:21.748+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:31:21.749+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:31:21.749+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:31:22.398+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f666300a290>
[2023-07-07T14:31:22.398+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:31:22.398+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:31:22.399+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:31:22.399+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:31:22.399+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:31:22.399+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:31:23.194+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:31:23.193+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:31:23.196+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:31:23.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.470 seconds
[2023-07-07T14:31:54.118+0000] {processor.py:157} INFO - Started process (PID=34612) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:31:54.124+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:31:54.124+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:31:54.124+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:31:54.698+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f666300b290>
[2023-07-07T14:31:54.698+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:31:54.698+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:31:54.698+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:31:54.698+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:31:54.699+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:31:54.699+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:31:55.573+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:31:55.572+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:31:55.575+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:31:55.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.470 seconds
[2023-07-07T14:32:26.408+0000] {processor.py:157} INFO - Started process (PID=34638) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:32:26.418+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:32:26.418+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:32:26.418+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:32:27.058+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f666300c3b0>
[2023-07-07T14:32:27.059+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:32:27.059+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:32:27.059+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:32:27.059+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:32:27.059+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:32:27.059+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:32:27.856+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:32:27.855+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:32:27.858+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:32:27.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.471 seconds
[2023-07-07T14:32:58.590+0000] {processor.py:157} INFO - Started process (PID=34664) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:32:58.601+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:32:58.601+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:32:58.601+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:32:59.169+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630098c0>
[2023-07-07T14:32:59.169+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:32:59.169+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:32:59.170+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:32:59.170+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:32:59.170+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:32:59.170+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:33:00.044+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:33:00.043+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:33:00.046+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:33:00.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.476 seconds
[2023-07-07T14:33:30.811+0000] {processor.py:157} INFO - Started process (PID=34690) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:33:30.817+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:33:30.817+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:33:30.817+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:33:31.464+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f666300a050>
[2023-07-07T14:33:31.464+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:33:31.464+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:33:31.465+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:33:31.465+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:33:31.465+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:33:31.465+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:33:32.255+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:33:32.253+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:33:32.257+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:33:32.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.467 seconds
[2023-07-07T14:34:03.052+0000] {processor.py:157} INFO - Started process (PID=34716) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:34:03.057+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:34:03.058+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:34:03.058+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:34:03.631+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f666300c680>
[2023-07-07T14:34:03.631+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:34:03.631+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:34:03.631+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:34:03.631+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:34:03.632+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:34:03.632+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:34:04.515+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:34:04.513+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:34:04.516+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:34:04.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.485 seconds
[2023-07-07T14:34:35.268+0000] {processor.py:157} INFO - Started process (PID=34742) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:34:35.273+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:34:35.273+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:34:35.273+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:34:35.920+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630d2dd0>
[2023-07-07T14:34:35.920+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:34:35.920+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:34:35.921+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:34:35.921+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:34:35.921+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:34:35.921+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:34:36.718+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:34:36.716+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:34:36.720+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:34:36.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.470 seconds
[2023-07-07T14:35:07.446+0000] {processor.py:157} INFO - Started process (PID=34768) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:35:07.452+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:35:07.453+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:35:07.453+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:35:08.024+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f666300b0e0>
[2023-07-07T14:35:08.024+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:35:08.024+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:35:08.025+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:35:08.025+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:35:08.025+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:35:08.025+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:35:08.919+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:35:08.917+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:35:08.921+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:35:08.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.489 seconds
[2023-07-07T14:35:39.733+0000] {processor.py:157} INFO - Started process (PID=34794) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:35:39.734+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:35:39.734+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:35:39.734+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:35:40.428+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f666300c0e0>
[2023-07-07T14:35:40.428+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:35:40.429+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:35:40.429+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:35:40.429+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:35:40.429+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:35:40.429+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:35:41.246+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:35:41.245+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:35:41.248+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:35:41.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.635 seconds
[2023-07-07T14:36:11.985+0000] {processor.py:157} INFO - Started process (PID=34820) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:36:11.990+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:36:11.991+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:36:11.991+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:36:12.582+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f666300c5f0>
[2023-07-07T14:36:12.583+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:36:12.583+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:36:12.583+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:36:12.584+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:36:12.584+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:36:12.584+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:36:13.507+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:36:13.505+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:36:13.508+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:36:13.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.537 seconds
[2023-07-07T14:36:44.181+0000] {processor.py:157} INFO - Started process (PID=34846) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:36:44.187+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:36:44.187+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:36:44.187+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:36:44.898+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630d2dd0>
[2023-07-07T14:36:44.898+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:36:44.898+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:36:44.899+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:36:44.899+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:36:44.899+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:36:44.899+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:36:45.710+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:36:45.708+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:36:45.712+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:36:45.724+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.545 seconds
[2023-07-07T14:37:16.380+0000] {processor.py:157} INFO - Started process (PID=34915) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:37:16.385+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:37:16.385+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:37:16.385+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:37:16.954+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f666300a050>
[2023-07-07T14:37:16.954+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:37:16.954+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:37:16.955+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:37:16.955+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:37:16.955+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:37:16.955+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:37:17.855+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:37:17.853+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:37:17.856+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:37:17.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.499 seconds
[2023-07-07T14:37:48.578+0000] {processor.py:157} INFO - Started process (PID=34941) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:37:48.579+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:37:48.579+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:37:48.579+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:37:49.227+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f666300b440>
[2023-07-07T14:37:49.227+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:37:49.227+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:37:49.228+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:37:49.228+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:37:49.228+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:37:49.228+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:37:50.025+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:37:50.023+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:37:50.026+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:37:50.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.468 seconds
[2023-07-07T14:38:20.879+0000] {processor.py:157} INFO - Started process (PID=34967) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:38:20.885+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:38:20.885+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:38:20.885+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:38:21.456+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f666300c320>
[2023-07-07T14:38:21.456+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:38:21.456+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:38:21.456+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:38:21.456+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:38:21.457+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:38:21.457+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:38:22.329+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:38:22.327+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:38:22.330+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:38:22.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.470 seconds
[2023-07-07T14:38:49.069+0000] {processor.py:157} INFO - Started process (PID=34993) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:38:49.075+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:38:49.076+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:38:49.076+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:38:49.726+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f666300e050>
[2023-07-07T14:38:49.727+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:38:49.727+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:38:49.727+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:38:49.727+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:38:49.727+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:38:49.728+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:38:50.518+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:38:50.516+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:38:50.520+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:38:50.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.462 seconds
[2023-07-07T14:39:20.314+0000] {processor.py:157} INFO - Started process (PID=35019) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:39:20.320+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:39:20.320+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:39:20.320+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:39:20.890+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6663008c20>
[2023-07-07T14:39:20.890+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:39:20.891+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:39:20.891+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:39:20.891+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:39:20.891+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:39:20.891+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:39:21.769+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:39:21.767+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:39:21.770+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:39:21.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.473 seconds
[2023-07-07T14:39:52.513+0000] {processor.py:157} INFO - Started process (PID=35045) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:39:52.514+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:39:52.514+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:39:52.514+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:39:53.201+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f666300b440>
[2023-07-07T14:39:53.201+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:39:53.201+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:39:53.202+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:39:53.202+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:39:53.202+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:39:53.202+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:39:54.007+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:39:54.005+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:39:54.008+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:39:54.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.508 seconds
[2023-07-07T14:40:24.818+0000] {processor.py:157} INFO - Started process (PID=35071) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:40:24.822+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:40:24.823+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:40:24.823+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:40:25.419+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f666300c710>
[2023-07-07T14:40:25.419+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:40:25.419+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:40:25.420+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:40:25.420+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:40:25.420+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:40:25.420+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:40:26.307+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:40:26.305+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:40:26.308+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:40:26.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.504 seconds
[2023-07-07T14:40:26.592+0000] {processor.py:157} INFO - Started process (PID=35090) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:40:26.592+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:40:26.593+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:40:26.592+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:40:27.253+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fe7200>
[2023-07-07T14:40:27.253+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:40:27.253+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:40:27.254+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:40:27.254+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:40:27.254+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:40:27.254+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:40:28.055+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:40:28.053+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:40:28.056+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:40:28.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.482 seconds
[2023-07-07T14:40:58.942+0000] {processor.py:157} INFO - Started process (PID=35118) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:40:58.948+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:40:58.948+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:40:58.948+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:40:59.589+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630d88c0>
[2023-07-07T14:40:59.589+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:40:59.589+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:40:59.590+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:40:59.590+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:40:59.590+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:40:59.590+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:41:00.387+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:41:00.386+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:41:00.389+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:41:00.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.462 seconds
[2023-07-07T14:41:31.191+0000] {processor.py:157} INFO - Started process (PID=35144) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:41:31.196+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:41:31.196+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:41:31.196+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:41:31.845+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630dbcb0>
[2023-07-07T14:41:31.846+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:41:31.846+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:41:31.846+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:41:31.846+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:41:31.846+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:41:31.847+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:41:32.646+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:41:32.645+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:41:32.648+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:41:32.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.476 seconds
[2023-07-07T14:42:03.432+0000] {processor.py:157} INFO - Started process (PID=35170) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:42:03.441+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:42:03.441+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:42:03.441+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:42:04.082+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630df4d0>
[2023-07-07T14:42:04.082+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:42:04.082+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:42:04.082+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:42:04.083+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:42:04.083+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:42:04.083+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:42:04.874+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:42:04.872+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:42:04.875+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:42:04.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.457 seconds
[2023-07-07T14:42:35.670+0000] {processor.py:157} INFO - Started process (PID=35196) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:42:35.676+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:42:35.676+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:42:35.676+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:42:36.322+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630e0d40>
[2023-07-07T14:42:36.322+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:42:36.322+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:42:36.323+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:42:36.323+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:42:36.323+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:42:36.323+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:42:37.113+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:42:37.111+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:42:37.115+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:42:37.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.463 seconds
[2023-07-07T14:43:07.897+0000] {processor.py:157} INFO - Started process (PID=35222) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:43:07.903+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:43:07.903+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:43:07.903+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:43:08.548+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630e03b0>
[2023-07-07T14:43:08.548+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:43:08.548+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:43:08.549+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:43:08.549+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:43:08.549+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:43:08.549+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:43:09.343+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:43:09.341+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:43:09.344+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:43:09.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.483 seconds
[2023-07-07T14:43:40.119+0000] {processor.py:157} INFO - Started process (PID=35248) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:43:40.120+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:43:40.120+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:43:40.120+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:43:40.767+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630e2a70>
[2023-07-07T14:43:40.767+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:43:40.767+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:43:40.768+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:43:40.768+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:43:40.768+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:43:40.768+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:43:41.562+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:43:41.561+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:43:41.564+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:43:41.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.467 seconds
[2023-07-07T14:44:12.338+0000] {processor.py:157} INFO - Started process (PID=35274) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:44:12.348+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:44:12.348+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:44:12.348+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:44:12.986+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630e4e60>
[2023-07-07T14:44:12.986+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:44:12.986+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:44:12.987+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:44:12.987+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:44:12.987+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:44:12.987+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:44:13.778+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:44:13.776+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:44:13.780+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:44:13.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.461 seconds
[2023-07-07T14:44:44.605+0000] {processor.py:157} INFO - Started process (PID=35300) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:44:44.617+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:44:44.617+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:44:44.617+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:44:45.256+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa53b0>
[2023-07-07T14:44:45.256+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:44:45.257+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:44:45.257+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:44:45.257+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:44:45.257+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:44:45.258+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:44:46.047+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:44:46.046+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:44:46.049+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:44:46.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.463 seconds
[2023-07-07T14:45:16.809+0000] {processor.py:157} INFO - Started process (PID=35333) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:45:16.815+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:45:16.816+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:45:16.816+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:45:17.469+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630e6680>
[2023-07-07T14:45:17.470+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:45:17.470+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:45:17.470+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:45:17.470+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:45:17.470+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:45:17.471+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:45:18.259+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:45:18.258+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:45:18.261+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:45:18.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.470 seconds
[2023-07-07T14:45:49.047+0000] {processor.py:157} INFO - Started process (PID=35359) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:45:49.052+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:45:49.053+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:45:49.053+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:45:49.691+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630e6560>
[2023-07-07T14:45:49.691+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:45:49.691+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:45:49.692+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:45:49.692+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:45:49.692+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:45:49.692+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:45:50.479+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:45:50.477+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:45:50.480+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:45:50.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.454 seconds
[2023-07-07T14:46:21.275+0000] {processor.py:157} INFO - Started process (PID=35385) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:46:21.282+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:46:21.282+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:46:21.282+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:46:21.919+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630e7d40>
[2023-07-07T14:46:21.919+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:46:21.919+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:46:21.920+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:46:21.920+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:46:21.920+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:46:21.920+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:46:22.715+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:46:22.713+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:46:22.716+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:46:22.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.459 seconds
[2023-07-07T14:46:53.488+0000] {processor.py:157} INFO - Started process (PID=35411) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:46:53.495+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:46:53.495+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:46:53.495+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:46:54.152+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa8440>
[2023-07-07T14:46:54.153+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:46:54.153+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:46:54.153+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:46:54.153+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:46:54.153+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:46:54.153+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:46:54.942+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:46:54.940+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:46:54.944+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:46:54.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.474 seconds
[2023-07-07T14:47:25.730+0000] {processor.py:157} INFO - Started process (PID=35437) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:47:25.735+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:47:25.736+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:47:25.736+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:47:26.377+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa47a0>
[2023-07-07T14:47:26.377+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:47:26.378+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:47:26.378+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:47:26.378+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:47:26.378+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:47:26.378+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:47:27.172+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:47:27.170+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:47:27.173+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:47:27.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.457 seconds
[2023-07-07T14:47:57.973+0000] {processor.py:157} INFO - Started process (PID=35463) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:47:57.979+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:47:57.979+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:47:57.979+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:47:58.618+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa70e0>
[2023-07-07T14:47:58.618+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:47:58.618+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:47:58.619+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:47:58.619+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:47:58.619+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:47:58.619+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:47:59.408+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:47:59.406+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:47:59.409+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:47:59.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.459 seconds
[2023-07-07T14:48:30.284+0000] {processor.py:157} INFO - Started process (PID=35489) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:48:30.289+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:48:30.290+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:48:30.290+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:48:30.929+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa7050>
[2023-07-07T14:48:30.929+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:48:30.929+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:48:30.930+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:48:30.930+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:48:30.930+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:48:30.930+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:48:31.719+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:48:31.717+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:48:31.721+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:48:31.743+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.461 seconds
[2023-07-07T14:49:02.629+0000] {processor.py:157} INFO - Started process (PID=35517) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:49:02.640+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:49:02.640+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:49:02.640+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:49:03.291+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa9710>
[2023-07-07T14:49:03.291+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:49:03.291+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:49:03.292+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:49:03.292+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:49:03.292+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:49:03.292+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:49:04.079+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:49:04.077+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:49:04.081+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:49:04.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.474 seconds
[2023-07-07T14:49:34.867+0000] {processor.py:157} INFO - Started process (PID=35543) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:49:34.874+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:49:34.874+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:49:34.874+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:49:35.517+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa7560>
[2023-07-07T14:49:35.517+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:49:35.517+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:49:35.518+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:49:35.518+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:49:35.518+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:49:35.518+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:49:36.311+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:49:36.309+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:49:36.312+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:49:36.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.460 seconds
[2023-07-07T14:50:07.081+0000] {processor.py:157} INFO - Started process (PID=35569) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:50:07.091+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:50:07.091+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:50:07.091+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:50:07.747+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa6170>
[2023-07-07T14:50:07.748+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:50:07.748+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:50:07.748+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:50:07.748+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:50:07.748+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:50:07.748+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:50:08.543+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:50:08.541+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:50:08.544+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:50:08.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.477 seconds
[2023-07-07T14:50:39.317+0000] {processor.py:157} INFO - Started process (PID=35595) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:50:39.323+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:50:39.323+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:50:39.323+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:50:39.968+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa7170>
[2023-07-07T14:50:39.968+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:50:39.968+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:50:39.968+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:50:39.968+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:50:39.969+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:50:39.969+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:50:40.760+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:50:40.758+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 225, in <module>
    dag = ScrapAndStoreData()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 3604, in factory
    f(**f_kwargs)
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 47, in ScrapAndStoreData
    browser = webdriver.Chrome(options=options)
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py", line 54, in __init__
    self.keep_alive,
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/chromium/webdriver.py", line 51, in __init__
    self.service.start()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 97, in start
    self.assert_process_still_running()
  File "/home/airflow/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py", line 110, in assert_process_still_running
    raise WebDriverException(f"Service {self._path} unexpectedly exited. Status code was: {return_code}")
selenium.common.exceptions.WebDriverException: Message: Service /chromedriver/chromedriver unexpectedly exited. Status code was: -5
[2023-07-07T14:50:40.761+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:50:40.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.465 seconds
[2023-07-07T14:50:49.405+0000] {processor.py:157} INFO - Started process (PID=35619) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:50:49.417+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:50:49.418+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:50:49.418+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:50:50.071+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa4cb0>
[2023-07-07T14:50:50.071+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:50:50.071+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:50:50.071+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:50:50.071+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:50:50.072+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:50:50.072+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:50:50.352+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:50:50.475+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:50:50.474+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T14:50:50.494+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:50:50.494+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T14:50:50.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.189 seconds
[2023-07-07T14:51:16.651+0000] {processor.py:157} INFO - Started process (PID=35634) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:51:16.652+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:51:16.652+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:51:16.652+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:51:17.308+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6663150c20>
[2023-07-07T14:51:17.308+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:51:17.308+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:51:17.309+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:51:17.309+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:51:17.309+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:51:17.309+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:51:17.597+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:51:17.603+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:51:17.603+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T14:51:17.618+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:51:17.618+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T14:51:17.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.980 seconds
[2023-07-07T14:51:26.709+0000] {processor.py:157} INFO - Started process (PID=35654) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:51:26.709+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:51:26.710+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:51:26.710+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:51:27.361+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa50e0>
[2023-07-07T14:51:27.361+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:51:27.361+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:51:27.361+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:51:27.362+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:51:27.362+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:51:27.362+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:51:27.658+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:51:27.675+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:51:27.674+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T14:51:27.690+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:51:27.690+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T14:51:27.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.994 seconds
[2023-07-07T14:51:29.732+0000] {processor.py:157} INFO - Started process (PID=35667) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:51:29.733+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:51:29.733+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:51:29.733+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:51:30.384+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f66630e7d40>
[2023-07-07T14:51:30.384+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:51:30.384+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:51:30.385+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:51:30.385+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:51:30.385+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:51:30.385+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:51:30.667+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:51:30.685+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:51:30.685+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T14:51:30.700+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:51:30.700+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T14:51:30.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.981 seconds
[2023-07-07T14:51:43.842+0000] {processor.py:157} INFO - Started process (PID=35682) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:51:43.848+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:51:43.849+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:51:43.848+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:51:44.500+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa4950>
[2023-07-07T14:51:44.500+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:51:44.500+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:51:44.500+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:51:44.500+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:51:44.501+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:51:44.501+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:51:44.786+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:51:44.803+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:51:44.803+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T14:51:44.818+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:51:44.818+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T14:51:44.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.995 seconds
[2023-07-07T14:51:48.886+0000] {processor.py:157} INFO - Started process (PID=35702) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:51:48.891+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:51:48.891+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:51:48.891+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:51:49.545+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa53b0>
[2023-07-07T14:51:49.545+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:51:49.545+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:51:49.546+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:51:49.546+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:51:49.546+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:51:49.546+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:51:49.836+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:51:49.853+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:51:49.853+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T14:51:49.868+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:51:49.867+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T14:51:49.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.995 seconds
[2023-07-07T14:52:20.100+0000] {processor.py:157} INFO - Started process (PID=35724) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:52:20.106+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:52:20.106+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:52:20.106+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:52:20.810+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa6170>
[2023-07-07T14:52:20.810+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:52:20.810+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:52:20.810+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:52:20.811+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:52:20.811+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:52:20.811+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:52:21.099+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:52:21.117+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:52:21.117+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T14:52:21.132+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:52:21.132+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T14:52:21.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.043 seconds
[2023-07-07T14:52:26.161+0000] {processor.py:157} INFO - Started process (PID=35737) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:52:26.161+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:52:26.162+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:52:26.161+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:52:26.815+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa49e0>
[2023-07-07T14:52:26.816+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:52:26.816+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:52:26.816+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:52:26.816+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:52:26.816+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:52:26.816+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:52:27.102+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:52:27.259+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:52:27.259+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T14:52:27.275+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:52:27.275+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T14:52:27.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.130 seconds
[2023-07-07T14:52:57.397+0000] {processor.py:157} INFO - Started process (PID=35759) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:52:57.397+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:52:57.397+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:52:57.397+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:52:58.063+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa6710>
[2023-07-07T14:52:58.063+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:52:58.063+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:52:58.063+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:52:58.063+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:52:58.064+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:52:58.064+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:52:58.360+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:52:58.377+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:52:58.376+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T14:52:58.394+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:52:58.393+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T14:52:58.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.010 seconds
[2023-07-07T14:53:28.696+0000] {processor.py:157} INFO - Started process (PID=35781) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:53:28.702+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:53:28.702+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:53:28.702+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:53:29.367+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa7560>
[2023-07-07T14:53:29.368+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:53:29.368+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:53:29.368+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:53:29.368+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:53:29.368+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:53:29.368+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:53:29.667+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:53:29.686+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:53:29.685+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T14:53:29.702+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:53:29.702+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T14:53:29.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.028 seconds
[2023-07-07T14:53:59.982+0000] {processor.py:157} INFO - Started process (PID=35803) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:53:59.983+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:53:59.983+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:53:59.983+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:54:00.684+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fa98c0>
[2023-07-07T14:54:00.684+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:54:00.684+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:54:00.684+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:54:00.684+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:54:00.685+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:54:00.685+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:54:00.967+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:54:00.984+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:54:00.984+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T14:54:01.000+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:54:01.000+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T14:54:01.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.031 seconds
[2023-07-07T14:54:31.229+0000] {processor.py:157} INFO - Started process (PID=35825) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:54:31.235+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T14:54:31.235+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:54:31.235+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:54:32.014+0000] {logging_mixin.py:149} WARNING - Exception ignored in: <function Group.__del__ at 0x7f6662fab050>
[2023-07-07T14:54:32.014+0000] {logging_mixin.py:149} WARNING - Traceback (most recent call last):
[2023-07-07T14:54:32.014+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/regex/_regex_core.py", line 3038, in __del__
[2023-07-07T14:54:32.015+0000] {logging_mixin.py:149} WARNING -     def __del__(self):
[2023-07-07T14:54:32.015+0000] {logging_mixin.py:149} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/manager.py", line 475, in _exit_gracefully
[2023-07-07T14:54:32.015+0000] {logging_mixin.py:149} WARNING -     sys.exit(os.EX_OK)
[2023-07-07T14:54:32.015+0000] {logging_mixin.py:149} WARNING - SystemExit: 0
[2023-07-07T14:54:32.311+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T14:54:32.330+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:54:32.329+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T14:54:32.345+0000] {logging_mixin.py:149} INFO - [2023-07-07T14:54:32.345+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T14:54:32.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.136 seconds
[2023-07-07T15:05:27.553+0000] {processor.py:157} INFO - Started process (PID=31) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:05:27.554+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:05:27.554+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:05:27.554+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:05:28.476+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:05:28.669+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:05:28.669+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:dag_scrap_biobio_v2
[2023-07-07T15:05:28.699+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:05:28.699+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:dag_scrap_biobio_v2
[2023-07-07T15:05:28.760+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:05:28.759+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:dag_scrap_biobio_v2
[2023-07-07T15:05:28.775+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:05:28.774+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:05:28.784+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:05:28.784+0000] {dag.py:2747} INFO - Creating ORM DAG for dag_scrap_biobio_v2
[2023-07-07T15:05:28.793+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:05:28.793+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T15:05:28.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.312 seconds
[2023-07-07T15:05:59.199+0000] {processor.py:157} INFO - Started process (PID=55) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:05:59.204+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:05:59.204+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:05:59.204+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:05:59.986+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:06:00.003+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:06:00.003+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:06:00.023+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:06:00.023+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T15:06:00.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.839 seconds
[2023-07-07T15:06:30.479+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:06:30.484+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:06:30.485+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:06:30.484+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:06:31.246+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:06:31.263+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:06:31.263+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:06:31.280+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:06:31.280+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T15:06:31.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.814 seconds
[2023-07-07T15:07:01.869+0000] {processor.py:157} INFO - Started process (PID=99) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:07:01.874+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:07:01.875+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:07:01.875+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:07:02.595+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:07:02.618+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:07:02.618+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:07:02.638+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:07:02.638+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T15:07:02.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.788 seconds
[2023-07-07T15:07:33.141+0000] {processor.py:157} INFO - Started process (PID=121) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:07:33.148+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:07:33.148+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:07:33.148+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:07:33.854+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:07:33.871+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:07:33.871+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:07:33.888+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:07:33.888+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T15:07:33.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.766 seconds
[2023-07-07T15:08:04.301+0000] {processor.py:157} INFO - Started process (PID=143) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:08:04.306+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:08:04.307+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:08:04.306+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:08:05.010+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:08:05.027+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:08:05.027+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:08:05.044+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:08:05.044+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T15:08:05.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.758 seconds
[2023-07-07T15:08:35.562+0000] {processor.py:157} INFO - Started process (PID=165) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:08:35.568+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:08:35.568+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:08:35.568+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:08:36.261+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:08:36.278+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:08:36.277+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:08:36.296+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:08:36.296+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T15:08:36.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.746 seconds
[2023-07-07T15:09:06.806+0000] {processor.py:157} INFO - Started process (PID=187) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:09:06.814+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:09:06.814+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:09:06.814+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:09:07.511+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:09:07.529+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:09:07.528+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:09:07.548+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:09:07.548+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T15:09:07.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.756 seconds
[2023-07-07T15:09:37.965+0000] {processor.py:157} INFO - Started process (PID=209) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:09:37.972+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:09:37.972+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:09:37.972+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:09:38.702+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:09:38.719+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:09:38.718+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:09:38.736+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:09:38.735+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T15:09:38.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.783 seconds
[2023-07-07T15:10:09.239+0000] {processor.py:157} INFO - Started process (PID=231) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:10:09.244+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:10:09.244+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:10:09.244+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:10:09.987+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:10:10.003+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:10:10.003+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:10:10.021+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:10:10.021+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T15:10:10.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.798 seconds
[2023-07-07T15:10:40.334+0000] {processor.py:157} INFO - Started process (PID=253) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:10:40.344+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:10:40.344+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:10:40.344+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:10:41.075+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:10:41.092+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:10:41.092+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:10:41.110+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:10:41.110+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T15:10:41.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.796 seconds
[2023-07-07T15:11:11.585+0000] {processor.py:157} INFO - Started process (PID=275) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:11:11.591+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:11:11.592+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:11:11.592+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:11:12.345+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:11:12.364+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:11:12.364+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:11:12.383+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:11:12.383+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T15:11:12.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.817 seconds
[2023-07-07T15:11:42.633+0000] {processor.py:157} INFO - Started process (PID=297) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:11:42.640+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:11:42.640+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:11:42.640+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:11:43.361+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:11:43.378+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:11:43.377+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:11:43.395+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:11:43.395+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T15:11:43.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.781 seconds
[2023-07-07T15:12:13.867+0000] {processor.py:157} INFO - Started process (PID=319) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:12:13.877+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:12:13.877+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:12:13.877+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:12:14.591+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:12:14.607+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:12:14.607+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:12:14.624+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:12:14.624+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-04T08:00:00+00:00, run_after=2023-07-05T08:00:00+00:00
[2023-07-07T15:12:14.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.774 seconds
[2023-07-07T15:12:45.108+0000] {processor.py:157} INFO - Started process (PID=341) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:12:45.115+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:12:45.115+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:12:45.115+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:12:45.890+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:12:45.908+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:12:45.908+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:12:45.926+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:12:45.926+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:12:45.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.831 seconds
[2023-07-07T15:13:16.132+0000] {processor.py:157} INFO - Started process (PID=363) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:13:16.138+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:13:16.138+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:13:16.138+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:13:16.848+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:13:16.864+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:13:16.864+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:13:16.882+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:13:16.881+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:13:16.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.766 seconds
[2023-07-07T15:13:25.961+0000] {processor.py:157} INFO - Started process (PID=388) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:13:25.962+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:13:25.962+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:13:25.962+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:13:26.666+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:13:26.753+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:13:26.753+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:13:26.772+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:13:26.772+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:13:26.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.831 seconds
[2023-07-07T15:13:33.245+0000] {processor.py:157} INFO - Started process (PID=403) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:13:33.253+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:13:33.253+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:13:33.253+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:13:33.965+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:13:33.971+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:13:33.971+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:13:33.990+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:13:33.990+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:13:34.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.765 seconds
[2023-07-07T15:13:57.400+0000] {processor.py:157} INFO - Started process (PID=423) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:13:57.407+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:13:57.407+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:13:57.407+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:13:58.109+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:13:58.190+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:13:58.189+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:13:58.207+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:13:58.207+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:13:58.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.826 seconds
[2023-07-07T15:13:59.167+0000] {processor.py:157} INFO - Started process (PID=436) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:13:59.167+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:13:59.168+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:13:59.168+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:13:59.884+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:13:59.891+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:13:59.891+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:13:59.910+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:13:59.910+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:13:59.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.763 seconds
[2023-07-07T15:14:05.997+0000] {processor.py:157} INFO - Started process (PID=451) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:14:05.998+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:14:05.998+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:14:05.998+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:14:06.718+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:14:06.726+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:14:06.726+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:14:06.746+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:14:06.745+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:14:06.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.769 seconds
[2023-07-07T15:14:20.105+0000] {processor.py:157} INFO - Started process (PID=464) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:14:20.115+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:14:20.115+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:14:20.115+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:14:20.824+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:14:20.831+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:14:20.830+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:14:20.849+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:14:20.849+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:14:20.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.772 seconds
[2023-07-07T15:14:27.922+0000] {processor.py:157} INFO - Started process (PID=484) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:14:27.923+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:14:27.923+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:14:27.923+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:14:28.638+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:14:28.655+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:14:28.655+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:14:28.672+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:14:28.672+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:14:28.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.770 seconds
[2023-07-07T15:14:58.902+0000] {processor.py:157} INFO - Started process (PID=506) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:14:58.912+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:14:58.913+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:14:58.913+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:14:59.654+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v2']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:14:59.671+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:14:59.671+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:14:59.689+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:14:59.689+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v2 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:14:59.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.801 seconds
[2023-07-07T15:15:20.028+0000] {processor.py:157} INFO - Started process (PID=521) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:15:20.037+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:15:20.038+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:15:20.038+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:15:20.756+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v3']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:15:20.849+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:15:20.849+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:dag_scrap_biobio_v3
[2023-07-07T15:15:20.857+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:15:20.857+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:dag_scrap_biobio_v3
[2023-07-07T15:15:20.861+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:15:20.861+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:dag_scrap_biobio_v3
[2023-07-07T15:15:20.873+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:15:20.873+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:15:20.883+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:15:20.883+0000] {dag.py:2747} INFO - Creating ORM DAG for dag_scrap_biobio_v3
[2023-07-07T15:15:20.893+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:15:20.893+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v3 to 2023-07-06T08:00:00+00:00, run_after=2023-07-07T08:00:00+00:00
[2023-07-07T15:15:20.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.880 seconds
[2023-07-07T15:15:51.130+0000] {processor.py:157} INFO - Started process (PID=543) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:15:51.135+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:15:51.136+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:15:51.136+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:15:51.851+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v3']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:15:51.868+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:15:51.867+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:15:51.887+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:15:51.887+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v3 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:15:51.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.777 seconds
[2023-07-07T15:16:22.413+0000] {processor.py:157} INFO - Started process (PID=565) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:16:22.420+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:16:22.420+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:16:22.420+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:16:23.137+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v3']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:16:23.155+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:16:23.154+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:16:23.173+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:16:23.173+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v3 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:16:23.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.776 seconds
[2023-07-07T15:16:53.619+0000] {processor.py:157} INFO - Started process (PID=587) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:16:53.625+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:16:53.626+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:16:53.626+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:16:54.397+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v3']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:16:54.416+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:16:54.416+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:16:54.435+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:16:54.435+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v3 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:16:54.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.835 seconds
[2023-07-07T15:17:24.817+0000] {processor.py:157} INFO - Started process (PID=616) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:17:24.823+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:17:24.823+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:17:24.823+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:17:25.521+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v3']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:17:25.538+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:17:25.537+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:17:25.555+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:17:25.555+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v3 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:17:25.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.751 seconds
[2023-07-07T15:17:41.929+0000] {processor.py:157} INFO - Started process (PID=631) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:17:41.938+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:17:41.939+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:17:41.939+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:17:42.652+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v3']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:17:42.668+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:17:42.667+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:17:42.686+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:17:42.685+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v3 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:17:42.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.777 seconds
[2023-07-07T15:17:43.732+0000] {processor.py:157} INFO - Started process (PID=644) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:17:43.733+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:17:43.733+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:17:43.733+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:17:44.439+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v3']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:17:44.455+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:17:44.455+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:17:44.473+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:17:44.473+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v3 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:17:44.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.760 seconds
[2023-07-07T15:18:02.599+0000] {processor.py:157} INFO - Started process (PID=664) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:18:02.609+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:18:02.610+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:18:02.610+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:18:03.329+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v3']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:18:03.414+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:18:03.414+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:18:03.431+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:18:03.431+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v3 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:18:03.444+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.847 seconds
[2023-07-07T15:18:11.209+0000] {processor.py:157} INFO - Started process (PID=679) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:18:11.209+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:18:11.209+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:18:11.209+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:18:11.930+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v3']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:18:11.938+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:18:11.937+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:18:11.957+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:18:11.957+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v3 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:18:11.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.762 seconds
[2023-07-07T15:18:33.114+0000] {processor.py:157} INFO - Started process (PID=699) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:18:33.120+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:18:33.120+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:18:33.120+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:18:33.823+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v3']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:18:33.842+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:18:33.841+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:18:33.860+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:18:33.860+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v3 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:18:33.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.767 seconds
[2023-07-07T15:18:37.328+0000] {processor.py:157} INFO - Started process (PID=714) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:18:37.329+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:18:37.329+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:18:37.329+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:18:38.050+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v4']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:18:38.122+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:18:38.122+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:dag_scrap_biobio_v4
[2023-07-07T15:18:38.129+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:18:38.129+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:dag_scrap_biobio_v4
[2023-07-07T15:18:38.133+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:18:38.133+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:dag_scrap_biobio_v4
[2023-07-07T15:18:38.144+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:18:38.144+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:18:38.154+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:18:38.153+0000] {dag.py:2747} INFO - Creating ORM DAG for dag_scrap_biobio_v4
[2023-07-07T15:18:38.162+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:18:38.162+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v4 to 2023-07-06T08:00:00+00:00, run_after=2023-07-07T08:00:00+00:00
[2023-07-07T15:18:38.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.847 seconds
[2023-07-07T15:19:08.538+0000] {processor.py:157} INFO - Started process (PID=736) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:19:08.543+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:19:08.544+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:19:08.544+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:19:09.269+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v4']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:19:09.287+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:19:09.286+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:19:09.307+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:19:09.307+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v4 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:19:09.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.782 seconds
[2023-07-07T15:19:39.941+0000] {processor.py:157} INFO - Started process (PID=758) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:19:39.948+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:19:39.949+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:19:39.949+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:19:40.687+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v4']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:19:40.704+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:19:40.704+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:19:40.724+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:19:40.723+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v4 to 2023-07-07T08:00:00+00:00, run_after=2023-07-08T08:00:00+00:00
[2023-07-07T15:19:40.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.802 seconds
[2023-07-07T15:19:57.871+0000] {processor.py:157} INFO - Started process (PID=778) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:19:57.877+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:19:57.877+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:19:57.877+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:19:58.589+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:19:58.588+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/dag_scrap_biobio.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrap_biobio.py", line 37, in <module>
    dagrun_timeout=datetime.timedelta(minutes=60),
AttributeError: type object 'datetime.datetime' has no attribute 'timedelta'
[2023-07-07T15:19:58.589+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:19:58.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.736 seconds
[2023-07-07T15:20:04.079+0000] {processor.py:157} INFO - Started process (PID=791) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:20:04.080+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:20:04.080+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:20:04.080+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:20:04.799+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v4']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:20:04.880+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:20:04.880+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:20:04.898+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:20:04.898+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v4 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:20:04.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.839 seconds
[2023-07-07T15:20:06.022+0000] {processor.py:157} INFO - Started process (PID=806) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:20:06.022+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:20:06.022+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:20:06.022+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:20:06.731+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v4']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:20:06.738+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:20:06.738+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:20:06.758+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:20:06.758+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v4 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:20:06.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.755 seconds
[2023-07-07T15:20:37.322+0000] {processor.py:157} INFO - Started process (PID=828) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:20:37.332+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:20:37.333+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:20:37.333+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:20:38.034+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v4']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:20:38.117+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:20:38.117+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:20:38.135+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:20:38.135+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v4 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:20:38.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.829 seconds
[2023-07-07T15:20:41.189+0000] {processor.py:157} INFO - Started process (PID=841) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:20:41.189+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:20:41.190+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:20:41.190+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:20:41.938+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v5']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:20:42.014+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:20:42.014+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:dag_scrap_biobio_v5
[2023-07-07T15:20:42.021+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:20:42.021+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:dag_scrap_biobio_v5
[2023-07-07T15:20:42.025+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:20:42.025+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:dag_scrap_biobio_v5
[2023-07-07T15:20:42.035+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:20:42.035+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:20:42.044+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:20:42.044+0000] {dag.py:2747} INFO - Creating ORM DAG for dag_scrap_biobio_v5
[2023-07-07T15:20:42.052+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:20:42.052+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v5 to 2023-07-06T00:00:00+00:00, run_after=2023-07-07T00:00:00+00:00
[2023-07-07T15:20:42.062+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.876 seconds
[2023-07-07T15:21:08.469+0000] {processor.py:157} INFO - Started process (PID=863) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:21:08.476+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:21:08.476+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:21:08.476+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:21:09.181+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v5']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:21:09.188+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:21:09.188+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:21:09.207+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:21:09.207+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v5 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:21:09.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.757 seconds
[2023-07-07T15:21:12.265+0000] {processor.py:157} INFO - Started process (PID=876) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:21:12.265+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:21:12.266+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:21:12.266+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:21:12.975+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:21:13.051+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:21:13.051+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:dag_scrap_biobio_v6
[2023-07-07T15:21:13.058+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:21:13.058+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:dag_scrap_biobio_v6
[2023-07-07T15:21:13.062+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:21:13.062+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:dag_scrap_biobio_v6
[2023-07-07T15:21:13.074+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:21:13.074+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:21:13.084+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:21:13.084+0000] {dag.py:2747} INFO - Creating ORM DAG for dag_scrap_biobio_v6
[2023-07-07T15:21:13.093+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:21:13.093+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-06T00:00:00+00:00, run_after=2023-07-07T00:00:00+00:00
[2023-07-07T15:21:13.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.842 seconds
[2023-07-07T15:21:43.709+0000] {processor.py:157} INFO - Started process (PID=898) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:21:43.710+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:21:43.710+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:21:43.710+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:21:44.442+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:21:44.460+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:21:44.460+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:21:44.480+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:21:44.479+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:21:44.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.783 seconds
[2023-07-07T15:22:14.986+0000] {processor.py:157} INFO - Started process (PID=920) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:22:14.991+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:22:14.991+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:22:14.991+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:22:15.695+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:22:15.712+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:22:15.712+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:22:15.731+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:22:15.731+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:22:15.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.762 seconds
[2023-07-07T15:22:46.213+0000] {processor.py:157} INFO - Started process (PID=942) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:22:46.223+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:22:46.224+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:22:46.223+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:22:46.927+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:22:46.944+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:22:46.944+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:22:46.962+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:22:46.962+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:22:46.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.761 seconds
[2023-07-07T15:23:17.469+0000] {processor.py:157} INFO - Started process (PID=964) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:23:17.478+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:23:17.479+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:23:17.479+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:23:18.177+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:23:18.192+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:23:18.192+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:23:18.211+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:23:18.211+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:23:18.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.756 seconds
[2023-07-07T15:23:48.637+0000] {processor.py:157} INFO - Started process (PID=986) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:23:48.642+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:23:48.642+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:23:48.642+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:23:49.369+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:23:49.385+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:23:49.385+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:23:49.403+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:23:49.403+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:23:49.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.783 seconds
[2023-07-07T15:24:19.829+0000] {processor.py:157} INFO - Started process (PID=1008) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:24:19.836+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:24:19.836+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:24:19.836+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:24:20.553+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:24:20.569+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:24:20.569+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:24:20.587+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:24:20.586+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:24:20.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.770 seconds
[2023-07-07T15:24:51.035+0000] {processor.py:157} INFO - Started process (PID=1031) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:24:51.040+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:24:51.041+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:24:51.041+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:24:51.759+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:24:51.776+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:24:51.775+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:24:51.794+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:24:51.794+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:24:51.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.776 seconds
[2023-07-07T15:25:22.061+0000] {processor.py:157} INFO - Started process (PID=1053) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:25:22.067+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:25:22.067+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:25:22.067+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:25:22.782+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:25:22.798+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:25:22.797+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:25:22.816+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:25:22.816+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:25:22.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.768 seconds
[2023-07-07T15:25:53.277+0000] {processor.py:157} INFO - Started process (PID=1075) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:25:53.289+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:25:53.289+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:25:53.289+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:25:54.014+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:25:54.032+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:25:54.032+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:25:54.051+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:25:54.051+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:25:54.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.793 seconds
[2023-07-07T15:26:14.405+0000] {processor.py:157} INFO - Started process (PID=1097) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:26:14.410+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:26:14.411+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:26:14.411+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:26:15.137+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:26:15.161+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:26:15.160+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:26:15.180+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:26:15.179+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:26:15.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.788 seconds
[2023-07-07T15:26:45.711+0000] {processor.py:157} INFO - Started process (PID=1120) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:26:45.717+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:26:45.717+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:26:45.717+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:26:46.427+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:26:46.443+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:26:46.443+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:26:46.461+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:26:46.461+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:26:46.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.764 seconds
[2023-07-07T15:27:17.228+0000] {processor.py:157} INFO - Started process (PID=1142) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:27:17.235+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:27:17.236+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:27:17.236+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:27:17.954+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:27:17.971+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:27:17.971+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:27:17.990+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:27:17.990+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:27:18.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.778 seconds
[2023-07-07T15:27:48.492+0000] {processor.py:157} INFO - Started process (PID=1165) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:27:48.498+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:27:48.498+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:27:48.498+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:27:49.209+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:27:49.224+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:27:49.224+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:27:49.242+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:27:49.242+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:27:49.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.764 seconds
[2023-07-07T15:28:19.571+0000] {processor.py:157} INFO - Started process (PID=1187) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:28:19.579+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:28:19.579+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:28:19.579+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:28:20.292+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:28:20.308+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:28:20.307+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:28:20.325+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:28:20.325+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:28:20.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.771 seconds
[2023-07-07T15:28:50.952+0000] {processor.py:157} INFO - Started process (PID=1211) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:28:50.959+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:28:50.960+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:28:50.960+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:28:51.680+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:28:51.697+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:28:51.697+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:28:51.716+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:28:51.716+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:28:51.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.781 seconds
[2023-07-07T15:29:22.069+0000] {processor.py:157} INFO - Started process (PID=1234) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:29:22.075+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:29:22.075+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:29:22.075+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:29:22.787+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:29:22.803+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:29:22.803+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:29:22.821+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:29:22.821+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:29:22.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.765 seconds
[2023-07-07T15:29:53.128+0000] {processor.py:157} INFO - Started process (PID=1257) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:29:53.134+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:29:53.134+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:29:53.134+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:29:53.836+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:29:53.852+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:29:53.852+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:29:53.871+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:29:53.871+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:29:53.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.761 seconds
[2023-07-07T15:30:24.155+0000] {processor.py:157} INFO - Started process (PID=1280) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:30:24.157+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:30:24.157+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:30:24.157+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:30:24.884+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:30:24.900+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:30:24.899+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:30:24.917+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:30:24.917+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:30:24.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.780 seconds
[2023-07-07T15:30:55.455+0000] {processor.py:157} INFO - Started process (PID=1312) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:30:55.466+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:30:55.466+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:30:55.466+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:30:56.173+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:30:56.189+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:30:56.189+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:30:56.207+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:30:56.207+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:30:56.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.769 seconds
[2023-07-07T15:31:26.727+0000] {processor.py:157} INFO - Started process (PID=1337) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:31:26.733+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:31:26.733+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:31:26.733+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:31:27.443+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:31:27.460+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:31:27.460+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:31:27.478+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:31:27.478+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:31:27.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.765 seconds
[2023-07-07T15:31:57.996+0000] {processor.py:157} INFO - Started process (PID=1366) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:31:58.002+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:31:58.002+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:31:58.002+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:31:58.719+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:31:58.735+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:31:58.735+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:31:58.754+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:31:58.754+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:31:58.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.776 seconds
[2023-07-07T15:32:29.243+0000] {processor.py:157} INFO - Started process (PID=1388) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:32:29.249+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:32:29.249+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:32:29.249+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:32:29.961+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:32:29.980+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:32:29.980+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:32:30.000+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:32:30.000+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:32:30.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.772 seconds
[2023-07-07T15:33:00.496+0000] {processor.py:157} INFO - Started process (PID=1542) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:33:00.502+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:33:00.502+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:33:00.502+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:33:01.217+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:33:01.234+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:33:01.234+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:33:01.252+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:33:01.252+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:33:01.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.775 seconds
[2023-07-07T15:33:31.749+0000] {processor.py:157} INFO - Started process (PID=1564) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:33:31.755+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:33:31.756+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:33:31.756+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:33:32.468+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:33:32.483+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:33:32.483+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:33:32.501+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:33:32.501+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:33:32.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.771 seconds
[2023-07-07T15:34:03.027+0000] {processor.py:157} INFO - Started process (PID=1587) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:34:03.036+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:34:03.037+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:34:03.037+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:34:03.748+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:34:03.764+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:34:03.764+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:34:03.783+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:34:03.783+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:34:03.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.775 seconds
[2023-07-07T15:34:34.144+0000] {processor.py:157} INFO - Started process (PID=1610) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:34:34.148+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:34:34.148+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:34:34.148+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:34:34.876+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:34:34.894+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:34:34.894+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:34:34.913+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:34:34.913+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:34:34.923+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.781 seconds
[2023-07-07T15:35:05.412+0000] {processor.py:157} INFO - Started process (PID=1632) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:35:05.426+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:35:05.427+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:35:05.427+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:35:06.154+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:35:06.170+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:35:06.170+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:35:06.188+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:35:06.188+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:35:06.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.794 seconds
[2023-07-07T15:35:36.667+0000] {processor.py:157} INFO - Started process (PID=1654) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:35:36.678+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:35:36.678+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:35:36.678+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:35:37.376+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:35:37.391+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:35:37.391+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:35:37.409+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:35:37.409+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:35:37.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.760 seconds
[2023-07-07T15:36:07.919+0000] {processor.py:157} INFO - Started process (PID=1676) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:36:07.924+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:36:07.924+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:36:07.924+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:36:08.637+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:36:08.654+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:36:08.654+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:36:08.673+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:36:08.673+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:36:08.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.773 seconds
[2023-07-07T15:36:39.171+0000] {processor.py:157} INFO - Started process (PID=1698) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:36:39.176+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:36:39.177+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:36:39.177+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:36:39.899+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:36:39.916+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:36:39.916+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:36:39.934+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:36:39.934+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:36:39.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.776 seconds
[2023-07-07T15:37:10.433+0000] {processor.py:157} INFO - Started process (PID=1720) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:37:10.438+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:37:10.439+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:37:10.439+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:37:11.149+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:37:11.165+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:37:11.165+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:37:11.182+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:37:11.182+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:37:11.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.768 seconds
[2023-07-07T15:37:41.689+0000] {processor.py:157} INFO - Started process (PID=1742) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:37:41.695+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:37:41.695+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:37:41.695+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:37:42.400+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:37:42.416+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:37:42.416+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:37:42.434+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:37:42.434+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:37:42.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.764 seconds
[2023-07-07T15:38:12.942+0000] {processor.py:157} INFO - Started process (PID=1764) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:38:12.947+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:38:12.947+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:38:12.947+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:38:13.657+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:38:13.674+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:38:13.673+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:38:13.693+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:38:13.693+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:38:13.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.769 seconds
[2023-07-07T15:38:44.192+0000] {processor.py:157} INFO - Started process (PID=1786) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:38:44.198+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:38:44.198+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:38:44.198+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:38:44.911+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:38:44.929+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:38:44.928+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:38:44.947+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:38:44.947+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:38:44.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.774 seconds
[2023-07-07T15:39:15.452+0000] {processor.py:157} INFO - Started process (PID=1808) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:39:15.458+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:39:15.458+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:39:15.458+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:39:16.177+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:39:16.195+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:39:16.194+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:39:16.213+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:39:16.213+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:39:16.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.777 seconds
[2023-07-07T15:39:46.685+0000] {processor.py:157} INFO - Started process (PID=1830) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:39:46.690+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:39:46.691+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:39:46.691+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:39:47.389+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:39:47.406+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:39:47.405+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:39:47.424+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:39:47.423+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:39:47.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.753 seconds
[2023-07-07T15:40:17.996+0000] {processor.py:157} INFO - Started process (PID=1853) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:40:18.002+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:40:18.002+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:40:18.002+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:40:18.712+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:40:18.728+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:40:18.728+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:40:18.747+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:40:18.747+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:40:18.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.762 seconds
[2023-07-07T15:40:49.200+0000] {processor.py:157} INFO - Started process (PID=1875) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:40:49.207+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:40:49.207+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:40:49.207+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:40:49.927+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:40:49.944+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:40:49.944+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:40:49.963+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:40:49.963+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:40:49.979+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.781 seconds
[2023-07-07T15:41:20.440+0000] {processor.py:157} INFO - Started process (PID=1897) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:41:20.446+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:41:20.447+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:41:20.447+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:41:21.158+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:41:21.176+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:41:21.175+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:41:21.194+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:41:21.194+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:41:21.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.772 seconds
[2023-07-07T15:41:51.650+0000] {processor.py:157} INFO - Started process (PID=1919) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:41:51.650+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:41:51.651+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:41:51.651+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:41:52.380+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:41:52.396+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:41:52.395+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:41:52.415+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:41:52.414+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:41:52.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.783 seconds
[2023-07-07T15:42:22.920+0000] {processor.py:157} INFO - Started process (PID=1941) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:42:22.925+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:42:22.926+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:42:22.926+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:42:23.638+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:42:23.654+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:42:23.654+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:42:23.673+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:42:23.673+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:42:23.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.765 seconds
[2023-07-07T15:42:54.121+0000] {processor.py:157} INFO - Started process (PID=1963) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:42:54.127+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:42:54.127+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:42:54.127+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:42:54.853+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:42:54.870+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:42:54.870+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:42:54.889+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:42:54.889+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:42:54.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.781 seconds
[2023-07-07T15:43:25.373+0000] {processor.py:157} INFO - Started process (PID=1985) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:43:25.379+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:43:25.379+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:43:25.379+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:43:26.098+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:43:26.114+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:43:26.114+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:43:26.132+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:43:26.132+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:43:26.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.776 seconds
[2023-07-07T15:43:56.606+0000] {processor.py:157} INFO - Started process (PID=2007) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:43:56.618+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:43:56.618+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:43:56.618+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:43:57.344+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:43:57.360+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:43:57.360+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:43:57.379+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:43:57.379+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:43:57.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.792 seconds
[2023-07-07T15:44:27.835+0000] {processor.py:157} INFO - Started process (PID=2029) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:44:27.842+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:44:27.842+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:44:27.842+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:44:28.549+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:44:28.565+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:44:28.565+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:44:28.584+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:44:28.583+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:44:28.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.767 seconds
[2023-07-07T15:44:59.060+0000] {processor.py:157} INFO - Started process (PID=2051) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:44:59.069+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:44:59.069+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:44:59.069+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:44:59.804+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:44:59.820+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:44:59.820+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:44:59.839+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:44:59.839+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:44:59.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.796 seconds
[2023-07-07T15:45:30.313+0000] {processor.py:157} INFO - Started process (PID=2073) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:45:30.320+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:45:30.320+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:45:30.320+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:45:31.073+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:45:31.090+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:45:31.090+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:45:31.109+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:45:31.109+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:45:31.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.813 seconds
[2023-07-07T15:46:01.542+0000] {processor.py:157} INFO - Started process (PID=2102) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:46:01.548+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:46:01.549+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:46:01.549+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:46:02.260+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:46:02.276+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:46:02.276+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:46:02.295+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:46:02.295+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:46:02.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.767 seconds
[2023-07-07T15:46:32.778+0000] {processor.py:157} INFO - Started process (PID=2133) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:46:32.785+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:46:32.785+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:46:32.785+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:46:33.496+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:46:33.512+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:46:33.512+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:46:33.531+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:46:33.531+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:46:33.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.771 seconds
[2023-07-07T15:47:04.026+0000] {processor.py:157} INFO - Started process (PID=2158) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:47:04.031+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:47:04.031+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:47:04.031+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:47:04.739+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:47:04.755+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:47:04.755+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:47:04.773+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:47:04.773+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:47:04.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.760 seconds
[2023-07-07T15:47:35.279+0000] {processor.py:157} INFO - Started process (PID=2190) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:47:35.285+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:47:35.285+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:47:35.285+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:47:35.996+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:47:36.012+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:47:36.012+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:47:36.030+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:47:36.030+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:47:36.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.769 seconds
[2023-07-07T15:48:06.536+0000] {processor.py:157} INFO - Started process (PID=2219) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:48:06.541+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:48:06.542+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:48:06.542+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:48:07.255+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:48:07.270+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:48:07.270+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:48:07.288+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:48:07.288+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:48:07.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.770 seconds
[2023-07-07T15:48:37.802+0000] {processor.py:157} INFO - Started process (PID=2256) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:48:37.807+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:48:37.807+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:48:37.807+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:48:38.527+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:48:38.542+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:48:38.542+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:48:38.561+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:48:38.561+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:48:38.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.776 seconds
[2023-07-07T15:49:09.071+0000] {processor.py:157} INFO - Started process (PID=2278) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:49:09.076+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:49:09.076+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:49:09.076+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:49:09.813+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:49:09.831+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:49:09.830+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:49:09.849+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:49:09.849+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:49:09.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.796 seconds
[2023-07-07T15:49:40.333+0000] {processor.py:157} INFO - Started process (PID=2300) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:49:40.339+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:49:40.340+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:49:40.339+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:49:41.047+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:49:41.067+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:49:41.066+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:49:41.093+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:49:41.093+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:49:41.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.780 seconds
[2023-07-07T15:49:45.374+0000] {processor.py:157} INFO - Started process (PID=2314) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:49:45.374+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:49:45.374+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:49:45.374+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:49:46.115+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:49:46.133+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:49:46.132+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:49:46.151+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:49:46.151+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:49:46.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.791 seconds
[2023-07-07T15:50:16.669+0000] {processor.py:157} INFO - Started process (PID=2336) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:50:16.674+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:50:16.674+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:50:16.674+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:50:17.376+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:50:17.393+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:50:17.392+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:50:17.411+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:50:17.411+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:50:17.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.761 seconds
[2023-07-07T15:50:39.547+0000] {processor.py:157} INFO - Started process (PID=32) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:50:39.548+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:50:39.548+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:50:39.548+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:50:40.969+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:50:40.992+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:50:40.991+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:50:41.010+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:50:41.009+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:50:41.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.475 seconds
[2023-07-07T15:51:11.885+0000] {processor.py:157} INFO - Started process (PID=56) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:51:11.891+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:51:11.891+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:51:11.891+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:51:12.610+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:51:12.627+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:51:12.627+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:51:12.645+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:51:12.645+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:51:12.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.773 seconds
[2023-07-07T15:51:43.097+0000] {processor.py:157} INFO - Started process (PID=78) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:51:43.106+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:51:43.107+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:51:43.106+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:51:43.827+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:51:43.844+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:51:43.843+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:51:43.863+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:51:43.863+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:51:43.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.779 seconds
[2023-07-07T15:52:14.352+0000] {processor.py:157} INFO - Started process (PID=100) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:52:14.358+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:52:14.358+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:52:14.358+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:52:15.097+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:52:15.118+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:52:15.118+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:52:15.145+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:52:15.145+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:52:15.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.814 seconds
[2023-07-07T15:52:45.504+0000] {processor.py:157} INFO - Started process (PID=122) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:52:45.510+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:52:45.510+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:52:45.510+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:52:46.232+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:52:46.247+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:52:46.247+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:52:46.266+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:52:46.266+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:52:46.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.779 seconds
[2023-07-07T15:53:16.697+0000] {processor.py:157} INFO - Started process (PID=144) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:53:16.703+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:53:16.703+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:53:16.703+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:53:17.437+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:53:17.454+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:53:17.454+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:53:17.473+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:53:17.473+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:53:17.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.794 seconds
[2023-07-07T15:53:47.986+0000] {processor.py:157} INFO - Started process (PID=166) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:53:47.992+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:53:47.992+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:53:47.992+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:53:48.735+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:53:48.752+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:53:48.752+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:53:48.770+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:53:48.770+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:53:48.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.803 seconds
[2023-07-07T15:54:19.132+0000] {processor.py:157} INFO - Started process (PID=188) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:54:19.138+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:54:19.138+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:54:19.138+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:54:19.857+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:54:19.875+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:54:19.875+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:54:19.894+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:54:19.894+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:54:19.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.781 seconds
[2023-07-07T15:54:50.332+0000] {processor.py:157} INFO - Started process (PID=210) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:54:50.337+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:54:50.337+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:54:50.337+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:54:51.042+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:54:51.057+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:54:51.057+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:54:51.076+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:54:51.075+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:54:51.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.762 seconds
[2023-07-07T15:55:21.539+0000] {processor.py:157} INFO - Started process (PID=232) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:55:21.545+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:55:21.545+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:55:21.545+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:55:22.266+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:55:22.283+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:55:22.282+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:55:22.302+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:55:22.301+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:55:22.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.775 seconds
[2023-07-07T15:55:52.746+0000] {processor.py:157} INFO - Started process (PID=254) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:55:52.752+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:55:52.752+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:55:52.752+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:55:53.503+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:55:53.522+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:55:53.522+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:55:53.541+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:55:53.541+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:55:53.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.809 seconds
[2023-07-07T15:56:23.956+0000] {processor.py:157} INFO - Started process (PID=276) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:56:23.963+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:56:23.963+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:56:23.963+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:56:24.663+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:56:24.679+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:56:24.679+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:56:24.698+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:56:24.697+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:56:24.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.760 seconds
[2023-07-07T15:56:55.148+0000] {processor.py:157} INFO - Started process (PID=298) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:56:55.153+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:56:55.154+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:56:55.154+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:56:55.877+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:56:55.895+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:56:55.894+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:56:55.914+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:56:55.914+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:56:55.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.783 seconds
[2023-07-07T15:57:26.414+0000] {processor.py:157} INFO - Started process (PID=320) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:57:26.420+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:57:26.420+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:57:26.420+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:57:27.119+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:57:27.135+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:57:27.134+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:57:27.153+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:57:27.153+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:57:27.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.751 seconds
[2023-07-07T15:57:57.612+0000] {processor.py:157} INFO - Started process (PID=342) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:57:57.617+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:57:57.617+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:57:57.617+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:57:58.314+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:57:58.330+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:57:58.330+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:57:58.348+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:57:58.348+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:57:58.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.752 seconds
[2023-07-07T15:58:28.788+0000] {processor.py:157} INFO - Started process (PID=364) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:58:28.794+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:58:28.794+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:58:28.794+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:58:29.496+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:58:29.511+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:58:29.511+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:58:29.529+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:58:29.529+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:58:29.539+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.753 seconds
[2023-07-07T15:58:59.969+0000] {processor.py:157} INFO - Started process (PID=386) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:58:59.979+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:58:59.979+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:58:59.979+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:59:00.687+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:59:00.704+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:59:00.703+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:59:00.722+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:59:00.722+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:59:00.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.768 seconds
[2023-07-07T15:59:31.191+0000] {processor.py:157} INFO - Started process (PID=416) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:59:31.197+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T15:59:31.198+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:59:31.198+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:59:31.915+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T15:59:31.931+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:59:31.931+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T15:59:31.950+0000] {logging_mixin.py:149} INFO - [2023-07-07T15:59:31.950+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T15:59:31.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.778 seconds
[2023-07-07T16:00:02.563+0000] {processor.py:157} INFO - Started process (PID=438) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:00:02.569+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:00:02.570+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:00:02.570+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:00:03.282+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:00:03.300+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:00:03.300+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:00:03.318+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:00:03.318+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:00:03.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.772 seconds
[2023-07-07T16:00:33.799+0000] {processor.py:157} INFO - Started process (PID=460) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:00:33.805+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:00:33.805+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:00:33.805+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:00:34.529+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:00:34.545+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:00:34.544+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:00:34.563+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:00:34.563+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:00:34.573+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.776 seconds
[2023-07-07T16:01:05.039+0000] {processor.py:157} INFO - Started process (PID=486) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:01:05.045+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:01:05.045+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:01:05.045+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:01:05.760+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:01:05.776+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:01:05.775+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:01:05.869+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:01:05.868+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:01:05.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.843 seconds
[2023-07-07T16:01:36.130+0000] {processor.py:157} INFO - Started process (PID=522) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:01:36.135+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:01:36.135+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:01:36.135+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:01:36.852+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:01:36.868+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:01:36.868+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:01:36.887+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:01:36.887+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:01:36.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.776 seconds
[2023-07-07T16:02:07.376+0000] {processor.py:157} INFO - Started process (PID=547) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:02:07.381+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:02:07.382+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:02:07.382+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:02:08.088+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:02:08.105+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:02:08.105+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:02:08.124+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:02:08.124+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:02:08.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.766 seconds
[2023-07-07T16:02:38.597+0000] {processor.py:157} INFO - Started process (PID=575) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:02:38.602+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:02:38.603+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:02:38.603+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:02:39.314+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:02:39.331+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:02:39.330+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:02:39.349+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:02:39.349+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:02:39.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.770 seconds
[2023-07-07T16:03:09.831+0000] {processor.py:157} INFO - Started process (PID=598) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:03:09.837+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:03:09.837+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:03:09.837+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:03:10.550+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:03:10.566+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:03:10.566+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:03:10.585+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:03:10.585+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:03:10.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.843 seconds
[2023-07-07T16:03:40.928+0000] {processor.py:157} INFO - Started process (PID=619) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:03:40.933+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:03:40.934+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:03:40.934+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:03:41.647+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:03:41.663+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:03:41.663+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:03:41.682+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:03:41.682+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:03:41.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.767 seconds
[2023-07-07T16:04:12.159+0000] {processor.py:157} INFO - Started process (PID=641) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:04:12.165+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:04:12.166+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:04:12.166+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:04:12.873+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:04:12.889+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:04:12.888+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:04:12.906+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:04:12.906+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:04:12.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.761 seconds
[2023-07-07T16:04:43.385+0000] {processor.py:157} INFO - Started process (PID=665) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:04:43.396+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:04:43.396+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:04:43.396+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:04:44.097+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:04:44.138+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:04:44.138+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:04:44.156+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:04:44.155+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:04:44.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.783 seconds
[2023-07-07T16:05:14.633+0000] {processor.py:157} INFO - Started process (PID=690) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:05:14.642+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:05:14.643+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:05:14.643+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:05:15.346+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:05:15.362+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:05:15.362+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:05:15.380+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:05:15.380+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:05:15.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.837 seconds
[2023-07-07T16:05:45.756+0000] {processor.py:157} INFO - Started process (PID=721) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:05:45.766+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:05:45.767+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:05:45.767+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:05:46.468+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:05:46.485+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:05:46.485+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:05:46.504+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:05:46.504+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:05:46.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.767 seconds
[2023-07-07T16:06:17.060+0000] {processor.py:157} INFO - Started process (PID=746) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:06:17.066+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:06:17.067+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:06:17.067+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:06:17.846+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:06:17.876+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:06:17.876+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:06:17.895+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:06:17.895+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:06:17.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.849 seconds
[2023-07-07T16:06:48.332+0000] {processor.py:157} INFO - Started process (PID=768) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:06:48.338+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:06:48.338+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:06:48.338+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:06:49.060+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:06:49.076+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:06:49.076+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:06:49.095+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:06:49.094+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:06:49.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.774 seconds
[2023-07-07T16:07:19.564+0000] {processor.py:157} INFO - Started process (PID=790) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:07:19.577+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:07:19.577+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:07:19.577+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:07:20.280+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:07:20.295+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:07:20.295+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:07:20.314+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:07:20.314+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:07:20.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.837 seconds
[2023-07-07T16:07:50.734+0000] {processor.py:157} INFO - Started process (PID=813) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:07:50.743+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:07:50.744+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:07:50.743+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:07:51.451+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:07:51.467+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:07:51.467+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:07:51.486+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:07:51.486+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:07:51.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.770 seconds
[2023-07-07T16:08:21.939+0000] {processor.py:157} INFO - Started process (PID=835) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:08:21.947+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:08:21.947+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:08:21.947+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:08:22.660+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:08:22.678+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:08:22.678+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:08:22.697+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:08:22.696+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:08:22.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.771 seconds
[2023-07-07T16:08:53.197+0000] {processor.py:157} INFO - Started process (PID=858) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:08:53.204+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:08:53.204+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:08:53.204+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:08:53.970+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:08:53.987+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:08:53.986+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:08:54.004+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:08:54.004+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:08:54.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.821 seconds
[2023-07-07T16:09:24.453+0000] {processor.py:157} INFO - Started process (PID=880) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:09:24.460+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:09:24.460+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:09:24.460+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:09:25.161+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:09:25.177+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:09:25.177+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:09:25.195+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:09:25.195+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:09:25.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.830 seconds
[2023-07-07T16:09:55.542+0000] {processor.py:157} INFO - Started process (PID=902) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:09:55.553+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:09:55.553+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:09:55.553+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:09:56.255+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:09:56.270+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:09:56.270+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:09:56.361+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:09:56.361+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:09:56.377+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.837 seconds
[2023-07-07T16:10:26.647+0000] {processor.py:157} INFO - Started process (PID=924) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:10:26.653+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:10:26.653+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:10:26.653+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:10:27.353+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:10:27.370+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:10:27.369+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:10:27.387+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:10:27.387+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:10:27.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.759 seconds
[2023-07-07T16:10:57.907+0000] {processor.py:157} INFO - Started process (PID=948) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:10:57.914+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:10:57.914+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:10:57.914+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:10:58.688+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:10:58.704+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:10:58.704+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:10:58.722+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:10:58.722+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:10:58.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.828 seconds
[2023-07-07T16:11:28.966+0000] {processor.py:157} INFO - Started process (PID=988) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:11:28.971+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:11:28.971+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:11:28.971+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:11:29.683+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:11:29.700+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:11:29.699+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:11:29.718+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:11:29.718+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:11:29.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.843 seconds
[2023-07-07T16:12:00.248+0000] {processor.py:157} INFO - Started process (PID=1017) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:12:00.255+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:12:00.256+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:12:00.256+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:12:00.959+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:12:00.975+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:12:00.975+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:12:01.067+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:12:01.066+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:12:01.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.836 seconds
[2023-07-07T16:12:31.368+0000] {processor.py:157} INFO - Started process (PID=1040) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:12:31.369+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:12:31.369+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:12:31.369+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:12:32.088+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:12:32.104+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:12:32.103+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:12:32.121+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:12:32.121+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:12:32.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.768 seconds
[2023-07-07T16:13:02.608+0000] {processor.py:157} INFO - Started process (PID=1067) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:13:02.614+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:13:02.614+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:13:02.614+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:13:03.391+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:13:03.408+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:13:03.407+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:13:03.426+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:13:03.426+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:13:03.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.835 seconds
[2023-07-07T16:13:33.709+0000] {processor.py:157} INFO - Started process (PID=1094) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:13:33.719+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:13:33.719+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:13:33.719+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:13:34.463+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:13:34.479+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:13:34.479+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:13:34.497+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:13:34.497+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:13:34.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.878 seconds
[2023-07-07T16:14:04.852+0000] {processor.py:157} INFO - Started process (PID=1119) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:14:04.855+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:14:04.856+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:14:04.856+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:14:05.591+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:14:05.607+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:14:05.607+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:14:05.701+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:14:05.701+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:14:05.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.863 seconds
[2023-07-07T16:14:35.982+0000] {processor.py:157} INFO - Started process (PID=1144) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:14:35.987+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:14:35.987+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:14:35.987+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:14:36.689+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:14:36.706+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:14:36.705+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:14:36.724+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:14:36.724+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:14:36.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.755 seconds
[2023-07-07T16:15:07.234+0000] {processor.py:157} INFO - Started process (PID=1207) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:15:07.240+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:15:07.240+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:15:07.240+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:15:08.030+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:15:08.045+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:15:08.044+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:15:08.062+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:15:08.062+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:15:08.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.847 seconds
[2023-07-07T16:15:38.337+0000] {processor.py:157} INFO - Started process (PID=1229) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:15:38.344+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:15:38.344+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:15:38.344+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:15:39.063+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:15:39.079+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:15:39.079+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:15:39.098+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:15:39.098+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:15:39.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.851 seconds
[2023-07-07T16:16:09.445+0000] {processor.py:157} INFO - Started process (PID=1270) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:16:09.451+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:16:09.451+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:16:09.451+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:16:10.152+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:16:10.169+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:16:10.168+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:16:10.260+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:16:10.260+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:16:10.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.832 seconds
[2023-07-07T16:16:40.693+0000] {processor.py:157} INFO - Started process (PID=1294) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:16:40.700+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:16:40.700+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:16:40.700+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:16:41.404+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:16:41.421+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:16:41.421+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:16:41.439+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:16:41.439+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:16:41.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.760 seconds
[2023-07-07T16:16:57.740+0000] {processor.py:157} INFO - Started process (PID=32) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:16:57.740+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:16:57.741+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:16:57.741+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:16:58.579+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:16:58.676+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:16:58.676+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:16:58.698+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:16:58.697+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:16:58.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.978 seconds
[2023-07-07T16:17:29.473+0000] {processor.py:157} INFO - Started process (PID=55) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:17:29.478+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:17:29.479+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:17:29.479+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:17:30.240+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:17:30.257+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:17:30.257+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:17:30.276+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:17:30.276+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:17:30.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.817 seconds
[2023-07-07T16:18:00.771+0000] {processor.py:157} INFO - Started process (PID=85) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:18:00.777+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:18:00.777+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:18:00.777+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:18:01.530+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:18:01.547+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:18:01.547+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:18:01.566+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:18:01.566+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:18:01.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.809 seconds
[2023-07-07T16:18:32.176+0000] {processor.py:157} INFO - Started process (PID=112) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:18:32.182+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:18:32.182+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:18:32.182+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:18:32.890+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:18:32.907+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:18:32.907+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:18:32.926+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:18:32.926+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:18:32.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.766 seconds
[2023-07-07T16:19:03.384+0000] {processor.py:157} INFO - Started process (PID=134) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:19:03.384+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:19:03.385+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:19:03.385+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:19:04.167+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:19:04.188+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:19:04.187+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:19:04.210+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:19:04.210+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:19:04.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.849 seconds
[2023-07-07T16:19:34.673+0000] {processor.py:157} INFO - Started process (PID=156) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:19:34.680+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:19:34.681+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:19:34.681+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:19:35.386+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:19:35.402+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:19:35.401+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:19:35.420+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:19:35.420+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:19:35.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.765 seconds
[2023-07-07T16:20:05.830+0000] {processor.py:157} INFO - Started process (PID=178) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:20:05.835+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:20:05.835+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:20:05.835+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:20:06.552+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:20:06.570+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:20:06.569+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:20:06.588+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:20:06.588+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:20:06.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.776 seconds
[2023-07-07T16:20:36.861+0000] {processor.py:157} INFO - Started process (PID=200) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:20:36.867+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:20:36.867+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:20:36.867+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:20:37.685+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:20:37.702+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:20:37.702+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:20:37.720+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:20:37.720+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:20:37.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.872 seconds
[2023-07-07T16:21:07.974+0000] {processor.py:157} INFO - Started process (PID=222) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:21:07.980+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:21:07.981+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:21:07.980+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:21:08.688+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:21:08.705+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:21:08.705+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:21:08.723+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:21:08.723+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:21:08.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.762 seconds
[2023-07-07T16:21:39.238+0000] {processor.py:157} INFO - Started process (PID=244) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:21:39.245+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:21:39.245+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:21:39.245+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:21:39.947+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:21:39.964+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:21:39.964+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:21:39.983+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:21:39.983+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:21:39.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.763 seconds
[2023-07-07T16:22:10.456+0000] {processor.py:157} INFO - Started process (PID=267) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:22:10.463+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:22:10.463+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:22:10.463+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:22:11.163+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:22:11.178+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:22:11.178+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:22:11.197+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:22:11.196+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:22:11.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.753 seconds
[2023-07-07T16:22:41.679+0000] {processor.py:157} INFO - Started process (PID=303) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:22:41.689+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:22:41.689+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:22:41.689+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:22:42.397+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:22:42.414+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:22:42.414+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:22:42.432+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:22:42.432+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:22:42.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.772 seconds
[2023-07-07T16:23:12.927+0000] {processor.py:157} INFO - Started process (PID=329) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:23:12.928+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:23:12.928+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:23:12.928+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:23:13.647+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:23:13.664+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:23:13.663+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:23:13.681+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:23:13.681+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:23:13.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.772 seconds
[2023-07-07T16:23:44.169+0000] {processor.py:157} INFO - Started process (PID=351) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:23:44.175+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:23:44.176+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:23:44.176+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:23:44.879+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:23:44.895+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:23:44.895+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:23:44.913+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:23:44.913+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:23:44.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.758 seconds
[2023-07-07T16:24:15.467+0000] {processor.py:157} INFO - Started process (PID=374) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:24:15.473+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:24:15.473+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:24:15.473+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:24:16.271+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:24:16.291+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:24:16.290+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:24:16.312+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:24:16.312+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:24:16.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.860 seconds
[2023-07-07T16:24:46.619+0000] {processor.py:157} INFO - Started process (PID=396) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:24:46.626+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:24:46.627+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:24:46.627+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:24:47.345+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:24:47.362+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:24:47.362+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:24:47.382+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:24:47.382+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:24:47.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.775 seconds
[2023-07-07T16:25:17.782+0000] {processor.py:157} INFO - Started process (PID=418) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:25:17.788+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:25:17.788+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:25:17.788+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:25:18.503+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:25:18.521+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:25:18.521+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:25:18.540+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:25:18.540+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:25:18.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.771 seconds
[2023-07-07T16:25:49.056+0000] {processor.py:157} INFO - Started process (PID=440) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:25:49.059+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:25:49.060+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:25:49.060+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:25:49.782+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:25:49.798+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:25:49.798+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:25:49.816+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:25:49.816+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:25:49.834+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.780 seconds
[2023-07-07T16:26:20.272+0000] {processor.py:157} INFO - Started process (PID=462) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:26:20.309+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:26:20.309+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:26:20.309+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:26:21.012+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:26:21.028+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:26:21.028+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:26:21.047+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:26:21.047+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:26:21.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.605 seconds
[2023-07-07T16:26:45.586+0000] {processor.py:157} INFO - Started process (PID=33) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:26:45.586+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:26:45.587+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:26:45.587+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:26:46.890+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:26:46.914+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:26:46.914+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:26:46.932+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:26:46.932+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:26:46.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.364 seconds
[2023-07-07T16:27:16.993+0000] {processor.py:157} INFO - Started process (PID=56) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:27:17.004+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:27:17.005+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:27:17.004+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:27:17.711+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:27:17.728+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:27:17.728+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:27:17.746+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:27:17.745+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:27:17.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.767 seconds
[2023-07-07T16:27:48.128+0000] {processor.py:157} INFO - Started process (PID=78) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:27:48.135+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:27:48.135+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:27:48.135+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:27:48.846+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:27:48.862+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:27:48.862+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:27:48.881+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:27:48.881+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:27:48.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.771 seconds
[2023-07-07T16:28:19.148+0000] {processor.py:157} INFO - Started process (PID=101) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:28:19.161+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:28:19.162+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:28:19.161+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:28:19.910+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:28:19.927+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:28:19.927+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:28:19.946+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:28:19.946+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:28:19.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.816 seconds
[2023-07-07T16:28:50.394+0000] {processor.py:157} INFO - Started process (PID=123) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:28:50.400+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:28:50.400+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:28:50.400+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:28:51.121+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:28:51.137+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:28:51.137+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:28:51.156+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:28:51.156+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:28:51.171+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.780 seconds
[2023-07-07T16:29:21.632+0000] {processor.py:157} INFO - Started process (PID=145) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:29:21.638+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:29:21.638+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:29:21.638+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:29:22.351+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:29:22.367+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:29:22.367+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:29:22.385+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:29:22.385+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:29:22.400+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.771 seconds
[2023-07-07T16:29:52.856+0000] {processor.py:157} INFO - Started process (PID=167) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:29:52.867+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:29:52.868+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:29:52.867+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:29:53.594+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:29:53.610+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:29:53.609+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:29:53.628+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:29:53.627+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:29:53.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.789 seconds
[2023-07-07T16:30:24.091+0000] {processor.py:157} INFO - Started process (PID=189) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:30:24.096+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:30:24.097+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:30:24.097+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:30:24.800+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:30:24.815+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:30:24.815+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:30:24.833+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:30:24.833+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:30:24.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.761 seconds
[2023-07-07T16:30:55.323+0000] {processor.py:157} INFO - Started process (PID=211) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:30:55.328+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:30:55.329+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:30:55.329+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:30:56.043+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:30:56.058+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:30:56.058+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:30:56.077+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:30:56.076+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:30:56.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.768 seconds
[2023-07-07T16:31:26.576+0000] {processor.py:157} INFO - Started process (PID=233) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:31:26.581+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:31:26.581+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:31:26.581+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:31:27.283+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:31:27.300+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:31:27.300+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:31:27.319+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:31:27.318+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:31:27.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.764 seconds
[2023-07-07T16:31:57.812+0000] {processor.py:157} INFO - Started process (PID=255) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:31:57.818+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:31:57.819+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:31:57.819+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:31:58.521+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:31:58.538+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:31:58.537+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:31:58.555+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:31:58.555+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:31:58.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.755 seconds
[2023-07-07T16:32:29.052+0000] {processor.py:157} INFO - Started process (PID=277) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:32:29.060+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:32:29.060+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:32:29.060+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:32:29.761+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:32:29.776+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:32:29.776+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:32:29.795+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:32:29.795+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:32:29.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.757 seconds
[2023-07-07T16:33:00.303+0000] {processor.py:157} INFO - Started process (PID=299) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:33:00.308+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:33:00.308+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:33:00.308+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:33:01.011+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:33:01.027+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:33:01.027+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:33:01.045+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:33:01.045+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:33:01.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.757 seconds
[2023-07-07T16:33:31.557+0000] {processor.py:157} INFO - Started process (PID=321) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:33:31.567+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:33:31.568+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:33:31.568+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:33:32.266+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:33:32.281+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:33:32.281+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:33:32.300+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:33:32.300+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:33:32.315+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.761 seconds
[2023-07-07T16:34:02.811+0000] {processor.py:157} INFO - Started process (PID=343) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:34:02.817+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:34:02.817+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:34:02.817+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:34:03.518+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:34:03.535+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:34:03.535+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:34:03.553+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:34:03.553+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:34:03.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.760 seconds
[2023-07-07T16:34:34.051+0000] {processor.py:157} INFO - Started process (PID=365) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:34:34.062+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:34:34.063+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:34:34.063+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:34:34.766+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:34:34.782+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:34:34.782+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:34:34.800+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:34:34.800+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:34:34.816+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.768 seconds
[2023-07-07T16:35:05.298+0000] {processor.py:157} INFO - Started process (PID=387) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:35:05.304+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:35:05.304+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:35:05.304+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:35:05.998+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:35:06.015+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:35:06.015+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:35:06.033+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:35:06.033+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:35:06.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.751 seconds
[2023-07-07T16:35:36.567+0000] {processor.py:157} INFO - Started process (PID=409) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:35:36.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:35:36.572+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:35:36.572+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:35:37.274+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:35:37.289+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:35:37.289+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:35:37.308+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:35:37.307+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:35:37.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.759 seconds
[2023-07-07T16:36:07.852+0000] {processor.py:157} INFO - Started process (PID=431) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:36:07.857+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:36:07.858+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:36:07.858+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:36:08.560+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:36:08.576+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:36:08.576+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:36:08.594+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:36:08.594+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:36:08.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.759 seconds
[2023-07-07T16:36:39.114+0000] {processor.py:157} INFO - Started process (PID=453) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:36:39.120+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:36:39.121+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:36:39.121+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:36:39.821+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:36:39.837+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:36:39.837+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:36:39.854+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:36:39.854+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:36:39.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.753 seconds
[2023-07-07T16:37:10.388+0000] {processor.py:157} INFO - Started process (PID=475) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:37:10.399+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:37:10.399+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:37:10.399+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:37:11.097+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:37:11.113+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:37:11.113+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:37:11.203+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:37:11.203+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:37:11.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.834 seconds
[2023-07-07T16:37:41.470+0000] {processor.py:157} INFO - Started process (PID=504) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:37:41.480+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:37:41.480+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:37:41.480+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:37:42.181+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:37:42.197+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:37:42.197+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:37:42.216+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:37:42.216+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:37:42.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.764 seconds
[2023-07-07T16:38:12.753+0000] {processor.py:157} INFO - Started process (PID=526) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:38:12.762+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:38:12.762+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:38:12.762+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:38:13.462+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:38:13.478+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:38:13.478+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:38:13.496+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:38:13.496+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:38:13.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.755 seconds
[2023-07-07T16:38:44.041+0000] {processor.py:157} INFO - Started process (PID=548) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:38:44.042+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:38:44.042+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:38:44.042+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:38:44.738+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:38:44.755+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:38:44.754+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:38:44.773+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:38:44.773+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:38:44.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.750 seconds
[2023-07-07T16:39:15.355+0000] {processor.py:157} INFO - Started process (PID=570) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:39:15.366+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:39:15.366+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:39:15.366+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:39:16.066+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:39:16.081+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:39:16.081+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:39:16.100+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:39:16.100+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:39:16.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.831 seconds
[2023-07-07T16:39:46.500+0000] {processor.py:157} INFO - Started process (PID=592) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:39:46.506+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:39:46.506+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:39:46.506+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:39:47.216+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:39:47.231+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:39:47.231+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:39:47.249+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:39:47.249+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:39:47.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.765 seconds
[2023-07-07T16:40:17.803+0000] {processor.py:157} INFO - Started process (PID=615) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:40:17.804+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:40:17.804+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:40:17.804+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:40:18.504+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:40:18.520+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:40:18.520+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:40:18.538+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:40:18.538+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:40:18.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.747 seconds
[2023-07-07T16:40:49.091+0000] {processor.py:157} INFO - Started process (PID=637) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:40:49.100+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:40:49.100+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:40:49.100+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:40:49.800+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:40:49.816+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:40:49.816+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:40:49.834+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:40:49.834+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:40:49.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.761 seconds
[2023-07-07T16:41:20.357+0000] {processor.py:157} INFO - Started process (PID=659) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:41:20.364+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:41:20.365+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:41:20.365+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:41:21.075+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:41:21.092+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:41:21.092+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:41:21.111+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:41:21.111+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:41:21.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.843 seconds
[2023-07-07T16:41:51.640+0000] {processor.py:157} INFO - Started process (PID=681) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:41:51.647+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:41:51.647+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:41:51.647+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:41:52.358+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:41:52.374+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:41:52.374+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:41:52.393+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:41:52.393+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:41:52.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.765 seconds
[2023-07-07T16:42:22.892+0000] {processor.py:157} INFO - Started process (PID=703) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:42:22.893+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:42:22.893+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:42:22.893+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:42:23.618+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:42:23.636+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:42:23.636+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:42:23.656+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:42:23.656+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:42:23.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.783 seconds
[2023-07-07T16:42:54.167+0000] {processor.py:157} INFO - Started process (PID=725) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:42:54.176+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:42:54.176+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:42:54.176+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:42:54.892+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:42:54.910+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:42:54.909+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:42:54.929+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:42:54.929+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:42:54.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.776 seconds
[2023-07-07T16:43:25.448+0000] {processor.py:157} INFO - Started process (PID=748) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:43:25.454+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:43:25.455+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:43:25.455+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:43:26.160+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:43:26.175+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:43:26.175+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:43:26.193+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:43:26.193+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:43:26.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.834 seconds
[2023-07-07T16:43:56.557+0000] {processor.py:157} INFO - Started process (PID=770) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:43:56.566+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:43:56.567+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:43:56.567+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:43:57.273+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:43:57.290+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:43:57.290+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:43:57.309+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:43:57.309+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:43:57.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.769 seconds
[2023-07-07T16:44:27.788+0000] {processor.py:157} INFO - Started process (PID=792) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:44:27.793+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:44:27.794+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:44:27.794+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:44:28.504+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:44:28.536+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:44:28.536+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:44:28.555+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:44:28.555+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:44:28.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.779 seconds
[2023-07-07T16:44:59.000+0000] {processor.py:157} INFO - Started process (PID=814) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:44:59.011+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:44:59.011+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:44:59.011+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:44:59.815+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:44:59.832+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:44:59.832+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:44:59.851+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:44:59.851+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:44:59.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.869 seconds
[2023-07-07T16:45:30.160+0000] {processor.py:157} INFO - Started process (PID=836) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:45:30.166+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:45:30.166+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:45:30.166+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:45:30.895+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:45:30.911+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:45:30.911+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:45:30.930+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:45:30.930+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:45:31.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.863 seconds
[2023-07-07T16:46:01.305+0000] {processor.py:157} INFO - Started process (PID=858) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:46:01.310+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:46:01.311+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:46:01.311+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:46:02.019+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:46:02.035+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:46:02.035+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:46:02.054+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:46:02.054+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:46:02.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.767 seconds
[2023-07-07T16:46:32.544+0000] {processor.py:157} INFO - Started process (PID=880) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:46:32.549+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:46:32.550+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:46:32.549+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:46:33.278+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:46:33.294+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:46:33.294+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:46:33.312+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:46:33.312+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:46:33.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.783 seconds
[2023-07-07T16:47:03.780+0000] {processor.py:157} INFO - Started process (PID=903) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:47:03.786+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:47:03.786+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:47:03.786+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:47:04.570+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:47:04.587+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:47:04.587+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:47:04.605+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:47:04.605+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:47:04.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.846 seconds
[2023-07-07T16:47:34.904+0000] {processor.py:157} INFO - Started process (PID=925) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:47:34.910+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:47:34.910+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:47:34.910+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:47:35.618+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:47:35.634+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:47:35.634+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:47:35.653+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:47:35.653+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:47:35.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.840 seconds
[2023-07-07T16:48:06.031+0000] {processor.py:157} INFO - Started process (PID=947) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:48:06.038+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:48:06.038+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:48:06.038+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:48:06.743+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:48:06.760+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:48:06.759+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:48:06.850+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:48:06.850+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:48:06.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.838 seconds
[2023-07-07T16:48:37.182+0000] {processor.py:157} INFO - Started process (PID=969) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:48:37.187+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:48:37.187+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:48:37.187+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:48:37.887+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:48:37.904+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:48:37.904+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:48:37.922+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:48:37.922+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:48:37.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.759 seconds
[2023-07-07T16:49:08.416+0000] {processor.py:157} INFO - Started process (PID=991) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:49:08.422+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:49:08.422+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:49:08.422+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:49:09.194+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:49:09.210+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:49:09.209+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:49:09.227+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:49:09.227+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:49:09.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.828 seconds
[2023-07-07T16:49:39.516+0000] {processor.py:157} INFO - Started process (PID=1013) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:49:39.523+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:49:39.523+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:49:39.523+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:49:40.235+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:49:40.252+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:49:40.251+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:49:40.271+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:49:40.271+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:49:40.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.850 seconds
[2023-07-07T16:50:10.630+0000] {processor.py:157} INFO - Started process (PID=1035) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:50:10.637+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:50:10.637+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:50:10.637+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:50:11.341+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:50:11.357+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:50:11.357+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:50:11.446+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:50:11.446+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:50:11.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.834 seconds
[2023-07-07T16:50:41.722+0000] {processor.py:157} INFO - Started process (PID=1057) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:50:41.728+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:50:41.729+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:50:41.729+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:50:42.444+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:50:42.463+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:50:42.462+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:50:42.482+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:50:42.482+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:50:42.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.777 seconds
[2023-07-07T16:51:12.973+0000] {processor.py:157} INFO - Started process (PID=1079) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:51:12.982+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:51:12.983+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:51:12.983+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:51:13.766+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:51:13.782+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:51:13.781+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:51:13.800+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:51:13.800+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:51:13.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.841 seconds
[2023-07-07T16:51:44.081+0000] {processor.py:157} INFO - Started process (PID=1101) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:51:44.092+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:51:44.093+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:51:44.093+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:51:44.832+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:51:44.849+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:51:44.848+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:51:44.869+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:51:44.868+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:51:44.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.881 seconds
[2023-07-07T16:52:15.256+0000] {processor.py:157} INFO - Started process (PID=1130) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:52:15.261+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:52:15.262+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:52:15.262+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:52:16.013+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:52:16.031+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:52:16.031+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:52:16.139+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:52:16.139+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:52:16.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.901 seconds
[2023-07-07T16:52:46.450+0000] {processor.py:157} INFO - Started process (PID=1152) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:52:46.456+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:52:46.457+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:52:46.457+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:52:47.180+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:52:47.198+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:52:47.198+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:52:47.217+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:52:47.217+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:52:47.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.786 seconds
[2023-07-07T16:53:17.729+0000] {processor.py:157} INFO - Started process (PID=1174) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:53:17.735+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:53:17.735+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:53:17.735+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:53:18.534+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:53:18.549+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:53:18.549+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:53:18.567+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:53:18.567+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:53:18.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.856 seconds
[2023-07-07T16:53:48.904+0000] {processor.py:157} INFO - Started process (PID=1196) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:53:48.914+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:53:48.915+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:53:48.914+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:53:49.629+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:53:49.645+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:53:49.644+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:53:49.664+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:53:49.664+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:53:49.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.847 seconds
[2023-07-07T16:54:20.058+0000] {processor.py:157} INFO - Started process (PID=1218) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:54:20.064+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:54:20.064+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:54:20.064+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:54:20.769+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:54:20.784+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:54:20.784+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:54:20.873+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:54:20.873+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:54:20.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.834 seconds
[2023-07-07T16:54:51.203+0000] {processor.py:157} INFO - Started process (PID=1240) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:54:51.208+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:54:51.209+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:54:51.209+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:54:51.904+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:54:51.920+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:54:51.920+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:54:51.938+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:54:51.938+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:54:51.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.753 seconds
[2023-07-07T16:55:22.505+0000] {processor.py:157} INFO - Started process (PID=1262) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:55:22.510+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:55:22.511+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:55:22.510+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:55:23.277+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:55:23.293+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:55:23.293+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:55:23.311+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:55:23.311+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:55:23.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.824 seconds
[2023-07-07T16:55:53.634+0000] {processor.py:157} INFO - Started process (PID=1285) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:55:53.634+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:55:53.635+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:55:53.635+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:55:54.333+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:55:54.349+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:55:54.349+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:55:54.367+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:55:54.367+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:55:54.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.823 seconds
[2023-07-07T16:56:24.696+0000] {processor.py:157} INFO - Started process (PID=1307) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:56:24.697+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:56:24.698+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:56:24.697+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:56:25.407+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:56:25.425+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:56:25.425+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:56:25.515+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:56:25.515+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:56:25.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.832 seconds
[2023-07-07T16:56:56.005+0000] {processor.py:157} INFO - Started process (PID=1329) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:56:56.015+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:56:56.015+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:56:56.015+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:56:56.716+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:56:56.733+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:56:56.733+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:56:56.751+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:56:56.751+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:56:56.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.763 seconds
[2023-07-07T16:57:27.303+0000] {processor.py:157} INFO - Started process (PID=1351) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:57:27.309+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:57:27.309+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:57:27.309+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:57:28.078+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:57:28.094+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:57:28.093+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:57:28.113+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:57:28.113+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:57:28.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.823 seconds
[2023-07-07T16:57:58.592+0000] {processor.py:157} INFO - Started process (PID=1373) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:57:58.598+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:57:58.598+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:57:58.598+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:57:59.301+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:57:59.318+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:57:59.318+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:57:59.337+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:57:59.337+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:57:59.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.841 seconds
[2023-07-07T16:58:29.648+0000] {processor.py:157} INFO - Started process (PID=1395) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:58:29.654+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:58:29.655+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:58:29.655+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:58:30.358+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:58:30.375+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:58:30.374+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:58:30.465+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:58:30.465+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:58:30.481+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.836 seconds
[2023-07-07T16:59:00.926+0000] {processor.py:157} INFO - Started process (PID=1418) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:59:00.932+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:59:00.932+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:59:00.932+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:59:01.644+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:59:01.661+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:59:01.660+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:59:01.678+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:59:01.678+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:59:01.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.770 seconds
[2023-07-07T16:59:32.147+0000] {processor.py:157} INFO - Started process (PID=1440) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:59:32.153+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T16:59:32.153+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:59:32.153+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:59:32.921+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T16:59:32.937+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:59:32.936+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T16:59:32.954+0000] {logging_mixin.py:149} INFO - [2023-07-07T16:59:32.954+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T16:59:32.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.824 seconds
[2023-07-07T17:00:03.243+0000] {processor.py:157} INFO - Started process (PID=1462) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:00:03.249+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:00:03.249+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:00:03.249+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:00:04.029+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:00:04.046+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:00:04.045+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:00:04.063+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:00:04.063+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:00:04.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.838 seconds
[2023-07-07T17:00:34.398+0000] {processor.py:157} INFO - Started process (PID=1484) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:00:34.407+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:00:34.408+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:00:34.408+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:00:35.112+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:00:35.127+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:00:35.127+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:00:35.217+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:00:35.217+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:00:35.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.837 seconds
[2023-07-07T17:01:44.039+0000] {processor.py:157} INFO - Started process (PID=32) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:01:44.040+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:01:44.041+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:01:44.040+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:01:45.578+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:01:45.613+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:01:45.613+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:01:45.641+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:01:45.641+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:01:45.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.624 seconds
[2023-07-07T17:02:15.769+0000] {processor.py:157} INFO - Started process (PID=55) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:02:15.775+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:02:15.775+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:02:15.775+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:02:16.538+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:02:16.554+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:02:16.554+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:02:16.573+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:02:16.573+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:02:16.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.816 seconds
[2023-07-07T17:02:47.046+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:02:47.052+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:02:47.052+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:02:47.052+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:02:47.874+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:02:47.891+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:02:47.891+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:02:47.913+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:02:47.913+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:02:47.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.893 seconds
[2023-07-07T17:03:18.514+0000] {processor.py:157} INFO - Started process (PID=99) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:03:18.515+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:03:18.515+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:03:18.515+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:03:19.261+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:03:19.279+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:03:19.279+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:03:19.297+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:03:19.297+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:03:19.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.816 seconds
[2023-07-07T17:03:49.718+0000] {processor.py:157} INFO - Started process (PID=121) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:03:49.723+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:03:49.724+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:03:49.724+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:03:50.463+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:03:50.480+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:03:50.480+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:03:50.501+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:03:50.501+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:03:50.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.802 seconds
[2023-07-07T17:04:20.854+0000] {processor.py:157} INFO - Started process (PID=143) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:04:20.859+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:04:20.860+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:04:20.860+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:04:21.604+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:04:21.620+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:04:21.619+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:04:21.639+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:04:21.639+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:04:21.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.803 seconds
[2023-07-07T17:04:52.051+0000] {processor.py:157} INFO - Started process (PID=165) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:04:52.056+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:04:52.056+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:04:52.056+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:04:52.799+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:04:52.815+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:04:52.815+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:04:52.835+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:04:52.835+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:04:52.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.799 seconds
[2023-07-07T17:05:23.322+0000] {processor.py:157} INFO - Started process (PID=187) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:05:23.327+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:05:23.328+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:05:23.328+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:05:24.067+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:05:24.084+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:05:24.083+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:05:24.106+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:05:24.106+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:05:24.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.800 seconds
[2023-07-07T17:05:54.476+0000] {processor.py:157} INFO - Started process (PID=209) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:05:54.487+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:05:54.488+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:05:54.488+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:05:55.233+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:05:55.248+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:05:55.248+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:05:55.266+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:05:55.266+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:05:55.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.819 seconds
[2023-07-07T17:06:25.673+0000] {processor.py:157} INFO - Started process (PID=231) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:06:25.678+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:06:25.679+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:06:25.679+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:06:26.406+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:06:26.423+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:06:26.422+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:06:26.442+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:06:26.442+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:06:26.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.781 seconds
[2023-07-07T17:06:56.870+0000] {processor.py:157} INFO - Started process (PID=252) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:06:56.879+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:06:56.880+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:06:56.880+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:06:57.622+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:06:57.639+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:06:57.639+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:06:57.657+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:06:57.657+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:06:57.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.806 seconds
[2023-07-07T17:07:28.046+0000] {processor.py:157} INFO - Started process (PID=274) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:07:28.057+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:07:28.058+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:07:28.058+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:07:28.790+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:07:28.809+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:07:28.809+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:07:28.828+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:07:28.828+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:07:28.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.800 seconds
[2023-07-07T17:07:59.241+0000] {processor.py:157} INFO - Started process (PID=296) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:07:59.246+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:07:59.247+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:07:59.247+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:07:59.990+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:08:00.006+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:08:00.006+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:08:00.025+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:08:00.025+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:08:00.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.800 seconds
[2023-07-07T17:08:30.512+0000] {processor.py:157} INFO - Started process (PID=318) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:08:30.518+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:08:30.519+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:08:30.518+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:08:31.255+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:08:31.275+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:08:31.275+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:08:31.295+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:08:31.295+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:08:31.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.802 seconds
[2023-07-07T17:09:01.750+0000] {processor.py:157} INFO - Started process (PID=340) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:09:01.760+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:09:01.761+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:09:01.760+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:09:02.506+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:09:02.522+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:09:02.522+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:09:02.542+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:09:02.541+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:09:02.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.810 seconds
[2023-07-07T17:09:32.768+0000] {processor.py:157} INFO - Started process (PID=362) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:09:32.773+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:09:32.773+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:09:32.773+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:09:33.533+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:09:33.551+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:09:33.551+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:09:33.571+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:09:33.571+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:09:33.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.820 seconds
[2023-07-07T17:10:04.039+0000] {processor.py:157} INFO - Started process (PID=384) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:10:04.045+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:10:04.045+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:10:04.045+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:10:04.790+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:10:04.807+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:10:04.806+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:10:04.825+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:10:04.825+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:10:04.842+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.805 seconds
[2023-07-07T17:10:35.110+0000] {processor.py:157} INFO - Started process (PID=406) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:10:35.115+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:10:35.116+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:10:35.116+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:10:35.860+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:10:35.876+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:10:35.875+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:10:35.897+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:10:35.897+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:10:35.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.804 seconds
[2023-07-07T17:11:06.297+0000] {processor.py:157} INFO - Started process (PID=428) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:11:06.302+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:11:06.303+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:11:06.303+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:11:07.037+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:11:07.053+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:11:07.053+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:11:07.073+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:11:07.073+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:11:07.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.795 seconds
[2023-07-07T17:11:37.558+0000] {processor.py:157} INFO - Started process (PID=450) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:11:37.566+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:11:37.566+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:11:37.566+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:11:38.304+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:11:38.323+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:11:38.323+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:11:38.341+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:11:38.341+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:11:38.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.797 seconds
[2023-07-07T17:12:08.729+0000] {processor.py:157} INFO - Started process (PID=472) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:12:08.735+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:12:08.735+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:12:08.735+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:12:09.476+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:12:09.492+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:12:09.492+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:12:09.510+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:12:09.510+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:12:09.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.794 seconds
[2023-07-07T17:12:39.919+0000] {processor.py:157} INFO - Started process (PID=500) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:12:39.924+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:12:39.925+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:12:39.925+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:12:40.666+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:12:40.681+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:12:40.681+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:12:40.701+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:12:40.700+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:12:40.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.794 seconds
[2023-07-07T17:13:11.102+0000] {processor.py:157} INFO - Started process (PID=523) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:13:11.109+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:13:11.110+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:13:11.110+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:13:11.854+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:13:11.872+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:13:11.871+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:13:11.893+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:13:11.893+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:13:11.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.810 seconds
[2023-07-07T17:13:42.278+0000] {processor.py:157} INFO - Started process (PID=545) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:13:42.284+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:13:42.284+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:13:42.284+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:13:43.019+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:13:43.037+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:13:43.037+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:13:43.056+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:13:43.056+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:13:43.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.806 seconds
[2023-07-07T17:14:13.456+0000] {processor.py:157} INFO - Started process (PID=567) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:14:13.461+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:14:13.461+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:14:13.461+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:14:14.187+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:14:14.204+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:14:14.204+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:14:14.225+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:14:14.225+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:14:14.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.788 seconds
[2023-07-07T17:14:44.717+0000] {processor.py:157} INFO - Started process (PID=589) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:14:44.723+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:14:44.723+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:14:44.723+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:14:45.468+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:14:45.485+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:14:45.485+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:14:45.507+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:14:45.506+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:14:45.521+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.806 seconds
[2023-07-07T17:15:15.975+0000] {processor.py:157} INFO - Started process (PID=611) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:15:15.980+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:15:15.980+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:15:15.980+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:15:16.737+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:15:16.753+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:15:16.752+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:15:16.771+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:15:16.771+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:15:16.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.814 seconds
[2023-07-07T17:15:47.048+0000] {processor.py:157} INFO - Started process (PID=633) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:15:47.053+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:15:47.054+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:15:47.053+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:15:47.799+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:15:47.819+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:15:47.818+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:15:47.839+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:15:47.839+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:15:47.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.809 seconds
[2023-07-07T17:16:18.230+0000] {processor.py:157} INFO - Started process (PID=655) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:16:18.236+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:16:18.236+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:16:18.236+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:16:18.966+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:16:18.985+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:16:18.984+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:16:19.003+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:16:19.003+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:16:19.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.792 seconds
[2023-07-07T17:16:49.537+0000] {processor.py:157} INFO - Started process (PID=677) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:16:49.542+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:16:49.543+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:16:49.543+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:16:50.291+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:16:50.313+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:16:50.313+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:16:50.336+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:16:50.336+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:16:50.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.820 seconds
[2023-07-07T17:17:20.643+0000] {processor.py:157} INFO - Started process (PID=700) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:17:20.644+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:17:20.644+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:17:20.644+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:17:21.380+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:17:21.396+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:17:21.396+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:17:21.414+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:17:21.414+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:17:21.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.789 seconds
[2023-07-07T17:17:51.934+0000] {processor.py:157} INFO - Started process (PID=723) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:17:51.939+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:17:51.940+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:17:51.939+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:17:52.664+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:17:52.681+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:17:52.680+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:17:52.698+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:17:52.698+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:17:52.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.783 seconds
[2023-07-07T17:18:23.140+0000] {processor.py:157} INFO - Started process (PID=745) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:18:23.140+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:18:23.141+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:18:23.141+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:18:23.887+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:18:23.907+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:18:23.907+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:18:23.926+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:18:23.926+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:18:23.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.804 seconds
[2023-07-07T17:18:54.338+0000] {processor.py:157} INFO - Started process (PID=767) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:18:54.343+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:18:54.343+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:18:54.343+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:18:55.092+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:18:55.108+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:18:55.108+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:18:55.127+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:18:55.127+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:18:55.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.804 seconds
[2023-07-07T17:19:25.608+0000] {processor.py:157} INFO - Started process (PID=789) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:19:25.613+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:19:25.613+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:19:25.613+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:19:26.355+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:19:26.372+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:19:26.371+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:19:26.391+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:19:26.391+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:19:26.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.795 seconds
[2023-07-07T17:19:56.757+0000] {processor.py:157} INFO - Started process (PID=811) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:19:56.767+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:19:56.768+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:19:56.767+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:19:57.501+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:19:57.519+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:19:57.519+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:19:57.538+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:19:57.538+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:19:57.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.801 seconds
[2023-07-07T17:20:28.020+0000] {processor.py:157} INFO - Started process (PID=833) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:20:28.027+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:20:28.028+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:20:28.028+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:20:28.764+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:20:28.781+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:20:28.780+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:20:28.800+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:20:28.800+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:20:28.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.791 seconds
[2023-07-07T17:20:59.225+0000] {processor.py:157} INFO - Started process (PID=855) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:20:59.231+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:20:59.232+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:20:59.232+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:20:59.975+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:20:59.991+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:20:59.991+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:21:00.009+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:21:00.009+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:21:00.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.799 seconds
[2023-07-07T17:21:30.387+0000] {processor.py:157} INFO - Started process (PID=877) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:21:30.393+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:21:30.394+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:21:30.394+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:21:31.135+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:21:31.152+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:21:31.152+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:21:31.173+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:21:31.173+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:21:31.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.810 seconds
[2023-07-07T17:22:01.653+0000] {processor.py:157} INFO - Started process (PID=899) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:22:01.661+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:22:01.661+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:22:01.661+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:22:02.404+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:22:02.420+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:22:02.420+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:22:02.439+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:22:02.439+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:22:02.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.804 seconds
[2023-07-07T17:22:32.809+0000] {processor.py:157} INFO - Started process (PID=921) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:22:32.809+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:22:32.810+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:22:32.810+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:22:33.557+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:22:33.575+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:22:33.574+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:22:33.594+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:22:33.594+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:22:33.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.799 seconds
[2023-07-07T17:23:04.009+0000] {processor.py:157} INFO - Started process (PID=943) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:23:04.014+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:23:04.014+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:23:04.014+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:23:04.752+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:23:04.770+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:23:04.769+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:23:04.790+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:23:04.790+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:23:04.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.800 seconds
[2023-07-07T17:23:35.177+0000] {processor.py:157} INFO - Started process (PID=965) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:23:35.182+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:23:35.183+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:23:35.182+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:23:35.938+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:23:35.957+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:23:35.956+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:23:35.976+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:23:35.975+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:23:35.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.817 seconds
[2023-07-07T17:24:06.394+0000] {processor.py:157} INFO - Started process (PID=987) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:24:06.399+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:24:06.400+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:24:06.400+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:24:07.140+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:24:07.158+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:24:07.158+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:24:07.178+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:24:07.177+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:24:07.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.803 seconds
[2023-07-07T17:24:37.584+0000] {processor.py:157} INFO - Started process (PID=1009) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:24:37.590+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:24:37.590+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:24:37.590+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:24:38.341+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:24:38.360+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:24:38.359+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:24:38.378+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:24:38.378+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:24:38.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.807 seconds
[2023-07-07T17:25:08.784+0000] {processor.py:157} INFO - Started process (PID=1031) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:25:08.791+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:25:08.791+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:25:08.791+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:25:09.534+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:25:09.549+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:25:09.549+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:25:09.569+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:25:09.569+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:25:09.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.803 seconds
[2023-07-07T17:25:39.982+0000] {processor.py:157} INFO - Started process (PID=1053) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:25:39.988+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:25:39.988+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:25:39.988+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:25:40.737+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:25:40.754+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:25:40.754+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:25:40.773+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:25:40.773+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:25:40.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.810 seconds
[2023-07-07T17:26:11.162+0000] {processor.py:157} INFO - Started process (PID=1075) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:26:11.168+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:26:11.169+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:26:11.169+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:26:11.939+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:26:11.956+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:26:11.956+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:26:11.975+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:26:11.975+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:26:11.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.834 seconds
[2023-07-07T17:26:42.337+0000] {processor.py:157} INFO - Started process (PID=1097) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:26:42.343+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:26:42.343+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:26:42.343+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:26:43.103+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:26:43.122+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:26:43.121+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:26:43.141+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:26:43.141+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:26:43.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.816 seconds
[2023-07-07T17:27:13.524+0000] {processor.py:157} INFO - Started process (PID=1126) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:27:13.536+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:27:13.537+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:27:13.537+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:27:14.280+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:27:14.298+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:27:14.298+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:27:14.317+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:27:14.317+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:27:14.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.814 seconds
[2023-07-07T17:27:44.721+0000] {processor.py:157} INFO - Started process (PID=1148) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:27:44.726+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:27:44.727+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:27:44.727+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:27:45.490+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:27:45.507+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:27:45.507+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:27:45.526+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:27:45.526+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:27:45.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.818 seconds
[2023-07-07T17:28:15.986+0000] {processor.py:157} INFO - Started process (PID=1170) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:28:15.995+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:28:15.996+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:28:15.996+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:28:16.734+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:28:16.750+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:28:16.750+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:28:16.769+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:28:16.769+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:28:16.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.802 seconds
[2023-07-07T17:28:46.975+0000] {processor.py:157} INFO - Started process (PID=1192) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:28:46.986+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:28:46.986+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:28:46.986+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:28:47.737+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:28:47.754+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:28:47.753+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:28:47.772+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:28:47.772+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:28:47.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.824 seconds
[2023-07-07T17:29:18.147+0000] {processor.py:157} INFO - Started process (PID=1214) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:29:18.152+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:29:18.152+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:29:18.152+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:29:18.925+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:29:18.940+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:29:18.940+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:29:18.960+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:29:18.960+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:29:18.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.832 seconds
[2023-07-07T17:29:49.408+0000] {processor.py:157} INFO - Started process (PID=1236) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:29:49.413+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:29:49.414+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:29:49.414+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:29:50.151+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:29:50.168+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:29:50.168+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:29:50.187+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:29:50.187+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:29:50.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.797 seconds
[2023-07-07T17:30:20.678+0000] {processor.py:157} INFO - Started process (PID=1258) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:30:20.683+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:30:20.684+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:30:20.684+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:30:21.436+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:30:21.455+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:30:21.454+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:30:21.481+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:30:21.481+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:30:21.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.816 seconds
[2023-07-07T17:30:51.784+0000] {processor.py:157} INFO - Started process (PID=1280) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:30:51.790+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:30:51.790+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:30:51.790+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:30:52.559+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:30:52.578+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:30:52.577+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:30:52.597+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:30:52.596+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:30:52.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.829 seconds
[2023-07-07T17:31:22.910+0000] {processor.py:157} INFO - Started process (PID=1302) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:31:22.915+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:31:22.915+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:31:22.915+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:31:23.669+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:31:23.685+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:31:23.685+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:31:23.708+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:31:23.708+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:31:23.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.818 seconds
[2023-07-07T17:31:54.018+0000] {processor.py:157} INFO - Started process (PID=1325) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:31:54.023+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:31:54.024+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:31:54.024+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:31:54.755+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:31:54.773+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:31:54.772+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:31:54.796+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:31:54.796+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:31:54.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.796 seconds
[2023-07-07T17:32:25.077+0000] {processor.py:157} INFO - Started process (PID=1347) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:32:25.083+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:32:25.084+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:32:25.083+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:32:25.821+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:32:25.838+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:32:25.837+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:32:25.856+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:32:25.856+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:32:25.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.796 seconds
[2023-07-07T17:32:56.289+0000] {processor.py:157} INFO - Started process (PID=1370) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:32:56.289+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:32:56.290+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:32:56.290+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:32:57.019+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:32:57.037+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:32:57.037+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:32:57.055+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:32:57.055+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:32:57.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.780 seconds
[2023-07-07T17:33:27.567+0000] {processor.py:157} INFO - Started process (PID=1393) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:33:27.580+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:33:27.581+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:33:27.581+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:33:28.298+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:33:28.314+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:33:28.313+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:33:28.332+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:33:28.332+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:33:28.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.778 seconds
[2023-07-07T17:33:58.778+0000] {processor.py:157} INFO - Started process (PID=1415) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:33:58.783+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:33:58.784+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:33:58.784+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:33:59.487+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:33:59.504+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:33:59.504+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:33:59.522+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:33:59.522+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:33:59.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.762 seconds
[2023-07-07T17:34:30.064+0000] {processor.py:157} INFO - Started process (PID=1437) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:34:30.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:34:30.070+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:34:30.070+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:34:30.816+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:34:30.832+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:34:30.832+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:34:30.850+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:34:30.850+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:34:30.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.803 seconds
[2023-07-07T17:35:01.298+0000] {processor.py:157} INFO - Started process (PID=1459) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:35:01.304+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:35:01.304+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:35:01.304+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:35:02.081+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:35:02.098+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:35:02.098+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:35:02.117+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:35:02.117+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:35:02.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.838 seconds
[2023-07-07T17:35:32.315+0000] {processor.py:157} INFO - Started process (PID=1481) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:35:32.320+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:35:32.321+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:35:32.321+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:35:33.062+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:35:33.078+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:35:33.077+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:35:33.096+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:35:33.096+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:35:33.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.800 seconds
[2023-07-07T17:36:03.551+0000] {processor.py:157} INFO - Started process (PID=1503) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:36:03.558+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:36:03.558+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:36:03.558+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:36:04.300+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:36:04.321+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:36:04.321+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:36:04.350+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:36:04.350+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:36:04.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.817 seconds
[2023-07-07T17:36:34.737+0000] {processor.py:157} INFO - Started process (PID=1525) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:36:34.743+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:36:34.744+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:36:34.743+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:36:35.468+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:36:35.486+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:36:35.486+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:36:35.504+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:36:35.504+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:36:35.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.786 seconds
[2023-07-07T17:37:05.942+0000] {processor.py:157} INFO - Started process (PID=1547) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:37:05.948+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:37:05.949+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:37:05.949+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:37:06.663+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:37:06.680+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:37:06.680+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:37:06.698+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:37:06.698+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:37:06.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.769 seconds
[2023-07-07T17:37:37.154+0000] {processor.py:157} INFO - Started process (PID=1569) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:37:37.160+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:37:37.161+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:37:37.160+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:37:37.954+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:37:37.971+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:37:37.970+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:37:37.992+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:37:37.992+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:37:38.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.852 seconds
[2023-07-07T17:38:08.338+0000] {processor.py:157} INFO - Started process (PID=1591) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:38:08.512+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:38:08.512+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:38:08.512+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:38:09.240+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:38:09.258+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:38:09.257+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:38:09.278+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:38:09.278+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:38:09.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.004 seconds
[2023-07-07T17:38:39.562+0000] {processor.py:157} INFO - Started process (PID=1613) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:38:39.568+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:38:39.568+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:38:39.568+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:38:40.313+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:38:40.329+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:38:40.329+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:38:40.347+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:38:40.347+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:38:40.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.804 seconds
[2023-07-07T17:39:10.748+0000] {processor.py:157} INFO - Started process (PID=1635) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:39:10.757+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:39:10.757+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:39:10.757+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:39:11.484+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:39:11.500+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:39:11.500+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:39:11.518+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:39:11.518+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:39:11.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.787 seconds
[2023-07-07T17:39:41.975+0000] {processor.py:157} INFO - Started process (PID=1657) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:39:41.980+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:39:41.980+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:39:41.980+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:39:42.706+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:39:42.722+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:39:42.722+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:39:42.741+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:39:42.741+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:39:42.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.785 seconds
[2023-07-07T17:40:13.223+0000] {processor.py:157} INFO - Started process (PID=1679) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:40:13.228+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:40:13.229+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:40:13.229+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:40:13.959+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:40:13.976+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:40:13.976+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:40:13.994+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:40:13.994+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:40:14.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.788 seconds
[2023-07-07T17:40:44.321+0000] {processor.py:157} INFO - Started process (PID=1701) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:40:44.326+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:40:44.326+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:40:44.326+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:40:45.049+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:40:45.065+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:40:45.064+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:40:45.082+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:40:45.082+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:40:45.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.780 seconds
[2023-07-07T17:41:15.427+0000] {processor.py:157} INFO - Started process (PID=1723) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:41:15.434+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:41:15.435+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:41:15.435+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:41:16.150+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:41:16.165+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:41:16.165+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:41:16.183+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:41:16.183+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:41:16.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.768 seconds
[2023-07-07T17:41:46.502+0000] {processor.py:157} INFO - Started process (PID=1745) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:41:46.508+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:41:46.508+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:41:46.508+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:41:47.250+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:41:47.266+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:41:47.266+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:41:47.285+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:41:47.285+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:41:47.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.802 seconds
[2023-07-07T17:42:17.628+0000] {processor.py:157} INFO - Started process (PID=1774) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:42:17.634+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:42:17.635+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:42:17.635+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:42:18.344+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:42:18.360+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:42:18.359+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:42:18.377+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:42:18.377+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:42:18.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.762 seconds
[2023-07-07T17:42:48.710+0000] {processor.py:157} INFO - Started process (PID=1796) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:42:48.716+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:42:48.716+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:42:48.716+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:42:49.439+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:42:49.454+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:42:49.454+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:42:49.472+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:42:49.472+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:42:49.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.781 seconds
[2023-07-07T17:43:19.820+0000] {processor.py:157} INFO - Started process (PID=1818) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:43:19.826+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:43:19.826+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:43:19.826+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:43:20.544+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:43:20.561+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:43:20.561+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:43:20.580+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:43:20.579+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:43:20.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.778 seconds
[2023-07-07T17:43:50.921+0000] {processor.py:157} INFO - Started process (PID=1840) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:43:50.927+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:43:50.927+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:43:50.927+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:43:51.655+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:43:51.671+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:43:51.671+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:43:51.689+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:43:51.689+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:43:51.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.786 seconds
[2023-07-07T17:44:22.044+0000] {processor.py:157} INFO - Started process (PID=1862) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:44:22.049+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:44:22.050+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:44:22.049+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:44:22.757+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:44:22.774+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:44:22.773+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:44:22.792+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:44:22.791+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:44:22.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.763 seconds
[2023-07-07T17:44:53.114+0000] {processor.py:157} INFO - Started process (PID=1884) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:44:53.121+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:44:53.121+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:44:53.121+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:44:53.892+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:44:53.909+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:44:53.909+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:44:53.928+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:44:53.928+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:44:53.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.827 seconds
[2023-07-07T17:45:24.254+0000] {processor.py:157} INFO - Started process (PID=1906) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:45:24.260+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:45:24.260+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:45:24.260+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:45:24.998+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:45:25.014+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:45:25.014+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:45:25.032+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:45:25.032+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:45:25.043+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.791 seconds
[2023-07-07T17:45:55.362+0000] {processor.py:157} INFO - Started process (PID=1928) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:45:55.368+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:45:55.369+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:45:55.369+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:45:56.073+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:45:56.090+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:45:56.089+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:45:56.108+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:45:56.108+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:45:56.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.763 seconds
[2023-07-07T17:46:26.559+0000] {processor.py:157} INFO - Started process (PID=1950) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:46:26.566+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:46:26.566+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:46:26.566+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:46:27.278+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:46:27.296+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:46:27.296+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:46:27.314+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:46:27.314+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:46:27.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.768 seconds
[2023-07-07T17:46:57.781+0000] {processor.py:157} INFO - Started process (PID=1972) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:46:57.788+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:46:57.789+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:46:57.788+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:46:58.557+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:46:58.574+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:46:58.574+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:46:58.592+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:46:58.592+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:46:58.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.829 seconds
[2023-07-07T17:47:28.998+0000] {processor.py:157} INFO - Started process (PID=1994) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:47:29.003+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:47:29.004+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:47:29.004+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:47:29.756+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:47:29.773+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:47:29.773+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:47:29.793+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:47:29.793+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:47:29.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.813 seconds
[2023-07-07T17:48:00.304+0000] {processor.py:157} INFO - Started process (PID=2016) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:48:00.309+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:48:00.309+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:48:00.309+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:48:01.051+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:48:01.066+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:48:01.066+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:48:01.085+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:48:01.085+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:48:01.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.799 seconds
[2023-07-07T17:48:31.320+0000] {processor.py:157} INFO - Started process (PID=2039) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:48:31.322+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:48:31.322+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:48:31.322+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:48:32.029+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:48:32.045+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:48:32.045+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:48:32.063+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:48:32.063+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:48:32.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.761 seconds
[2023-07-07T17:49:02.617+0000] {processor.py:157} INFO - Started process (PID=2062) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:49:02.623+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:49:02.624+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:49:02.624+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:49:03.337+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:49:03.354+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:49:03.354+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:49:03.372+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:49:03.372+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:49:03.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.768 seconds
[2023-07-07T17:49:33.831+0000] {processor.py:157} INFO - Started process (PID=2084) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:49:33.832+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:49:33.832+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:49:33.832+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:49:34.550+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:49:34.566+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:49:34.566+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:49:34.584+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:49:34.584+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:49:34.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.766 seconds
[2023-07-07T17:50:05.105+0000] {processor.py:157} INFO - Started process (PID=2106) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:50:05.110+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:50:05.111+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:50:05.111+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:50:05.832+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:50:05.848+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:50:05.847+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:50:05.866+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:50:05.866+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:50:05.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.773 seconds
[2023-07-07T17:50:36.257+0000] {processor.py:157} INFO - Started process (PID=2128) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:50:36.267+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:50:36.268+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:50:36.268+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:50:36.974+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:50:36.990+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:50:36.989+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:50:37.008+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:50:37.008+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:50:37.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.768 seconds
[2023-07-07T17:51:07.533+0000] {processor.py:157} INFO - Started process (PID=2150) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:51:07.538+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:51:07.538+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:51:07.538+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:51:08.261+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:51:08.279+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:51:08.279+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:51:08.298+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:51:08.298+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:51:08.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.777 seconds
[2023-07-07T17:51:38.756+0000] {processor.py:157} INFO - Started process (PID=2172) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:51:38.761+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:51:38.761+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:51:38.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:51:39.495+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:51:39.510+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:51:39.510+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:51:39.528+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:51:39.528+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:51:39.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.785 seconds
[2023-07-07T17:52:09.905+0000] {processor.py:157} INFO - Started process (PID=2194) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:52:09.910+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:52:09.911+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:52:09.911+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:52:10.631+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:52:10.647+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:52:10.646+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:52:10.665+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:52:10.665+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:52:10.676+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.773 seconds
[2023-07-07T17:52:41.116+0000] {processor.py:157} INFO - Started process (PID=2216) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:52:41.123+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:52:41.123+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:52:41.123+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:52:41.836+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:52:41.852+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:52:41.852+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:52:41.870+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:52:41.870+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:52:41.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.766 seconds
[2023-07-07T17:53:12.323+0000] {processor.py:157} INFO - Started process (PID=2238) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:53:12.329+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:53:12.330+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:53:12.330+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:53:13.035+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:53:13.050+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:53:13.050+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:53:13.068+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:53:13.068+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:53:13.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.763 seconds
[2023-07-07T17:53:43.596+0000] {processor.py:157} INFO - Started process (PID=2260) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:53:43.602+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:53:43.603+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:53:43.602+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:53:44.320+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:53:44.336+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:53:44.335+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:53:44.353+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:53:44.353+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:53:44.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.775 seconds
[2023-07-07T17:54:14.662+0000] {processor.py:157} INFO - Started process (PID=2282) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:54:14.663+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:54:14.663+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:54:14.663+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:54:15.377+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:54:15.392+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:54:15.392+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:54:15.411+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:54:15.411+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:54:15.422+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.762 seconds
[2023-07-07T17:54:45.877+0000] {processor.py:157} INFO - Started process (PID=2304) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:54:45.882+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:54:45.883+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:54:45.883+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:54:46.582+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:54:46.599+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:54:46.599+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:54:46.617+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:54:46.617+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:54:46.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.759 seconds
[2023-07-07T17:55:17.049+0000] {processor.py:157} INFO - Started process (PID=2326) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:55:17.060+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:55:17.060+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:55:17.060+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:55:17.768+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:55:17.784+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:55:17.784+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:55:17.802+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:55:17.802+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:55:17.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.765 seconds
[2023-07-07T17:55:48.256+0000] {processor.py:157} INFO - Started process (PID=2348) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:55:48.262+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:55:48.262+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:55:48.262+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:55:48.970+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:55:48.996+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:55:48.996+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:55:49.016+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:55:49.015+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:55:49.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.771 seconds
[2023-07-07T17:56:19.511+0000] {processor.py:157} INFO - Started process (PID=2370) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:56:19.522+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:56:19.522+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:56:19.522+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:56:20.239+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:56:20.278+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:56:20.278+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:56:20.300+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:56:20.300+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:56:20.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.802 seconds
[2023-07-07T17:56:50.534+0000] {processor.py:157} INFO - Started process (PID=2399) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:56:50.540+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:56:50.541+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:56:50.541+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:56:51.249+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:56:51.266+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:56:51.265+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:56:51.284+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:56:51.284+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:56:51.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.762 seconds
[2023-07-07T17:57:21.736+0000] {processor.py:157} INFO - Started process (PID=2421) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:57:21.744+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:57:21.744+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:57:21.744+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:57:22.452+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:57:22.468+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:57:22.468+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:57:22.486+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:57:22.486+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:57:22.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.763 seconds
[2023-07-07T17:57:53.005+0000] {processor.py:157} INFO - Started process (PID=2443) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:57:53.011+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:57:53.012+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:57:53.011+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:57:53.738+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:57:53.754+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:57:53.754+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:57:53.772+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:57:53.772+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:57:53.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.855 seconds
[2023-07-07T17:58:24.207+0000] {processor.py:157} INFO - Started process (PID=2465) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:58:24.214+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:58:24.214+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:58:24.214+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:58:24.931+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:58:24.946+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:58:24.946+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:58:24.964+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:58:24.964+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:58:24.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.769 seconds
[2023-07-07T17:58:55.232+0000] {processor.py:157} INFO - Started process (PID=2487) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:58:55.237+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:58:55.237+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:58:55.237+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:58:55.947+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:58:55.964+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:58:55.964+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:58:55.984+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:58:55.984+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:58:56.000+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.771 seconds
[2023-07-07T17:59:26.437+0000] {processor.py:157} INFO - Started process (PID=2509) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:59:26.443+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:59:26.444+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:59:26.444+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:59:27.155+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:59:27.171+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:59:27.170+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:59:27.188+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:59:27.188+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:59:27.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.769 seconds
[2023-07-07T17:59:57.718+0000] {processor.py:157} INFO - Started process (PID=2531) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:59:57.723+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T17:59:57.724+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:59:57.724+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:59:58.464+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T17:59:58.481+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:59:58.481+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T17:59:58.501+0000] {logging_mixin.py:149} INFO - [2023-07-07T17:59:58.501+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T17:59:58.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.879 seconds
[2023-07-07T18:00:28.783+0000] {processor.py:157} INFO - Started process (PID=2553) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:00:28.788+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:00:28.789+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:00:28.789+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:00:29.519+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:00:29.535+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:00:29.535+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:00:29.556+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:00:29.556+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:00:29.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.791 seconds
[2023-07-07T18:01:00.079+0000] {processor.py:157} INFO - Started process (PID=2575) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:01:00.086+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:01:00.086+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:01:00.086+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:01:00.816+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:01:00.836+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:01:00.835+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:01:00.854+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:01:00.854+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:01:00.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.794 seconds
[2023-07-07T18:01:31.065+0000] {processor.py:157} INFO - Started process (PID=2597) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:01:31.066+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:01:31.066+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:01:31.066+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:01:31.773+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:01:31.790+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:01:31.790+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:01:31.809+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:01:31.808+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:01:31.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.756 seconds
[2023-07-07T18:02:02.269+0000] {processor.py:157} INFO - Started process (PID=2619) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:02:02.275+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:02:02.275+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:02:02.275+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:02:02.986+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:02:03.002+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:02:03.001+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:02:03.021+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:02:03.020+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:02:03.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.836 seconds
[2023-07-07T18:02:33.468+0000] {processor.py:157} INFO - Started process (PID=2641) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:02:33.477+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:02:33.477+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:02:33.477+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:02:34.194+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:02:34.210+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:02:34.210+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:02:34.229+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:02:34.229+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:02:34.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.779 seconds
[2023-07-07T18:03:04.660+0000] {processor.py:157} INFO - Started process (PID=2663) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:03:04.671+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:03:04.671+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:03:04.671+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:03:05.376+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:03:05.392+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:03:05.392+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:03:05.410+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:03:05.410+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:03:05.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.767 seconds
[2023-07-07T18:03:35.845+0000] {processor.py:157} INFO - Started process (PID=2685) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:03:35.851+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:03:35.851+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:03:35.851+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:03:36.564+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:03:36.582+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:03:36.582+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:03:36.601+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:03:36.600+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:03:36.617+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.774 seconds
[2023-07-07T18:04:07.109+0000] {processor.py:157} INFO - Started process (PID=2708) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:04:07.110+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:04:07.110+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:04:07.110+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:04:07.816+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:04:07.832+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:04:07.832+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:04:07.850+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:04:07.850+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:04:07.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.832 seconds
[2023-07-07T18:04:38.374+0000] {processor.py:157} INFO - Started process (PID=2731) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:04:38.375+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:04:38.376+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:04:38.376+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:04:39.079+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:04:39.095+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:04:39.095+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:04:39.115+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:04:39.115+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:04:39.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.754 seconds
[2023-07-07T18:05:09.584+0000] {processor.py:157} INFO - Started process (PID=2753) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:05:09.591+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:05:09.591+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:05:09.591+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:05:10.293+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:05:10.310+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:05:10.309+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:05:10.328+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:05:10.328+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:05:10.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.755 seconds
[2023-07-07T18:05:40.787+0000] {processor.py:157} INFO - Started process (PID=2775) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:05:40.792+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:05:40.793+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:05:40.793+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:05:41.497+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:05:41.513+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:05:41.513+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:05:41.531+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:05:41.531+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:05:41.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.760 seconds
[2023-07-07T18:06:11.988+0000] {processor.py:157} INFO - Started process (PID=2797) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:06:11.993+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:06:11.993+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:06:11.993+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:06:12.702+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:06:12.718+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:06:12.718+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:06:12.737+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:06:12.737+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:06:12.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.831 seconds
[2023-07-07T18:06:43.254+0000] {processor.py:157} INFO - Started process (PID=2819) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:06:43.259+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:06:43.260+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:06:43.260+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:06:43.984+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:06:43.999+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:06:43.999+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:06:44.017+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:06:44.017+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:06:44.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.781 seconds
[2023-07-07T18:07:14.417+0000] {processor.py:157} INFO - Started process (PID=2841) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:07:14.422+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:07:14.423+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:07:14.422+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:07:15.140+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:07:15.156+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:07:15.155+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:07:15.173+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:07:15.173+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:07:15.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.773 seconds
[2023-07-07T18:07:45.614+0000] {processor.py:157} INFO - Started process (PID=2863) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:07:45.619+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:07:45.620+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:07:45.619+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:07:46.408+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:07:46.427+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:07:46.427+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:07:46.446+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:07:46.446+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:07:46.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.845 seconds
[2023-07-07T18:08:16.877+0000] {processor.py:157} INFO - Started process (PID=2885) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:08:16.877+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:08:16.878+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:08:16.877+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:08:17.616+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:08:17.632+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:08:17.632+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:08:17.651+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:08:17.651+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:08:17.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.870 seconds
[2023-07-07T18:08:48.034+0000] {processor.py:157} INFO - Started process (PID=2907) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:08:48.039+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:08:48.040+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:08:48.040+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:08:48.770+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:08:48.788+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:08:48.788+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:08:48.808+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:08:48.808+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:08:48.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.787 seconds
[2023-07-07T18:09:19.133+0000] {processor.py:157} INFO - Started process (PID=2929) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:09:19.138+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:09:19.139+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:09:19.138+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:09:19.845+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:09:19.862+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:09:19.862+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:09:19.880+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:09:19.880+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:09:19.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.760 seconds
[2023-07-07T18:09:50.309+0000] {processor.py:157} INFO - Started process (PID=2951) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:09:50.315+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:09:50.315+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:09:50.315+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:09:51.087+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:09:51.102+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:09:51.102+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:09:51.120+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:09:51.119+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:09:51.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.829 seconds
[2023-07-07T18:10:21.555+0000] {processor.py:157} INFO - Started process (PID=2973) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:10:21.562+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:10:21.562+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:10:21.562+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:10:22.357+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:10:22.374+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:10:22.373+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:10:22.394+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:10:22.393+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:10:22.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.931 seconds
[2023-07-07T18:10:52.696+0000] {processor.py:157} INFO - Started process (PID=2995) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:10:52.701+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:10:52.702+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:10:52.701+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:10:53.432+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:10:53.448+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:10:53.448+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:10:53.548+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:10:53.548+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:10:53.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.865 seconds
[2023-07-07T18:11:23.857+0000] {processor.py:157} INFO - Started process (PID=3024) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:11:23.864+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:11:23.865+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:11:23.865+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:11:24.607+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:11:24.623+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:11:24.622+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:11:24.641+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:11:24.641+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:11:24.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.801 seconds
[2023-07-07T18:11:55.058+0000] {processor.py:157} INFO - Started process (PID=3046) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:11:55.059+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:11:55.059+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:11:55.059+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:11:55.850+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:11:55.866+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:11:55.866+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:11:55.887+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:11:55.887+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:11:55.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.847 seconds
[2023-07-07T18:12:26.223+0000] {processor.py:157} INFO - Started process (PID=3068) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:12:26.236+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:12:26.236+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:12:26.236+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:12:26.958+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:12:26.974+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:12:26.974+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:12:26.994+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:12:26.994+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:12:27.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.860 seconds
[2023-07-07T18:12:57.404+0000] {processor.py:157} INFO - Started process (PID=3090) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:12:57.409+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:12:57.409+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:12:57.409+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:12:58.124+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:12:58.140+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:12:58.139+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:12:58.231+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:12:58.231+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:12:58.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.845 seconds
[2023-07-07T18:13:28.584+0000] {processor.py:157} INFO - Started process (PID=3112) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:13:28.590+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:13:28.590+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:13:28.590+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:13:29.307+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:13:29.324+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:13:29.323+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:13:29.342+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:13:29.341+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:13:29.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.771 seconds
[2023-07-07T18:13:59.747+0000] {processor.py:157} INFO - Started process (PID=3134) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:13:59.753+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:13:59.754+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:13:59.753+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:14:00.555+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:14:00.572+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:14:00.571+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:14:00.590+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:14:00.590+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:14:00.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.862 seconds
[2023-07-07T18:14:30.918+0000] {processor.py:157} INFO - Started process (PID=3156) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:14:30.925+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:14:30.926+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:14:30.926+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:14:31.649+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:14:31.665+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:14:31.664+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:14:31.683+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:14:31.683+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:14:31.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.852 seconds
[2023-07-07T18:15:02.079+0000] {processor.py:157} INFO - Started process (PID=3178) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:15:02.086+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:15:02.087+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:15:02.087+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:15:02.808+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:15:02.824+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:15:02.824+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:15:02.916+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:15:02.916+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:15:02.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.853 seconds
[2023-07-07T18:15:33.253+0000] {processor.py:157} INFO - Started process (PID=3200) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:15:33.258+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:15:33.258+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:15:33.258+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:15:33.976+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:15:33.993+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:15:33.992+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:15:34.011+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:15:34.011+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:15:34.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.776 seconds
[2023-07-07T18:16:04.430+0000] {processor.py:157} INFO - Started process (PID=3222) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:16:04.436+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:16:04.437+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:16:04.437+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:16:05.223+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:16:05.239+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:16:05.239+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:16:05.257+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:16:05.257+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:16:05.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.841 seconds
[2023-07-07T18:16:35.691+0000] {processor.py:157} INFO - Started process (PID=3244) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:16:35.697+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:16:35.697+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:16:35.697+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:16:36.415+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:16:36.431+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:16:36.431+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:16:36.450+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:16:36.450+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:16:36.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.845 seconds
[2023-07-07T18:17:06.753+0000] {processor.py:157} INFO - Started process (PID=3266) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:17:06.758+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:17:06.759+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:17:06.759+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:17:07.479+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:17:07.496+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:17:07.495+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:17:07.588+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:17:07.588+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:17:07.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.848 seconds
[2023-07-07T18:17:37.953+0000] {processor.py:157} INFO - Started process (PID=3288) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:17:37.959+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:17:37.959+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:17:37.959+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:17:38.672+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:17:38.690+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:17:38.690+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:17:38.708+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:17:38.707+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:17:38.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.771 seconds
[2023-07-07T18:18:09.174+0000] {processor.py:157} INFO - Started process (PID=3310) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:18:09.179+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:18:09.180+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:18:09.180+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:18:09.969+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:18:09.985+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:18:09.984+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:18:10.003+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:18:10.003+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:18:10.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.846 seconds
[2023-07-07T18:18:40.366+0000] {processor.py:157} INFO - Started process (PID=3332) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:18:40.371+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:18:40.371+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:18:40.371+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:18:41.090+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:18:41.106+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:18:41.106+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:18:41.125+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:18:41.125+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:18:41.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.849 seconds
[2023-07-07T18:19:11.632+0000] {processor.py:157} INFO - Started process (PID=3354) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:19:11.638+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:19:11.638+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:19:11.638+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:19:12.354+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:19:12.370+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:19:12.370+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:19:12.462+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:19:12.462+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:19:12.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.847 seconds
[2023-07-07T18:19:42.695+0000] {processor.py:157} INFO - Started process (PID=3377) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:19:42.696+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:19:42.696+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:19:42.696+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:19:43.427+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:19:43.445+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:19:43.445+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:19:43.464+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:19:43.464+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:19:43.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.787 seconds
[2023-07-07T18:20:13.986+0000] {processor.py:157} INFO - Started process (PID=3400) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:20:13.992+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:20:13.993+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:20:13.993+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:20:14.776+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:20:14.792+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:20:14.792+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:20:14.810+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:20:14.810+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:20:14.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.843 seconds
[2023-07-07T18:20:45.177+0000] {processor.py:157} INFO - Started process (PID=3422) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:20:45.184+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:20:45.184+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:20:45.184+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:20:45.908+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:20:45.925+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:20:45.925+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:20:45.945+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:20:45.944+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:20:46.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.853 seconds
[2023-07-07T18:21:16.374+0000] {processor.py:157} INFO - Started process (PID=3444) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:21:16.379+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:21:16.380+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:21:16.380+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:21:17.101+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:21:17.117+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:21:17.117+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:21:17.211+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:21:17.210+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:21:17.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.856 seconds
[2023-07-07T18:21:47.642+0000] {processor.py:157} INFO - Started process (PID=3466) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:21:47.647+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:21:47.648+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:21:47.648+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:21:48.438+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:21:48.454+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:21:48.453+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:21:48.473+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:21:48.473+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:21:48.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.846 seconds
[2023-07-07T18:22:18.664+0000] {processor.py:157} INFO - Started process (PID=3488) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:22:18.674+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:22:18.675+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:22:18.675+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:22:19.459+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:22:19.476+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:22:19.475+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:22:19.495+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:22:19.494+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:22:19.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.844 seconds
[2023-07-07T18:22:49.869+0000] {processor.py:157} INFO - Started process (PID=3510) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:22:49.874+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:22:49.875+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:22:49.874+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:22:50.660+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:22:50.676+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:22:50.676+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:22:50.694+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:22:50.694+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:22:50.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.844 seconds
[2023-07-07T18:23:21.121+0000] {processor.py:157} INFO - Started process (PID=3532) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:23:21.127+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:23:21.128+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:23:21.127+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:23:21.837+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:23:21.853+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:23:21.853+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:23:21.945+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:23:21.944+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:23:21.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.837 seconds
[2023-07-07T18:23:52.243+0000] {processor.py:157} INFO - Started process (PID=3554) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:23:52.250+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:23:52.250+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:23:52.250+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:23:53.034+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:23:53.050+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:23:53.050+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:23:53.070+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:23:53.070+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:23:53.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.840 seconds
[2023-07-07T18:24:23.437+0000] {processor.py:157} INFO - Started process (PID=3576) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:24:23.443+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:24:23.443+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:24:23.443+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:24:24.247+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:24:24.263+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:24:24.262+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:24:24.281+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:24:24.281+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:24:24.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.863 seconds
[2023-07-07T18:24:54.611+0000] {processor.py:157} INFO - Started process (PID=3598) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:24:54.617+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:24:54.617+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:24:54.617+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:24:55.401+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:24:55.418+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:24:55.417+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:24:55.437+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:24:55.437+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:24:55.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.845 seconds
[2023-07-07T18:25:25.790+0000] {processor.py:157} INFO - Started process (PID=3620) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:25:25.796+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:25:25.796+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:25:25.796+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:25:26.514+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:25:26.530+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:25:26.530+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:25:26.621+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:25:26.621+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:25:26.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.849 seconds
[2023-07-07T18:25:56.961+0000] {processor.py:157} INFO - Started process (PID=3649) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:25:56.967+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:25:56.968+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:25:56.968+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:25:57.768+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:25:57.784+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:25:57.784+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:25:57.803+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:25:57.803+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:25:57.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.860 seconds
[2023-07-07T18:26:28.154+0000] {processor.py:157} INFO - Started process (PID=3671) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:26:28.165+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:26:28.165+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:26:28.165+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:26:28.958+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:26:28.974+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:26:28.974+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:26:28.993+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:26:28.993+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:26:29.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.858 seconds
[2023-07-07T18:26:59.395+0000] {processor.py:157} INFO - Started process (PID=3693) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:26:59.400+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:26:59.401+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:26:59.401+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:27:00.183+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:27:00.199+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:27:00.199+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:27:00.217+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:27:00.217+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:27:00.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.839 seconds
[2023-07-07T18:27:30.441+0000] {processor.py:157} INFO - Started process (PID=3715) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:27:30.449+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:27:30.450+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:27:30.450+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:27:31.153+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:27:31.172+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:27:31.171+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:27:31.265+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:27:31.265+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:27:31.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.837 seconds
[2023-07-07T18:28:01.597+0000] {processor.py:157} INFO - Started process (PID=3737) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:28:01.604+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:28:01.604+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:28:01.604+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:28:02.384+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:28:02.399+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:28:02.399+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:28:02.418+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:28:02.418+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:28:02.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.833 seconds
[2023-07-07T18:28:32.772+0000] {processor.py:157} INFO - Started process (PID=3759) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:28:32.778+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:28:32.778+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:28:32.778+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:28:33.498+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:28:33.587+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:28:33.586+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:28:33.607+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:28:33.607+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:28:33.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.848 seconds
[2023-07-07T18:29:03.974+0000] {processor.py:157} INFO - Started process (PID=3781) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:29:03.980+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:29:03.980+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:29:03.980+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:29:04.750+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:29:04.766+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:29:04.766+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:29:04.784+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:29:04.784+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:29:04.800+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.829 seconds
[2023-07-07T18:29:35.154+0000] {processor.py:157} INFO - Started process (PID=3803) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:29:35.164+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:29:35.165+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:29:35.165+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:29:35.874+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:29:35.890+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:29:35.890+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:29:35.982+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:29:35.982+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:29:35.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.847 seconds
[2023-07-07T18:30:06.321+0000] {processor.py:157} INFO - Started process (PID=3825) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:30:06.333+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:30:06.334+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:30:06.334+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:30:07.118+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:30:07.134+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:30:07.134+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:30:07.152+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:30:07.152+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:30:07.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.849 seconds
[2023-07-07T18:30:37.477+0000] {processor.py:157} INFO - Started process (PID=3847) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:30:37.483+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:30:37.483+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:30:37.483+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:30:38.191+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:30:38.277+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:30:38.277+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:30:38.296+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:30:38.296+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:30:38.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.839 seconds
[2023-07-07T18:31:08.722+0000] {processor.py:157} INFO - Started process (PID=3869) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:31:08.728+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:31:08.728+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:31:08.728+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:31:09.523+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:31:09.540+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:31:09.540+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:31:09.558+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:31:09.558+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:31:09.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.850 seconds
[2023-07-07T18:31:39.754+0000] {processor.py:157} INFO - Started process (PID=3891) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:31:39.760+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:31:39.760+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:31:39.760+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:31:40.467+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:31:40.485+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:31:40.485+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:31:40.576+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:31:40.576+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:31:40.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.841 seconds
[2023-07-07T18:32:10.951+0000] {processor.py:157} INFO - Started process (PID=3912) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:32:10.956+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:32:10.957+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:32:10.957+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:32:11.800+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:32:11.823+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:32:11.823+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:32:11.843+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:32:11.843+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:32:11.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.905 seconds
[2023-07-07T18:32:42.142+0000] {processor.py:157} INFO - Started process (PID=3934) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:32:42.152+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:32:42.153+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:32:42.153+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:32:42.854+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:32:42.940+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:32:42.940+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:32:42.958+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:32:42.958+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:32:42.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.835 seconds
[2023-07-07T18:33:13.196+0000] {processor.py:157} INFO - Started process (PID=3956) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:33:13.203+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:33:13.203+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:33:13.203+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:33:13.973+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:33:13.989+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:33:13.988+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:33:14.006+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:33:14.006+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:33:14.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.828 seconds
[2023-07-07T18:33:44.420+0000] {processor.py:157} INFO - Started process (PID=3978) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:33:44.431+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:33:44.432+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:33:44.431+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:33:45.137+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:33:45.152+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:33:45.152+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:33:45.242+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:33:45.242+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:33:45.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.835 seconds
[2023-07-07T18:34:15.641+0000] {processor.py:157} INFO - Started process (PID=4000) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:34:15.646+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:34:15.647+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:34:15.647+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:34:16.427+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:34:16.443+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:34:16.443+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:34:16.462+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:34:16.462+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:34:16.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.833 seconds
[2023-07-07T18:34:46.845+0000] {processor.py:157} INFO - Started process (PID=4022) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:34:46.850+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:34:46.851+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:34:46.851+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:34:47.561+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:34:47.649+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:34:47.649+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:34:47.667+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:34:47.667+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:34:47.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.834 seconds
[2023-07-07T18:35:18.092+0000] {processor.py:157} INFO - Started process (PID=4045) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:35:18.093+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:35:18.094+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:35:18.093+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:35:18.885+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:35:18.903+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:35:18.902+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:35:18.922+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:35:18.922+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:35:18.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.847 seconds
[2023-07-07T18:35:49.365+0000] {processor.py:157} INFO - Started process (PID=4068) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:35:49.371+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:35:49.371+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:35:49.371+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:35:50.086+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:35:50.102+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:35:50.102+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:35:50.193+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:35:50.193+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:35:50.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.848 seconds
[2023-07-07T18:36:20.614+0000] {processor.py:157} INFO - Started process (PID=4090) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:36:20.619+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:36:20.620+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:36:20.620+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:36:21.409+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:36:21.425+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:36:21.424+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:36:21.443+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:36:21.443+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:36:21.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.853 seconds
[2023-07-07T18:36:51.646+0000] {processor.py:157} INFO - Started process (PID=4112) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:36:51.652+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:36:51.652+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:36:51.652+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:36:52.366+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:36:52.455+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:36:52.455+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:36:52.474+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:36:52.474+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:36:52.490+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.846 seconds
[2023-07-07T18:37:22.835+0000] {processor.py:157} INFO - Started process (PID=4134) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:37:22.840+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:37:22.841+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:37:22.841+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:37:23.624+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:37:23.641+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:37:23.641+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:37:23.660+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:37:23.660+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:37:23.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.846 seconds
[2023-07-07T18:37:54.006+0000] {processor.py:157} INFO - Started process (PID=4156) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:37:54.011+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:37:54.012+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:37:54.012+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:37:54.800+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:37:54.815+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:37:54.815+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:37:54.834+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:37:54.834+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:37:54.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.849 seconds
[2023-07-07T18:38:25.187+0000] {processor.py:157} INFO - Started process (PID=4178) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:38:25.188+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:38:25.188+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:38:25.188+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:38:25.970+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:38:25.986+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:38:25.986+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:38:26.005+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:38:26.005+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:38:26.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.832 seconds
[2023-07-07T18:38:56.376+0000] {processor.py:157} INFO - Started process (PID=4200) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:38:56.381+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:38:56.382+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:38:56.382+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:38:57.104+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:38:57.194+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:38:57.194+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:38:57.213+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:38:57.213+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:38:57.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.850 seconds
[2023-07-07T18:39:27.557+0000] {processor.py:157} INFO - Started process (PID=4222) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:39:27.564+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:39:27.564+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:39:27.564+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:39:28.363+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:39:28.379+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:39:28.379+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:39:28.397+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:39:28.397+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:39:28.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.852 seconds
[2023-07-07T18:39:58.752+0000] {processor.py:157} INFO - Started process (PID=4244) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:39:58.758+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:39:58.759+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:39:58.759+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:39:59.541+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:39:59.558+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:39:59.557+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:39:59.576+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:39:59.576+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:39:59.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.842 seconds
[2023-07-07T18:40:29.924+0000] {processor.py:157} INFO - Started process (PID=4266) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:40:29.930+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:40:29.930+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:40:29.930+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:40:30.743+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:40:30.760+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:40:30.759+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:40:30.779+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:40:30.779+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:40:30.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.873 seconds
[2023-07-07T18:41:01.114+0000] {processor.py:157} INFO - Started process (PID=4295) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:41:01.119+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:41:01.119+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:41:01.119+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:41:01.840+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:41:01.942+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:41:01.941+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:41:01.960+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:41:01.960+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:41:01.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.865 seconds
[2023-07-07T18:41:32.381+0000] {processor.py:157} INFO - Started process (PID=4317) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:41:32.387+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:41:32.387+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:41:32.387+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:41:33.205+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:41:33.222+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:41:33.221+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:41:33.240+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:41:33.240+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:41:33.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.877 seconds
[2023-07-07T18:42:03.453+0000] {processor.py:157} INFO - Started process (PID=4339) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:42:03.454+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:42:03.454+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:42:03.454+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:42:04.239+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:42:04.255+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:42:04.254+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:42:04.273+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:42:04.273+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:42:04.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.838 seconds
[2023-07-07T18:42:34.708+0000] {processor.py:157} INFO - Started process (PID=4361) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:42:34.713+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:42:34.713+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:42:34.713+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:42:35.486+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:42:35.502+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:42:35.502+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:42:35.520+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:42:35.520+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:42:35.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.830 seconds
[2023-07-07T18:43:05.834+0000] {processor.py:157} INFO - Started process (PID=4383) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:43:05.839+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:43:05.840+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:43:05.840+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:43:06.555+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:43:06.644+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:43:06.644+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:43:06.662+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:43:06.662+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:43:06.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.852 seconds
[2023-07-07T18:43:36.913+0000] {processor.py:157} INFO - Started process (PID=4405) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:43:36.919+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:43:36.919+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:43:36.919+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:43:37.696+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:43:37.712+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:43:37.712+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:43:37.730+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:43:37.729+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:43:37.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.830 seconds
[2023-07-07T18:44:08.090+0000] {processor.py:157} INFO - Started process (PID=4427) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:44:08.096+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:44:08.096+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:44:08.096+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:44:08.878+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:44:08.894+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:44:08.894+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:44:08.912+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:44:08.912+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:44:08.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.835 seconds
[2023-07-07T18:44:39.265+0000] {processor.py:157} INFO - Started process (PID=4449) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:44:39.274+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:44:39.274+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:44:39.274+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:44:40.048+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:44:40.064+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:44:40.064+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:44:40.083+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:44:40.083+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:44:40.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.830 seconds
[2023-07-07T18:45:10.539+0000] {processor.py:157} INFO - Started process (PID=4471) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:45:10.554+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:45:10.554+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:45:10.554+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:45:11.259+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:45:11.344+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:45:11.343+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:45:11.362+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:45:11.362+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:45:11.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.839 seconds
[2023-07-07T18:45:41.688+0000] {processor.py:157} INFO - Started process (PID=4493) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:45:41.689+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:45:41.689+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:45:41.689+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:45:42.535+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:45:42.555+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:45:42.554+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:45:42.576+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:45:42.576+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:45:42.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.902 seconds
[2023-07-07T18:46:12.866+0000] {processor.py:157} INFO - Started process (PID=4515) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:46:12.876+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:46:12.877+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:46:12.877+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:46:13.659+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:46:13.675+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:46:13.674+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:46:13.693+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:46:13.693+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:46:13.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.846 seconds
[2023-07-07T18:46:43.926+0000] {processor.py:157} INFO - Started process (PID=4537) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:46:43.932+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:46:43.932+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:46:43.932+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:46:44.718+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:46:44.733+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:46:44.733+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:46:44.752+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:46:44.752+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:46:44.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.843 seconds
[2023-07-07T18:47:15.124+0000] {processor.py:157} INFO - Started process (PID=4559) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:47:15.130+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:47:15.130+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:47:15.130+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:47:15.881+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:47:15.976+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:47:15.975+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:47:15.995+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:47:15.995+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:47:16.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.891 seconds
[2023-07-07T18:47:46.209+0000] {processor.py:157} INFO - Started process (PID=4581) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:47:46.215+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:47:46.216+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:47:46.216+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:47:47.019+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:47:47.035+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:47:47.035+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:47:47.054+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:47:47.054+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:47:47.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.863 seconds
[2023-07-07T18:48:17.468+0000] {processor.py:157} INFO - Started process (PID=4603) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:48:17.477+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:48:17.477+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:48:17.477+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:48:18.314+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:48:18.331+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:48:18.331+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:48:18.353+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:48:18.353+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:48:18.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.904 seconds
[2023-07-07T18:48:48.603+0000] {processor.py:157} INFO - Started process (PID=4625) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:48:48.614+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:48:48.615+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:48:48.614+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:48:49.394+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:48:49.410+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:48:49.410+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:48:49.429+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:48:49.429+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:48:49.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.839 seconds
[2023-07-07T18:49:19.778+0000] {processor.py:157} INFO - Started process (PID=4647) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:49:19.784+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:49:19.785+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:49:19.785+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:49:20.502+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:49:20.597+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:49:20.596+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:49:20.615+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:49:20.615+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:49:20.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.856 seconds
[2023-07-07T18:49:50.986+0000] {processor.py:157} INFO - Started process (PID=4669) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:49:50.995+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:49:50.995+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:49:50.995+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:49:51.772+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:49:51.787+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:49:51.787+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:49:51.805+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:49:51.804+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:49:51.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.836 seconds
[2023-07-07T18:50:22.185+0000] {processor.py:157} INFO - Started process (PID=4691) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:50:22.186+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:50:22.186+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:50:22.186+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:50:23.024+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:50:23.043+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:50:23.043+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:50:23.064+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:50:23.064+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:50:23.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.891 seconds
[2023-07-07T18:50:53.327+0000] {processor.py:157} INFO - Started process (PID=4714) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:50:53.335+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:50:53.335+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:50:53.335+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:50:54.117+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:50:54.132+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:50:54.132+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:50:54.151+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:50:54.151+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:50:54.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.836 seconds
[2023-07-07T18:51:24.590+0000] {processor.py:157} INFO - Started process (PID=4737) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:51:24.590+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:51:24.591+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:51:24.591+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:51:25.529+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:51:25.551+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:51:25.550+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:51:25.572+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:51:25.572+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:51:25.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.996 seconds
[2023-07-07T18:51:55.937+0000] {processor.py:157} INFO - Started process (PID=4760) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:51:55.944+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:51:55.945+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:51:55.945+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:51:56.765+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:51:56.783+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:51:56.783+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:51:56.803+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:51:56.803+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:51:56.815+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.880 seconds
[2023-07-07T18:52:27.047+0000] {processor.py:157} INFO - Started process (PID=4783) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:52:27.048+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:52:27.048+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:52:27.048+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:52:27.840+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:52:27.856+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:52:27.856+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:52:27.875+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:52:27.874+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:52:27.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.842 seconds
[2023-07-07T18:52:58.103+0000] {processor.py:157} INFO - Started process (PID=4805) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:52:58.108+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:52:58.108+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:52:58.108+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:52:58.936+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:52:58.952+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:52:58.952+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:52:58.971+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:52:58.971+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:52:58.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.885 seconds
[2023-07-07T18:53:29.340+0000] {processor.py:157} INFO - Started process (PID=4827) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:53:29.350+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:53:29.350+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:53:29.350+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:53:30.169+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:53:30.186+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:53:30.185+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:53:30.208+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:53:30.208+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:53:30.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.888 seconds
[2023-07-07T18:54:00.520+0000] {processor.py:157} INFO - Started process (PID=4850) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:54:00.526+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:54:00.526+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:54:00.526+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:54:01.307+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:54:01.323+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:54:01.322+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:54:01.340+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:54:01.340+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:54:01.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.838 seconds
[2023-07-07T18:54:31.600+0000] {processor.py:157} INFO - Started process (PID=4872) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:54:31.606+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:54:31.606+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:54:31.606+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:54:32.412+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:54:32.428+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:54:32.428+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:54:32.447+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:54:32.446+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:54:32.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.863 seconds
[2023-07-07T18:55:02.710+0000] {processor.py:157} INFO - Started process (PID=4894) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:55:02.719+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:55:02.719+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:55:02.719+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:55:03.542+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:55:03.558+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:55:03.558+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:55:03.576+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:55:03.576+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:55:03.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.879 seconds
[2023-07-07T18:55:33.813+0000] {processor.py:157} INFO - Started process (PID=4923) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:55:33.820+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:55:33.820+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:55:33.820+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:55:34.625+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:55:34.642+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:55:34.641+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:55:34.659+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:55:34.659+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:55:34.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.859 seconds
[2023-07-07T18:56:05.069+0000] {processor.py:157} INFO - Started process (PID=4945) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:56:05.075+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:56:05.076+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:56:05.076+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:56:05.865+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:56:05.883+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:56:05.883+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:56:05.903+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:56:05.903+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:56:05.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.854 seconds
[2023-07-07T18:56:13.104+0000] {processor.py:157} INFO - Started process (PID=4958) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:56:13.105+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:56:13.105+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:56:13.105+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:56:13.886+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:56:13.901+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:56:13.901+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:56:13.919+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:56:13.919+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:56:13.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.834 seconds
[2023-07-07T18:56:44.329+0000] {processor.py:157} INFO - Started process (PID=4980) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:56:44.336+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:56:44.337+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:56:44.337+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:56:45.145+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:56:45.160+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:56:45.159+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:56:45.178+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:56:45.178+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:56:45.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.867 seconds
[2023-07-07T18:57:15.406+0000] {processor.py:157} INFO - Started process (PID=5002) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:57:15.411+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:57:15.412+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:57:15.411+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:57:16.210+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:57:16.227+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:57:16.227+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:57:16.246+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:57:16.246+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:57:16.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.855 seconds
[2023-07-07T18:57:30.546+0000] {processor.py:157} INFO - Started process (PID=5017) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:57:30.546+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:57:30.547+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:57:30.547+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:57:31.365+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:57:31.382+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:57:31.382+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:57:31.401+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:57:31.401+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:57:31.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.875 seconds
[2023-07-07T18:58:01.640+0000] {processor.py:157} INFO - Started process (PID=5039) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:58:01.647+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:58:01.647+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:58:01.647+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:58:02.440+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:58:02.456+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:58:02.455+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:58:02.474+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:58:02.474+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:58:02.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.853 seconds
[2023-07-07T18:58:07.720+0000] {processor.py:157} INFO - Started process (PID=5059) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:58:07.721+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:58:07.721+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:58:07.721+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:58:08.512+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:58:08.530+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:58:08.529+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:58:08.548+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:58:08.548+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:58:08.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.847 seconds
[2023-07-07T18:58:38.771+0000] {processor.py:157} INFO - Started process (PID=5081) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:58:38.785+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:58:38.786+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:58:38.786+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:58:39.555+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:58:39.570+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:58:39.569+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:58:39.588+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:58:39.588+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:58:39.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.834 seconds
[2023-07-07T18:59:10.007+0000] {processor.py:157} INFO - Started process (PID=5103) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:59:10.012+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:59:10.012+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:59:10.012+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:59:10.789+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:59:10.804+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:59:10.804+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:59:10.823+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:59:10.823+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:59:10.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.831 seconds
[2023-07-07T18:59:41.229+0000] {processor.py:157} INFO - Started process (PID=5125) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:59:41.235+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T18:59:41.235+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:59:41.235+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:59:42.039+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T18:59:42.054+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:59:42.054+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T18:59:42.073+0000] {logging_mixin.py:149} INFO - [2023-07-07T18:59:42.073+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T18:59:42.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.862 seconds
[2023-07-07T19:00:12.342+0000] {processor.py:157} INFO - Started process (PID=5147) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:00:12.348+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:00:12.349+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:00:12.349+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:00:13.122+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:00:13.138+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:00:13.138+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:00:13.155+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:00:13.155+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:00:13.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.826 seconds
[2023-07-07T19:00:41.564+0000] {processor.py:157} INFO - Started process (PID=5169) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:00:41.575+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:00:41.576+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:00:41.576+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:00:41.583+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:00:41.601+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:00:41.601+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:00:41.621+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:00:41.621+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:00:41.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T19:01:11.812+0000] {processor.py:157} INFO - Started process (PID=5179) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:01:11.820+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:01:11.821+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:01:11.821+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:01:11.827+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:01:11.845+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:01:11.845+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:01:11.868+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:01:11.868+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:01:11.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T19:01:13.853+0000] {processor.py:157} INFO - Started process (PID=5180) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:01:13.853+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:01:13.854+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:01:13.854+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:01:13.860+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:01:13.879+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:01:13.878+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:01:13.897+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:01:13.897+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:01:13.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.059 seconds
[2023-07-07T19:01:36.085+0000] {processor.py:157} INFO - Started process (PID=5190) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:01:36.097+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:01:36.097+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:01:36.097+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:01:36.104+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:01:36.125+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:01:36.125+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:01:36.144+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:01:36.143+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:01:36.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.073 seconds
[2023-07-07T19:01:44.151+0000] {processor.py:157} INFO - Started process (PID=5191) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:01:44.152+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:01:44.152+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:01:44.152+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:01:44.160+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:01:44.179+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:01:44.178+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:01:44.198+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:01:44.198+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:01:44.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T19:01:47.213+0000] {processor.py:157} INFO - Started process (PID=5192) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:01:47.214+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:01:47.214+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:01:47.214+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:01:47.221+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:01:47.241+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:01:47.240+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:01:47.261+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:01:47.260+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:01:47.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T19:02:08.444+0000] {processor.py:157} INFO - Started process (PID=5202) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:02:08.450+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:02:08.451+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:02:08.450+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:02:08.458+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v6']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:02:08.547+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:02:08.546+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:02:08.566+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:02:08.566+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v6 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:02:08.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.138 seconds
[2023-07-07T19:02:27.608+0000] {processor.py:157} INFO - Started process (PID=5204) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:02:27.608+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:02:27.609+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:02:27.608+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:02:27.617+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:02:27.701+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:02:27.701+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:dag_scrap_biobio_v7
[2023-07-07T19:02:27.708+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:02:27.708+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:dag_scrap_biobio_v7
[2023-07-07T19:02:27.718+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:02:27.718+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:dag_scrap_biobio_v7
[2023-07-07T19:02:27.729+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:02:27.729+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:02:27.738+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:02:27.738+0000] {dag.py:2747} INFO - Creating ORM DAG for dag_scrap_biobio_v7
[2023-07-07T19:02:27.747+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:02:27.747+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-06T00:00:00+00:00, run_after=2023-07-07T00:00:00+00:00
[2023-07-07T19:02:27.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.152 seconds
[2023-07-07T19:02:57.816+0000] {processor.py:157} INFO - Started process (PID=5214) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:02:57.850+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:02:57.851+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:02:57.851+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:02:57.861+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:02:57.884+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:02:57.883+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:02:57.902+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:02:57.902+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:02:58.003+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.189 seconds
[2023-07-07T19:03:28.264+0000] {processor.py:157} INFO - Started process (PID=5224) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:03:28.265+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:03:28.265+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:03:28.265+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:03:28.272+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:03:28.290+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:03:28.290+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:03:28.311+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:03:28.311+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:03:28.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T19:03:37.399+0000] {processor.py:157} INFO - Started process (PID=5232) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:03:37.399+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:03:37.400+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:03:37.400+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:03:37.408+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:03:37.430+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:03:37.430+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:03:37.449+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:03:37.449+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:03:37.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T19:04:07.612+0000] {processor.py:157} INFO - Started process (PID=5242) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:04:07.618+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:04:07.619+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:04:07.619+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:04:07.627+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:04:07.649+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:04:07.649+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:04:07.669+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:04:07.669+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:04:07.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T19:04:37.865+0000] {processor.py:157} INFO - Started process (PID=5252) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:04:37.870+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:04:37.871+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:04:37.870+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:04:37.879+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:04:37.898+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:04:37.898+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:04:37.918+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:04:37.918+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:04:37.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T19:05:08.117+0000] {processor.py:157} INFO - Started process (PID=5262) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:05:08.123+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:05:08.123+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:05:08.123+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:05:08.130+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:05:08.149+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:05:08.148+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:05:08.169+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:05:08.169+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:05:08.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T19:05:38.368+0000] {processor.py:157} INFO - Started process (PID=5272) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:05:38.374+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:05:38.374+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:05:38.374+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:05:38.381+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:05:38.400+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:05:38.400+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:05:38.421+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:05:38.421+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:05:38.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T19:05:56.518+0000] {processor.py:157} INFO - Started process (PID=5274) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:05:56.519+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:05:56.519+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:05:56.519+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:05:56.527+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:05:56.546+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:05:56.546+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:05:56.564+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:05:56.564+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:05:56.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.061 seconds
[2023-07-07T19:06:27.997+0000] {processor.py:157} INFO - Started process (PID=31) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:06:27.998+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:06:27.998+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:06:27.998+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:06:28.010+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:06:28.230+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:06:28.230+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:06:28.250+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:06:28.250+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:06:28.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.270 seconds
[2023-07-07T19:06:58.457+0000] {processor.py:157} INFO - Started process (PID=41) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:06:58.463+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:06:58.463+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:06:58.463+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:06:58.469+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:06:58.574+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:06:58.574+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:06:58.596+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:06:58.596+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:06:58.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.154 seconds
[2023-07-07T19:07:28.805+0000] {processor.py:157} INFO - Started process (PID=52) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:07:28.813+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:07:28.814+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:07:28.814+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:07:28.909+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:07:28.926+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:07:28.926+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:07:28.945+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:07:28.944+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:07:28.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.154 seconds
[2023-07-07T19:07:59.208+0000] {processor.py:157} INFO - Started process (PID=62) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:07:59.214+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:07:59.214+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:07:59.214+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:07:59.221+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:07:59.240+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:07:59.240+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:07:59.261+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:07:59.261+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:07:59.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T19:08:29.458+0000] {processor.py:157} INFO - Started process (PID=72) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:08:29.465+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:08:29.465+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:08:29.465+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:08:29.472+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:08:29.492+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:08:29.492+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:08:29.511+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:08:29.511+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:08:29.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T19:08:59.741+0000] {processor.py:157} INFO - Started process (PID=82) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:08:59.746+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:08:59.747+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:08:59.747+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:08:59.753+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:08:59.773+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:08:59.773+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:08:59.793+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:08:59.793+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:08:59.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T19:09:30.020+0000] {processor.py:157} INFO - Started process (PID=92) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:09:30.026+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:09:30.026+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:09:30.026+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:09:30.034+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:09:30.053+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:09:30.053+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:09:30.072+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:09:30.072+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:09:30.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T19:10:00.311+0000] {processor.py:157} INFO - Started process (PID=102) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:10:00.316+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:10:00.316+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:10:00.316+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:10:00.323+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:10:00.348+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:10:00.348+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:10:00.374+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:10:00.374+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:10:00.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.078 seconds
[2023-07-07T19:10:30.592+0000] {processor.py:157} INFO - Started process (PID=112) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:10:30.593+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:10:30.593+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:10:30.593+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:10:30.600+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:10:30.619+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:10:30.619+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:10:30.638+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:10:30.638+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:10:30.649+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.059 seconds
[2023-07-07T19:11:00.862+0000] {processor.py:157} INFO - Started process (PID=122) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:11:00.868+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:11:00.868+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:11:00.868+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:11:00.875+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:11:00.893+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:11:00.893+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:11:00.911+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:11:00.911+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:11:00.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T19:11:31.182+0000] {processor.py:157} INFO - Started process (PID=132) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:11:31.188+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:11:31.188+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:11:31.188+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:11:31.195+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:11:31.219+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:11:31.219+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:11:31.247+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:11:31.247+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:11:31.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.079 seconds
[2023-07-07T19:12:01.506+0000] {processor.py:157} INFO - Started process (PID=142) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:12:01.511+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:12:01.512+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:12:01.511+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:12:01.519+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:12:01.539+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:12:01.539+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:12:01.558+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:12:01.558+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:12:01.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T19:12:31.797+0000] {processor.py:157} INFO - Started process (PID=152) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:12:31.803+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:12:31.803+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:12:31.803+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:12:31.810+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:12:31.833+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:12:31.833+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:12:31.857+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:12:31.857+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:12:31.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.075 seconds
[2023-07-07T19:13:02.083+0000] {processor.py:157} INFO - Started process (PID=162) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:13:02.096+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:13:02.096+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:13:02.096+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:13:02.103+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:13:02.121+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:13:02.121+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:13:02.140+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:13:02.140+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:13:02.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T19:13:32.372+0000] {processor.py:157} INFO - Started process (PID=172) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:13:32.379+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:13:32.380+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:13:32.380+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:13:32.389+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:13:32.411+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:13:32.411+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:13:32.430+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:13:32.430+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:13:32.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T19:14:02.666+0000] {processor.py:157} INFO - Started process (PID=182) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:14:02.672+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:14:02.672+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:14:02.672+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:14:02.679+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:14:02.699+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:14:02.699+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:14:02.719+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:14:02.719+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:14:02.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T19:14:32.978+0000] {processor.py:157} INFO - Started process (PID=192) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:14:32.989+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:14:32.989+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:14:32.989+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:14:32.996+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:14:33.015+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:14:33.015+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:14:33.034+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:14:33.034+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:14:33.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T19:15:03.248+0000] {processor.py:157} INFO - Started process (PID=202) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:15:03.249+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:15:03.250+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:15:03.249+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:15:03.256+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:15:03.276+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:15:03.275+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:15:03.294+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:15:03.294+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:15:03.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.058 seconds
[2023-07-07T19:15:33.508+0000] {processor.py:157} INFO - Started process (PID=212) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:15:33.515+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:15:33.515+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:15:33.515+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:15:33.522+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:15:33.540+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:15:33.540+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:15:33.559+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:15:33.559+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:15:33.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T19:16:03.784+0000] {processor.py:157} INFO - Started process (PID=222) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:16:03.790+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:16:03.790+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:16:03.790+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:16:03.797+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:16:03.815+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:16:03.815+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:16:03.834+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:16:03.834+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:16:03.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T19:16:34.098+0000] {processor.py:157} INFO - Started process (PID=232) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:16:34.106+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:16:34.106+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:16:34.106+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:16:34.113+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:16:34.131+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:16:34.131+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:16:34.150+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:16:34.150+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:16:34.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T19:17:04.392+0000] {processor.py:157} INFO - Started process (PID=242) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:17:04.398+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:17:04.398+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:17:04.398+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:17:04.405+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:17:04.423+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:17:04.423+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:17:04.442+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:17:04.442+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:17:04.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T19:17:34.658+0000] {processor.py:157} INFO - Started process (PID=252) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:17:34.663+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:17:34.664+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:17:34.664+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:17:34.671+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:17:34.689+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:17:34.688+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:17:34.708+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:17:34.708+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:17:34.721+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T19:18:04.958+0000] {processor.py:157} INFO - Started process (PID=262) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:18:04.964+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:18:04.964+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:18:04.964+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:18:04.971+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:18:04.988+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:18:04.988+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:18:05.007+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:18:05.007+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:18:05.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T19:18:35.259+0000] {processor.py:157} INFO - Started process (PID=272) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:18:35.265+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:18:35.265+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:18:35.265+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:18:35.272+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:18:35.295+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:18:35.295+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:18:35.318+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:18:35.318+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:18:35.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.075 seconds
[2023-07-07T19:19:05.553+0000] {processor.py:157} INFO - Started process (PID=282) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:19:05.558+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:19:05.558+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:19:05.558+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:19:05.565+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:19:05.584+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:19:05.584+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:19:05.603+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:19:05.603+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:19:05.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T19:19:35.880+0000] {processor.py:157} INFO - Started process (PID=292) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:19:35.893+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:19:35.893+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:19:35.893+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:19:35.902+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:19:35.927+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:19:35.927+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:19:35.946+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:19:35.946+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:19:35.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.079 seconds
[2023-07-07T19:20:06.193+0000] {processor.py:157} INFO - Started process (PID=302) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:20:06.198+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:20:06.198+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:20:06.198+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:20:06.205+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:20:06.223+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:20:06.223+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:20:06.244+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:20:06.244+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:20:06.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T19:20:36.478+0000] {processor.py:157} INFO - Started process (PID=312) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:20:36.483+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:20:36.484+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:20:36.484+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:20:36.491+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:20:36.514+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:20:36.514+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:20:36.540+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:20:36.540+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:20:36.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.076 seconds
[2023-07-07T19:21:06.790+0000] {processor.py:157} INFO - Started process (PID=322) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:21:06.796+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:21:06.796+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:21:06.796+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:21:06.803+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:21:06.823+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:21:06.823+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:21:06.842+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:21:06.842+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:21:06.853+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T19:21:37.073+0000] {processor.py:157} INFO - Started process (PID=332) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:21:37.079+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:21:37.080+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:21:37.079+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:21:37.086+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:21:37.112+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:21:37.111+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:21:37.135+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:21:37.135+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:21:37.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.075 seconds
[2023-07-07T19:22:07.370+0000] {processor.py:157} INFO - Started process (PID=342) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:22:07.375+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:22:07.375+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:22:07.375+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:22:07.382+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:22:07.402+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:22:07.402+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:22:07.422+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:22:07.422+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:22:07.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T19:22:37.647+0000] {processor.py:157} INFO - Started process (PID=352) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:22:37.652+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:22:37.653+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:22:37.653+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:22:37.659+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:22:37.677+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:22:37.677+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:22:37.696+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:22:37.696+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:22:37.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T19:23:07.946+0000] {processor.py:157} INFO - Started process (PID=362) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:23:07.953+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:23:07.954+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:23:07.954+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:23:07.964+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:23:07.983+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:23:07.983+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:23:08.001+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:23:08.001+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:23:08.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T19:23:38.241+0000] {processor.py:157} INFO - Started process (PID=372) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:23:38.246+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:23:38.247+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:23:38.247+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:23:38.256+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:23:38.274+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:23:38.274+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:23:38.292+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:23:38.292+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:23:38.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T19:24:08.522+0000] {processor.py:157} INFO - Started process (PID=382) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:24:08.524+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:24:08.524+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:24:08.524+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:24:08.532+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:24:08.552+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:24:08.552+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:24:08.572+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:24:08.572+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:24:08.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T19:24:38.819+0000] {processor.py:157} INFO - Started process (PID=392) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:24:38.825+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:24:38.826+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:24:38.826+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:24:38.833+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:24:38.850+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:24:38.850+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:24:38.869+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:24:38.869+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:24:38.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T19:25:09.114+0000] {processor.py:157} INFO - Started process (PID=402) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:25:09.119+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:25:09.120+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:25:09.120+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:25:09.127+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:25:09.146+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:25:09.146+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:25:09.166+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:25:09.166+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:25:09.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T19:25:39.416+0000] {processor.py:157} INFO - Started process (PID=412) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:25:39.423+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:25:39.424+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:25:39.424+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:25:39.433+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:25:39.458+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:25:39.458+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:25:39.482+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:25:39.482+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:25:39.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.081 seconds
[2023-07-07T19:26:09.724+0000] {processor.py:157} INFO - Started process (PID=422) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:26:09.736+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:26:09.736+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:26:09.736+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:26:09.743+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:26:09.762+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:26:09.762+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:26:09.781+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:26:09.781+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:26:09.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T19:26:40.038+0000] {processor.py:157} INFO - Started process (PID=432) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:26:40.045+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:26:40.046+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:26:40.046+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:26:40.052+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:26:40.075+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:26:40.075+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:26:40.096+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:26:40.095+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:26:40.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T19:27:10.331+0000] {processor.py:157} INFO - Started process (PID=442) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:27:10.336+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:27:10.337+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:27:10.337+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:27:10.343+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:27:10.361+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:27:10.361+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:27:10.380+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:27:10.380+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:27:10.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.061 seconds
[2023-07-07T19:27:40.626+0000] {processor.py:157} INFO - Started process (PID=452) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:27:40.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:27:40.633+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:27:40.633+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:27:40.641+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:27:40.658+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:27:40.658+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:27:40.677+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:27:40.677+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:27:40.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T19:28:10.906+0000] {processor.py:157} INFO - Started process (PID=462) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:28:10.913+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:28:10.913+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:28:10.913+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:28:10.920+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:28:10.938+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:28:10.937+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:28:10.957+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:28:10.957+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:28:10.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T19:28:41.218+0000] {processor.py:157} INFO - Started process (PID=472) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:28:41.229+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:28:41.230+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:28:41.230+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:28:41.236+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:28:41.258+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:28:41.258+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:28:41.276+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:28:41.276+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:28:41.287+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T19:29:11.498+0000] {processor.py:157} INFO - Started process (PID=482) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:29:11.508+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:29:11.508+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:29:11.508+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:29:11.518+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:29:11.544+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:29:11.544+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:29:11.564+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:29:11.564+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:29:11.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.080 seconds
[2023-07-07T19:29:41.771+0000] {processor.py:157} INFO - Started process (PID=492) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:29:41.784+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:29:41.784+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:29:41.784+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:29:41.791+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:29:41.810+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:29:41.810+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:29:41.829+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:29:41.829+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:29:41.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T19:30:12.085+0000] {processor.py:157} INFO - Started process (PID=502) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:30:12.092+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:30:12.092+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:30:12.092+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:30:12.099+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:30:12.117+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:30:12.117+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:30:12.137+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:30:12.136+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:30:12.147+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T19:30:42.388+0000] {processor.py:157} INFO - Started process (PID=512) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:30:42.396+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:30:42.396+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:30:42.396+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:30:42.403+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:30:42.420+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:30:42.420+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:30:42.440+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:30:42.440+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:30:42.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T19:31:12.672+0000] {processor.py:157} INFO - Started process (PID=522) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:31:12.683+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:31:12.683+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:31:12.683+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:31:12.690+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:31:12.710+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:31:12.710+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:31:12.729+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:31:12.729+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:31:12.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T19:31:42.977+0000] {processor.py:157} INFO - Started process (PID=532) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:31:42.982+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:31:42.983+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:31:42.983+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:31:42.990+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:31:43.008+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:31:43.008+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:31:43.027+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:31:43.026+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:31:43.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T19:32:13.263+0000] {processor.py:157} INFO - Started process (PID=542) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:32:13.269+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:32:13.269+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:32:13.269+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:32:13.276+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:32:13.293+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:32:13.293+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:32:13.312+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:32:13.312+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:32:13.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T19:32:43.575+0000] {processor.py:157} INFO - Started process (PID=552) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:32:43.580+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:32:43.581+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:32:43.581+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:32:43.588+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:32:43.607+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:32:43.607+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:32:43.627+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:32:43.627+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:32:43.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T19:33:13.903+0000] {processor.py:157} INFO - Started process (PID=562) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:33:13.908+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:33:13.908+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:33:13.908+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:33:13.915+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:33:13.933+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:33:13.933+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:33:13.952+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:33:13.951+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:33:13.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T19:33:44.212+0000] {processor.py:157} INFO - Started process (PID=572) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:33:44.218+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:33:44.218+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:33:44.218+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:33:44.227+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:33:44.248+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:33:44.248+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:33:44.268+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:33:44.268+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:33:44.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T19:34:14.502+0000] {processor.py:157} INFO - Started process (PID=582) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:34:14.507+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:34:14.508+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:34:14.508+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:34:14.514+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:34:14.533+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:34:14.533+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:34:14.553+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:34:14.552+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:34:14.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T19:34:44.785+0000] {processor.py:157} INFO - Started process (PID=592) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:34:44.790+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:34:44.791+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:34:44.790+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:34:44.797+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:34:44.815+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:34:44.815+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:34:44.834+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:34:44.834+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:34:44.845+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T19:35:15.095+0000] {processor.py:157} INFO - Started process (PID=602) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:35:15.103+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:35:15.103+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:35:15.103+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:35:15.110+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:35:15.129+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:35:15.129+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:35:15.148+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:35:15.148+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:35:15.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T19:35:45.405+0000] {processor.py:157} INFO - Started process (PID=612) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:35:45.410+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:35:45.411+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:35:45.410+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:35:45.417+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:35:45.435+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:35:45.435+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:35:45.454+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:35:45.454+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:35:45.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.061 seconds
[2023-07-07T19:36:15.682+0000] {processor.py:157} INFO - Started process (PID=622) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:36:15.688+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:36:15.689+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:36:15.688+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:36:15.695+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:36:15.717+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:36:15.717+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:36:15.736+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:36:15.736+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:36:15.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T19:36:45.988+0000] {processor.py:157} INFO - Started process (PID=632) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:36:45.998+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:36:45.998+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:36:45.998+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:36:46.005+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:36:46.024+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:36:46.023+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:36:46.042+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:36:46.042+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:36:46.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T19:37:16.282+0000] {processor.py:157} INFO - Started process (PID=642) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:37:16.288+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:37:16.288+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:37:16.288+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:37:16.299+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:37:16.318+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:37:16.317+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:37:16.336+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:37:16.336+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:37:16.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T19:37:46.601+0000] {processor.py:157} INFO - Started process (PID=652) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:37:46.607+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:37:46.607+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:37:46.607+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:37:46.614+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:37:46.632+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:37:46.632+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:37:46.651+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:37:46.651+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:37:46.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T19:38:16.893+0000] {processor.py:157} INFO - Started process (PID=662) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:38:16.901+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:38:16.902+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:38:16.902+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:38:16.908+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:38:16.927+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:38:16.926+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:38:16.946+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:38:16.946+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:38:16.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T19:38:47.210+0000] {processor.py:157} INFO - Started process (PID=672) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:38:47.216+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:38:47.216+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:38:47.216+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:38:47.223+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:38:47.243+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:38:47.243+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:38:47.263+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:38:47.263+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:38:47.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T19:39:17.501+0000] {processor.py:157} INFO - Started process (PID=682) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:39:17.507+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:39:17.507+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:39:17.507+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:39:17.514+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:39:17.540+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:39:17.540+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:39:17.559+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:39:17.559+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:39:17.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T19:39:47.798+0000] {processor.py:157} INFO - Started process (PID=692) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:39:47.809+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:39:47.809+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:39:47.809+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:39:47.816+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:39:47.836+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:39:47.836+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:39:47.855+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:39:47.855+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:39:47.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T19:40:18.112+0000] {processor.py:157} INFO - Started process (PID=702) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:40:18.117+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:40:18.118+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:40:18.118+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:40:18.125+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:40:18.143+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:40:18.143+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:40:18.163+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:40:18.163+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:40:18.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T19:40:48.395+0000] {processor.py:157} INFO - Started process (PID=712) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:40:48.402+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:40:48.402+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:40:48.402+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:40:48.409+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:40:48.427+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:40:48.427+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:40:48.446+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:40:48.446+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:40:48.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T19:41:18.689+0000] {processor.py:157} INFO - Started process (PID=722) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:41:18.696+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:41:18.696+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:41:18.696+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:41:18.703+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:41:18.722+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:41:18.722+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:41:18.741+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:41:18.741+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:41:18.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T19:41:48.984+0000] {processor.py:157} INFO - Started process (PID=732) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:41:48.991+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:41:48.992+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:41:48.992+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:41:48.998+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:41:49.016+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:41:49.016+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:41:49.034+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:41:49.034+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:41:49.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T19:42:19.266+0000] {processor.py:157} INFO - Started process (PID=742) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:42:19.271+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:42:19.272+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:42:19.272+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:42:19.278+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:42:19.298+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:42:19.298+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:42:19.318+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:42:19.318+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:42:19.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T19:42:49.548+0000] {processor.py:157} INFO - Started process (PID=752) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:42:49.554+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:42:49.554+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:42:49.554+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:42:49.561+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:42:49.579+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:42:49.579+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:42:49.599+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:42:49.598+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:42:49.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T19:43:19.843+0000] {processor.py:157} INFO - Started process (PID=762) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:43:19.848+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:43:19.848+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:43:19.848+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:43:19.855+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:43:19.873+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:43:19.873+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:43:19.892+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:43:19.892+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:43:19.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T19:43:50.148+0000] {processor.py:157} INFO - Started process (PID=772) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:43:50.155+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:43:50.155+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:43:50.155+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:43:50.162+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:43:50.181+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:43:50.181+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:43:50.200+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:43:50.200+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:43:50.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T19:44:20.438+0000] {processor.py:157} INFO - Started process (PID=782) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:44:20.443+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:44:20.444+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:44:20.443+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:44:20.450+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:44:20.469+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:44:20.468+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:44:20.488+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:44:20.488+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:44:20.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T19:44:50.709+0000] {processor.py:157} INFO - Started process (PID=792) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:44:50.715+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:44:50.715+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:44:50.715+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:44:50.722+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:44:50.740+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:44:50.740+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:44:50.760+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:44:50.760+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:44:50.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T19:45:21.006+0000] {processor.py:157} INFO - Started process (PID=802) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:45:21.018+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:45:21.019+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:45:21.019+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:45:21.028+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:45:21.055+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:45:21.055+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:45:21.083+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:45:21.083+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:45:21.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.092 seconds
[2023-07-07T19:45:51.329+0000] {processor.py:157} INFO - Started process (PID=812) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:45:51.332+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:45:51.332+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:45:51.332+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:45:51.339+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:45:51.359+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:45:51.359+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:45:51.379+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:45:51.378+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:45:51.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T19:46:21.642+0000] {processor.py:157} INFO - Started process (PID=822) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:46:21.649+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:46:21.649+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:46:21.649+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:46:21.656+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:46:21.676+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:46:21.676+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:46:21.696+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:46:21.696+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:46:21.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T19:46:51.942+0000] {processor.py:157} INFO - Started process (PID=832) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:46:51.945+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:46:51.946+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:46:51.946+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:46:51.953+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:46:51.972+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:46:51.972+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:46:51.992+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:46:51.992+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:46:52.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.104 seconds
[2023-07-07T19:47:22.276+0000] {processor.py:157} INFO - Started process (PID=842) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:47:22.285+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:47:22.285+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:47:22.285+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:47:22.292+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:47:22.311+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:47:22.311+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:47:22.330+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:47:22.330+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:47:22.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T19:47:52.552+0000] {processor.py:157} INFO - Started process (PID=852) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:47:52.558+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:47:52.558+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:47:52.558+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:47:52.565+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:47:52.583+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:47:52.583+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:47:52.602+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:47:52.602+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:47:52.612+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T19:48:22.861+0000] {processor.py:157} INFO - Started process (PID=862) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:48:22.869+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:48:22.870+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:48:22.870+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:48:22.876+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:48:22.901+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:48:22.901+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:48:22.932+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:48:22.932+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:48:22.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.086 seconds
[2023-07-07T19:48:53.172+0000] {processor.py:157} INFO - Started process (PID=872) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:48:53.182+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:48:53.183+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:48:53.183+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:48:53.189+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:48:53.213+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:48:53.213+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:48:53.234+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:48:53.234+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:48:53.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.076 seconds
[2023-07-07T19:49:23.494+0000] {processor.py:157} INFO - Started process (PID=882) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:49:23.504+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:49:23.505+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:49:23.505+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:49:23.512+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:49:23.531+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:49:23.531+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:49:23.550+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:49:23.550+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:49:23.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T19:49:53.794+0000] {processor.py:157} INFO - Started process (PID=892) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:49:53.799+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:49:53.800+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:49:53.800+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:49:53.806+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:49:53.826+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:49:53.825+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:49:53.844+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:49:53.844+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:49:53.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T19:50:24.123+0000] {processor.py:157} INFO - Started process (PID=902) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:50:24.129+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:50:24.130+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:50:24.130+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:50:24.136+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:50:24.156+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:50:24.156+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:50:24.176+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:50:24.176+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:50:24.187+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T19:50:54.422+0000] {processor.py:157} INFO - Started process (PID=912) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:50:54.433+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:50:54.433+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:50:54.433+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:50:54.440+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:50:54.459+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:50:54.459+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:50:54.478+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:50:54.478+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:50:54.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T19:51:24.710+0000] {processor.py:157} INFO - Started process (PID=922) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:51:24.715+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:51:24.716+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:51:24.716+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:51:24.725+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:51:24.743+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:51:24.743+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:51:24.762+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:51:24.762+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:51:24.773+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T19:51:55.032+0000] {processor.py:157} INFO - Started process (PID=932) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:51:55.042+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:51:55.043+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:51:55.043+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:51:55.049+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:51:55.068+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:51:55.068+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:51:55.087+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:51:55.087+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:51:55.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T19:52:25.323+0000] {processor.py:157} INFO - Started process (PID=942) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:52:25.329+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:52:25.329+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:52:25.329+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:52:25.336+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:52:25.354+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:52:25.354+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:52:25.374+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:52:25.374+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:52:25.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T19:52:55.637+0000] {processor.py:157} INFO - Started process (PID=952) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:52:55.642+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:52:55.642+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:52:55.642+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:52:55.649+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:52:55.668+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:52:55.668+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:52:55.688+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:52:55.687+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:52:55.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T19:53:25.956+0000] {processor.py:157} INFO - Started process (PID=962) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:53:25.963+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:53:25.963+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:53:25.963+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:53:25.970+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:53:25.988+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:53:25.988+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:53:26.006+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:53:26.006+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:53:26.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T19:53:56.265+0000] {processor.py:157} INFO - Started process (PID=972) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:53:56.274+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:53:56.275+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:53:56.275+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:53:56.281+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:53:56.299+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:53:56.299+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:53:56.318+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:53:56.318+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:53:56.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T19:54:26.569+0000] {processor.py:157} INFO - Started process (PID=982) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:54:26.574+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:54:26.575+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:54:26.575+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:54:26.582+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:54:26.600+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:54:26.600+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:54:26.620+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:54:26.620+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:54:26.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T19:54:56.873+0000] {processor.py:157} INFO - Started process (PID=992) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:54:56.880+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:54:56.880+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:54:56.880+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:54:56.887+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:54:56.906+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:54:56.906+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:54:56.925+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:54:56.925+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:54:56.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T19:55:27.179+0000] {processor.py:157} INFO - Started process (PID=1002) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:55:27.185+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:55:27.185+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:55:27.185+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:55:27.191+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:55:27.209+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:55:27.209+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:55:27.228+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:55:27.227+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:55:27.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.061 seconds
[2023-07-07T19:55:57.476+0000] {processor.py:157} INFO - Started process (PID=1012) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:55:57.486+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:55:57.487+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:55:57.487+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:55:57.493+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:55:57.511+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:55:57.511+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:55:57.532+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:55:57.532+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:55:57.542+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T19:56:27.761+0000] {processor.py:157} INFO - Started process (PID=1022) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:56:27.766+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:56:27.767+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:56:27.767+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:56:27.773+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:56:27.792+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:56:27.792+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:56:27.812+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:56:27.811+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:56:27.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T19:56:58.064+0000] {processor.py:157} INFO - Started process (PID=1032) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:56:58.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:56:58.070+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:56:58.070+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:56:58.077+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:56:58.096+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:56:58.095+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:56:58.114+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:56:58.114+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:56:58.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T19:57:28.354+0000] {processor.py:157} INFO - Started process (PID=1042) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:57:28.362+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:57:28.362+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:57:28.362+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:57:28.369+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:57:28.388+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:57:28.388+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:57:28.406+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:57:28.406+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:57:28.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T19:57:58.655+0000] {processor.py:157} INFO - Started process (PID=1052) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:57:58.661+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:57:58.662+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:57:58.661+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:57:58.668+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:57:58.688+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:57:58.688+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:57:58.707+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:57:58.707+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:57:58.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T19:58:28.955+0000] {processor.py:157} INFO - Started process (PID=1062) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:58:28.962+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:58:28.962+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:58:28.962+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:58:28.969+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:58:28.987+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:58:28.987+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:58:29.007+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:58:29.007+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:58:29.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T19:58:59.268+0000] {processor.py:157} INFO - Started process (PID=1072) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:58:59.274+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:58:59.275+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:58:59.275+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:58:59.281+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:58:59.300+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:58:59.300+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:58:59.319+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:58:59.319+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:58:59.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T19:59:29.567+0000] {processor.py:157} INFO - Started process (PID=1082) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:59:29.574+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:59:29.574+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:59:29.574+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:59:29.581+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:59:29.601+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:59:29.600+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:59:29.620+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:59:29.620+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:59:29.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T19:59:59.888+0000] {processor.py:157} INFO - Started process (PID=1092) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:59:59.894+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T19:59:59.895+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:59:59.895+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:59:59.901+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T19:59:59.919+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:59:59.919+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T19:59:59.937+0000] {logging_mixin.py:149} INFO - [2023-07-07T19:59:59.937+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T19:59:59.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T20:00:30.177+0000] {processor.py:157} INFO - Started process (PID=1102) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:00:30.184+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:00:30.185+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:00:30.184+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:00:30.191+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:00:30.211+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:00:30.211+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:00:30.231+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:00:30.231+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:00:30.243+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T20:01:00.490+0000] {processor.py:157} INFO - Started process (PID=1112) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:01:00.494+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:01:00.495+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:01:00.495+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:01:00.501+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:01:00.519+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:01:00.519+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:01:00.539+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:01:00.539+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:01:00.550+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T20:01:30.779+0000] {processor.py:157} INFO - Started process (PID=1122) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:01:30.785+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:01:30.786+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:01:30.785+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:01:30.792+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:01:30.811+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:01:30.811+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:01:30.829+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:01:30.829+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:01:30.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T20:02:01.097+0000] {processor.py:157} INFO - Started process (PID=1132) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:02:01.102+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:02:01.103+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:02:01.103+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:02:01.112+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:02:01.130+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:02:01.129+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:02:01.148+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:02:01.148+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:02:01.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T20:02:31.376+0000] {processor.py:157} INFO - Started process (PID=1142) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:02:31.383+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:02:31.383+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:02:31.383+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:02:31.390+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:02:31.408+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:02:31.408+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:02:31.427+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:02:31.427+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:02:31.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T20:03:01.672+0000] {processor.py:157} INFO - Started process (PID=1152) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:03:01.680+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:03:01.681+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:03:01.681+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:03:01.687+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:03:01.706+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:03:01.706+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:03:01.725+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:03:01.725+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:03:01.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T20:03:31.966+0000] {processor.py:157} INFO - Started process (PID=1162) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:03:31.972+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:03:31.972+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:03:31.972+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:03:31.979+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:03:32.003+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:03:32.003+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:03:32.024+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:03:32.024+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:03:32.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T20:04:02.269+0000] {processor.py:157} INFO - Started process (PID=1172) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:04:02.275+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:04:02.275+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:04:02.275+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:04:02.282+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:04:02.301+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:04:02.300+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:04:02.320+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:04:02.320+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:04:02.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T20:04:32.555+0000] {processor.py:157} INFO - Started process (PID=1182) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:04:32.563+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:04:32.563+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:04:32.563+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:04:32.570+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:04:32.588+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:04:32.588+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:04:32.608+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:04:32.607+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:04:32.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T20:05:02.848+0000] {processor.py:157} INFO - Started process (PID=1192) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:05:02.854+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:05:02.855+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:05:02.855+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:05:02.861+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:05:02.880+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:05:02.880+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:05:02.899+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:05:02.899+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:05:02.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T20:05:33.165+0000] {processor.py:157} INFO - Started process (PID=1202) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:05:33.171+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:05:33.171+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:05:33.171+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:05:33.178+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:05:33.198+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:05:33.198+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:05:33.218+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:05:33.218+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:05:33.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T20:06:03.460+0000] {processor.py:157} INFO - Started process (PID=1212) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:06:03.468+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:06:03.468+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:06:03.468+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:06:03.475+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:06:03.492+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:06:03.492+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:06:03.512+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:06:03.511+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:06:03.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T20:06:33.751+0000] {processor.py:157} INFO - Started process (PID=1222) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:06:33.757+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:06:33.757+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:06:33.757+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:06:33.764+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:06:33.783+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:06:33.783+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:06:33.802+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:06:33.802+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:06:33.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T20:07:04.055+0000] {processor.py:157} INFO - Started process (PID=1232) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:07:04.061+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:07:04.061+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:07:04.061+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:07:04.068+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:07:04.087+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:07:04.087+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:07:04.106+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:07:04.106+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:07:04.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T20:07:34.345+0000] {processor.py:157} INFO - Started process (PID=1242) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:07:34.353+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:07:34.353+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:07:34.353+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:07:34.359+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:07:34.379+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:07:34.379+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:07:34.398+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:07:34.398+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:07:34.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T20:08:04.658+0000] {processor.py:157} INFO - Started process (PID=1252) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:08:04.665+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:08:04.665+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:08:04.665+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:08:04.672+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:08:04.690+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:08:04.690+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:08:04.709+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:08:04.709+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:08:04.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T20:08:34.976+0000] {processor.py:157} INFO - Started process (PID=1262) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:08:34.982+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:08:34.982+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:08:34.982+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:08:34.989+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:08:35.008+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:08:35.008+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:08:35.027+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:08:35.027+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:08:35.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T20:09:05.273+0000] {processor.py:157} INFO - Started process (PID=1272) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:09:05.280+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:09:05.280+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:09:05.280+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:09:05.289+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:09:05.306+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:09:05.306+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:09:05.326+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:09:05.326+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:09:05.338+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T20:09:35.583+0000] {processor.py:157} INFO - Started process (PID=1282) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:09:35.588+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:09:35.589+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:09:35.589+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:09:35.595+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:09:35.613+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:09:35.613+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:09:35.632+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:09:35.632+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:09:35.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T20:10:05.872+0000] {processor.py:157} INFO - Started process (PID=1292) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:10:05.881+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:10:05.881+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:10:05.881+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:10:05.888+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:10:05.906+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:10:05.906+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:10:05.924+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:10:05.924+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:10:05.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T20:10:36.162+0000] {processor.py:157} INFO - Started process (PID=1302) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:10:36.168+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:10:36.168+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:10:36.168+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:10:36.175+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:10:36.194+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:10:36.194+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:10:36.214+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:10:36.214+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:10:36.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T20:11:06.453+0000] {processor.py:157} INFO - Started process (PID=1312) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:11:06.460+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:11:06.460+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:11:06.460+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:11:06.467+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:11:06.486+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:11:06.485+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:11:06.504+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:11:06.504+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:11:06.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T20:11:36.736+0000] {processor.py:157} INFO - Started process (PID=1322) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:11:36.742+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:11:36.742+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:11:36.742+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:11:36.749+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:11:36.767+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:11:36.767+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:11:36.786+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:11:36.786+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:11:36.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T20:12:07.021+0000] {processor.py:157} INFO - Started process (PID=1332) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:12:07.029+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:12:07.029+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:12:07.029+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:12:07.036+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:12:07.055+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:12:07.055+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:12:07.074+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:12:07.074+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:12:07.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T20:12:37.292+0000] {processor.py:157} INFO - Started process (PID=1342) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:12:37.303+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:12:37.303+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:12:37.303+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:12:37.310+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:12:37.327+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:12:37.327+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:12:37.346+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:12:37.346+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:12:37.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T20:13:07.602+0000] {processor.py:157} INFO - Started process (PID=1352) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:13:07.613+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:13:07.614+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:13:07.613+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:13:07.620+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:13:07.638+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:13:07.638+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:13:07.657+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:13:07.657+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:13:07.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T20:13:37.908+0000] {processor.py:157} INFO - Started process (PID=1362) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:13:37.914+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:13:37.915+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:13:37.914+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:13:37.921+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:13:37.947+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:13:37.946+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:13:37.968+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:13:37.968+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:13:37.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.082 seconds
[2023-07-07T20:14:08.249+0000] {processor.py:157} INFO - Started process (PID=1378) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:14:08.258+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:14:08.258+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:14:08.258+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:14:08.266+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:14:08.284+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:14:08.284+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:14:08.303+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:14:08.303+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:14:08.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T20:14:38.557+0000] {processor.py:157} INFO - Started process (PID=1389) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:14:38.567+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:14:38.568+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:14:38.567+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:14:38.574+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:14:38.592+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:14:38.592+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:14:38.611+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:14:38.611+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:14:38.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T20:15:08.856+0000] {processor.py:157} INFO - Started process (PID=1399) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:15:08.864+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:15:08.864+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:15:08.864+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:15:08.870+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:15:08.890+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:15:08.890+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:15:08.910+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:15:08.909+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:15:08.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T20:15:39.155+0000] {processor.py:157} INFO - Started process (PID=1409) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:15:39.165+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:15:39.165+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:15:39.165+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:15:39.172+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:15:39.190+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:15:39.189+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:15:39.208+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:15:39.208+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:15:39.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T20:16:09.460+0000] {processor.py:157} INFO - Started process (PID=1419) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:16:09.467+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:16:09.467+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:16:09.467+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:16:09.473+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:16:09.492+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:16:09.492+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:16:09.511+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:16:09.511+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:16:09.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T20:16:39.767+0000] {processor.py:157} INFO - Started process (PID=1429) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:16:39.773+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:16:39.773+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:16:39.773+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:16:39.779+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:16:39.798+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:16:39.798+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:16:39.817+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:16:39.817+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:16:39.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T20:17:10.070+0000] {processor.py:157} INFO - Started process (PID=1439) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:17:10.080+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:17:10.080+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:17:10.080+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:17:10.087+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:17:10.109+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:17:10.109+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:17:10.128+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:17:10.128+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:17:10.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T20:17:40.353+0000] {processor.py:157} INFO - Started process (PID=1449) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:17:40.365+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:17:40.365+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:17:40.365+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:17:40.372+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:17:40.393+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:17:40.393+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:17:40.412+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:17:40.412+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:17:40.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.073 seconds
[2023-07-07T20:18:10.668+0000] {processor.py:157} INFO - Started process (PID=1459) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:18:10.675+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:18:10.676+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:18:10.676+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:18:10.684+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:18:10.703+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:18:10.703+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:18:10.721+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:18:10.721+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:18:10.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T20:18:40.997+0000] {processor.py:157} INFO - Started process (PID=1469) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:18:41.004+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:18:41.004+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:18:41.004+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:18:41.011+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:18:41.033+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:18:41.033+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:18:41.059+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:18:41.059+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:18:41.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.075 seconds
[2023-07-07T20:19:11.299+0000] {processor.py:157} INFO - Started process (PID=1478) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:19:11.305+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:19:11.305+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:19:11.305+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:19:11.315+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:19:11.333+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:19:11.333+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:19:11.352+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:19:11.352+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:19:11.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T20:19:41.589+0000] {processor.py:157} INFO - Started process (PID=1488) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:19:41.599+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:19:41.600+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:19:41.600+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:19:41.607+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:19:41.625+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:19:41.625+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:19:41.644+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:19:41.644+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:19:41.655+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T20:20:11.897+0000] {processor.py:157} INFO - Started process (PID=1498) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:20:11.903+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:20:11.904+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:20:11.904+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:20:11.912+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:20:11.935+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:20:11.935+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:20:11.953+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:20:11.953+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:20:11.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T20:20:42.204+0000] {processor.py:157} INFO - Started process (PID=1508) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:20:42.210+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:20:42.210+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:20:42.210+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:20:42.217+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:20:42.235+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:20:42.235+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:20:42.255+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:20:42.255+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:20:42.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T20:21:12.506+0000] {processor.py:157} INFO - Started process (PID=1518) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:21:12.515+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:21:12.515+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:21:12.515+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:21:12.522+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:21:12.541+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:21:12.541+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:21:12.560+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:21:12.560+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:21:12.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T20:21:42.818+0000] {processor.py:157} INFO - Started process (PID=1528) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:21:42.819+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:21:42.820+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:21:42.820+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:21:42.827+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:21:42.847+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:21:42.847+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:21:42.866+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:21:42.866+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:21:42.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.061 seconds
[2023-07-07T20:22:13.132+0000] {processor.py:157} INFO - Started process (PID=1538) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:22:13.138+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:22:13.138+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:22:13.138+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:22:13.145+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:22:13.162+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:22:13.162+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:22:13.181+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:22:13.181+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:22:13.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T20:22:43.422+0000] {processor.py:157} INFO - Started process (PID=1548) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:22:43.428+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:22:43.428+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:22:43.428+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:22:43.435+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:22:43.452+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:22:43.452+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:22:43.472+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:22:43.471+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:22:43.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T20:23:13.701+0000] {processor.py:157} INFO - Started process (PID=1558) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:23:13.708+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:23:13.709+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:23:13.708+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:23:13.718+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:23:13.742+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:23:13.741+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:23:13.761+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:23:13.761+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:23:13.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.075 seconds
[2023-07-07T20:23:43.998+0000] {processor.py:157} INFO - Started process (PID=1568) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:23:44.004+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:23:44.004+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:23:44.004+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:23:44.011+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:23:44.029+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:23:44.029+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:23:44.047+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:23:44.047+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:23:44.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T20:24:14.296+0000] {processor.py:157} INFO - Started process (PID=1578) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:24:14.305+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:24:14.305+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:24:14.305+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:24:14.314+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:24:14.336+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:24:14.335+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:24:14.354+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:24:14.354+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:24:14.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T20:24:44.590+0000] {processor.py:157} INFO - Started process (PID=1588) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:24:44.595+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:24:44.595+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:24:44.595+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:24:44.602+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:24:44.622+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:24:44.622+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:24:44.642+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:24:44.642+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:24:44.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T20:25:14.908+0000] {processor.py:157} INFO - Started process (PID=1598) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:25:14.913+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:25:14.914+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:25:14.914+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:25:14.923+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:25:14.945+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:25:14.945+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:25:14.964+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:25:14.964+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:25:14.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T20:25:45.211+0000] {processor.py:157} INFO - Started process (PID=1608) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:25:45.216+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:25:45.216+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:25:45.216+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:25:45.223+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:25:45.241+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:25:45.241+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:25:45.259+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:25:45.259+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:25:45.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T20:26:15.454+0000] {processor.py:157} INFO - Started process (PID=1618) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:26:15.461+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:26:15.461+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:26:15.461+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:26:15.467+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:26:15.487+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:26:15.487+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:26:15.508+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:26:15.508+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:26:15.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T20:26:45.761+0000] {processor.py:157} INFO - Started process (PID=1628) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:26:45.767+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:26:45.768+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:26:45.768+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:26:45.774+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:26:45.794+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:26:45.794+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:26:45.813+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:26:45.813+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:26:45.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T20:27:16.061+0000] {processor.py:157} INFO - Started process (PID=1638) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:27:16.068+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:27:16.069+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:27:16.069+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:27:16.078+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:27:16.101+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:27:16.101+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:27:16.126+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:27:16.126+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:27:16.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.079 seconds
[2023-07-07T20:27:46.353+0000] {processor.py:157} INFO - Started process (PID=1648) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:27:46.361+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:27:46.361+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:27:46.361+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:27:46.370+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:27:46.389+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:27:46.389+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:27:46.408+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:27:46.408+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:27:46.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T20:28:16.656+0000] {processor.py:157} INFO - Started process (PID=1658) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:28:16.665+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:28:16.665+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:28:16.665+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:28:16.671+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:28:16.690+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:28:16.689+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:28:16.708+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:28:16.708+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:28:16.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T20:28:46.965+0000] {processor.py:157} INFO - Started process (PID=1668) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:28:46.972+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:28:46.972+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:28:46.972+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:28:46.979+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:28:46.997+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:28:46.997+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:28:47.016+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:28:47.016+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:28:47.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T20:29:17.264+0000] {processor.py:157} INFO - Started process (PID=1677) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:29:17.273+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:29:17.273+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:29:17.273+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:29:17.280+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:29:17.298+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:29:17.298+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:29:17.317+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:29:17.317+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:29:17.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T20:29:47.570+0000] {processor.py:157} INFO - Started process (PID=1687) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:29:47.578+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:29:47.578+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:29:47.578+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:29:47.585+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:29:47.604+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:29:47.603+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:29:47.623+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:29:47.623+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:29:47.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T20:30:17.850+0000] {processor.py:157} INFO - Started process (PID=1697) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:30:17.855+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:30:17.855+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:30:17.855+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:30:17.862+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:30:17.880+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:30:17.880+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:30:17.898+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:30:17.898+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:30:17.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T20:30:48.129+0000] {processor.py:157} INFO - Started process (PID=1707) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:30:48.140+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:30:48.141+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:30:48.141+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:30:48.147+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:30:48.165+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:30:48.165+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:30:48.185+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:30:48.185+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:30:48.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T20:31:18.426+0000] {processor.py:157} INFO - Started process (PID=1717) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:31:18.427+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:31:18.427+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:31:18.427+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:31:18.436+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:31:18.455+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:31:18.455+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:31:18.475+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:31:18.475+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:31:18.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T20:31:48.718+0000] {processor.py:157} INFO - Started process (PID=1727) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:31:48.723+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:31:48.724+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:31:48.724+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:31:48.730+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:31:48.748+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:31:48.748+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:31:48.766+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:31:48.766+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:31:48.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T20:32:19.010+0000] {processor.py:157} INFO - Started process (PID=1737) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:32:19.016+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:32:19.016+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:32:19.016+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:32:19.022+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:32:19.042+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:32:19.042+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:32:19.061+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:32:19.061+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:32:19.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T20:32:49.335+0000] {processor.py:157} INFO - Started process (PID=1747) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:32:49.339+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:32:49.340+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:32:49.340+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:32:49.346+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:32:49.363+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:32:49.363+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:32:49.382+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:32:49.382+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:32:49.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.061 seconds
[2023-07-07T20:33:19.612+0000] {processor.py:157} INFO - Started process (PID=1757) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:33:19.618+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:33:19.618+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:33:19.618+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:33:19.624+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:33:19.643+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:33:19.643+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:33:19.662+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:33:19.662+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:33:19.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T20:33:49.892+0000] {processor.py:157} INFO - Started process (PID=1767) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:33:49.899+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:33:49.900+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:33:49.900+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:33:49.909+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:33:49.933+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:33:49.932+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:33:49.951+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:33:49.951+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:33:49.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.073 seconds
[2023-07-07T20:34:20.187+0000] {processor.py:157} INFO - Started process (PID=1777) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:34:20.195+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:34:20.195+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:34:20.195+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:34:20.202+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:34:20.219+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:34:20.219+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:34:20.238+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:34:20.238+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:34:20.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T20:34:50.494+0000] {processor.py:157} INFO - Started process (PID=1787) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:34:50.500+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:34:50.500+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:34:50.500+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:34:50.507+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:34:50.528+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:34:50.527+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:34:50.548+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:34:50.547+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:34:50.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T20:35:20.792+0000] {processor.py:157} INFO - Started process (PID=1797) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:35:20.801+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:35:20.801+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:35:20.801+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:35:20.808+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:35:20.826+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:35:20.826+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:35:20.845+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:35:20.845+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:35:20.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T20:35:51.069+0000] {processor.py:157} INFO - Started process (PID=1807) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:35:51.077+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:35:51.077+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:35:51.077+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:35:51.084+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:35:51.102+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:35:51.102+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:35:51.122+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:35:51.122+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:35:51.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T20:36:21.376+0000] {processor.py:157} INFO - Started process (PID=1817) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:36:21.381+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:36:21.382+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:36:21.381+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:36:21.388+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:36:21.408+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:36:21.408+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:36:21.427+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:36:21.427+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:36:21.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T20:36:51.699+0000] {processor.py:157} INFO - Started process (PID=1827) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:36:51.704+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:36:51.704+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:36:51.704+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:36:51.711+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:36:51.729+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:36:51.729+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:36:51.749+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:36:51.749+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:36:51.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T20:37:22.013+0000] {processor.py:157} INFO - Started process (PID=1837) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:37:22.018+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:37:22.019+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:37:22.019+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:37:22.025+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:37:22.043+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:37:22.043+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:37:22.062+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:37:22.062+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:37:22.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T20:37:52.302+0000] {processor.py:157} INFO - Started process (PID=1847) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:37:52.307+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:37:52.307+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:37:52.307+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:37:52.314+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:37:52.333+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:37:52.333+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:37:52.352+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:37:52.352+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:37:52.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T20:38:22.600+0000] {processor.py:157} INFO - Started process (PID=1857) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:38:22.610+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:38:22.611+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:38:22.611+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:38:22.617+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:38:22.635+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:38:22.635+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:38:22.654+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:38:22.654+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:38:22.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T20:38:52.898+0000] {processor.py:157} INFO - Started process (PID=1867) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:38:52.912+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:38:52.913+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:38:52.913+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:38:52.919+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:38:52.948+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:38:52.948+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:38:52.968+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:38:52.968+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:38:52.981+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.085 seconds
[2023-07-07T20:39:23.232+0000] {processor.py:157} INFO - Started process (PID=1877) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:39:23.237+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:39:23.238+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:39:23.238+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:39:23.254+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:39:23.272+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:39:23.272+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:39:23.291+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:39:23.291+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:39:23.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T20:39:53.513+0000] {processor.py:157} INFO - Started process (PID=1887) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:39:53.523+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:39:53.524+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:39:53.524+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:39:53.533+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:39:53.555+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:39:53.555+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:39:53.574+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:39:53.574+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:39:53.585+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.074 seconds
[2023-07-07T20:40:23.806+0000] {processor.py:157} INFO - Started process (PID=1897) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:40:23.812+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:40:23.812+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:40:23.812+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:40:23.819+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:40:23.836+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:40:23.836+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:40:23.855+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:40:23.855+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:40:23.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.061 seconds
[2023-07-07T20:40:54.106+0000] {processor.py:157} INFO - Started process (PID=1907) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:40:54.112+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:40:54.112+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:40:54.112+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:40:54.119+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:40:54.138+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:40:54.138+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:40:54.162+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:40:54.162+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:40:54.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T20:41:24.405+0000] {processor.py:157} INFO - Started process (PID=1917) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:41:24.411+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:41:24.412+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:41:24.412+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:41:24.418+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:41:24.436+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:41:24.436+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:41:24.454+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:41:24.454+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:41:24.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T20:41:54.687+0000] {processor.py:157} INFO - Started process (PID=1927) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:41:54.693+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:41:54.694+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:41:54.694+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:41:54.701+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:41:54.719+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:41:54.719+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:41:54.737+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:41:54.737+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:41:54.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T20:42:24.978+0000] {processor.py:157} INFO - Started process (PID=1937) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:42:24.985+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:42:24.985+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:42:24.985+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:42:24.992+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:42:25.011+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:42:25.011+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:42:25.030+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:42:25.030+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:42:25.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T20:42:55.301+0000] {processor.py:157} INFO - Started process (PID=1947) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:42:55.308+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:42:55.308+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:42:55.308+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:42:55.315+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:42:55.333+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:42:55.332+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:42:55.353+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:42:55.353+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:42:55.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T20:43:25.595+0000] {processor.py:157} INFO - Started process (PID=1957) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:43:25.602+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:43:25.602+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:43:25.602+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:43:25.609+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:43:25.629+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:43:25.629+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:43:25.648+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:43:25.648+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:43:25.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T20:43:55.885+0000] {processor.py:157} INFO - Started process (PID=1967) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:43:55.890+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:43:55.891+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:43:55.891+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:43:55.898+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:43:55.916+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:43:55.916+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:43:55.935+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:43:55.935+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:43:55.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T20:44:26.179+0000] {processor.py:157} INFO - Started process (PID=1977) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:44:26.190+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:44:26.190+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:44:26.190+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:44:26.199+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:44:26.218+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:44:26.218+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:44:26.238+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:44:26.237+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:44:26.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T20:44:56.468+0000] {processor.py:157} INFO - Started process (PID=1987) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:44:56.480+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:44:56.480+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:44:56.480+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:44:56.487+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:44:56.507+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:44:56.507+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:44:56.528+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:44:56.528+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:44:56.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.074 seconds
[2023-07-07T20:45:26.787+0000] {processor.py:157} INFO - Started process (PID=1997) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:45:26.788+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:45:26.788+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:45:26.788+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:45:26.795+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:45:26.815+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:45:26.815+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:45:26.835+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:45:26.835+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:45:26.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T20:45:57.082+0000] {processor.py:157} INFO - Started process (PID=2007) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:45:57.087+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:45:57.088+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:45:57.088+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:45:57.096+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:45:57.114+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:45:57.114+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:45:57.133+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:45:57.133+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:45:57.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T20:46:27.383+0000] {processor.py:157} INFO - Started process (PID=2017) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:46:27.388+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:46:27.388+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:46:27.388+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:46:27.395+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:46:27.414+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:46:27.414+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:46:27.436+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:46:27.436+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:46:27.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T20:46:57.709+0000] {processor.py:157} INFO - Started process (PID=2027) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:46:57.715+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:46:57.715+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:46:57.715+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:46:57.722+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:46:57.741+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:46:57.741+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:46:57.760+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:46:57.760+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:46:57.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T20:47:28.007+0000] {processor.py:157} INFO - Started process (PID=2037) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:47:28.012+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:47:28.013+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:47:28.013+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:47:28.019+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:47:28.037+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:47:28.037+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:47:28.057+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:47:28.056+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:47:28.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T20:47:58.291+0000] {processor.py:157} INFO - Started process (PID=2047) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:47:58.297+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:47:58.297+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:47:58.297+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:47:58.307+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:47:58.325+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:47:58.325+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:47:58.344+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:47:58.344+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:47:58.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T20:48:28.579+0000] {processor.py:157} INFO - Started process (PID=2057) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:48:28.589+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:48:28.590+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:48:28.590+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:48:28.596+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:48:28.614+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:48:28.614+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:48:28.634+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:48:28.633+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:48:28.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T20:48:58.871+0000] {processor.py:157} INFO - Started process (PID=2067) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:48:58.877+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:48:58.877+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:48:58.877+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:48:58.883+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:48:58.902+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:48:58.902+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:48:58.922+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:48:58.921+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:48:58.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T20:49:29.169+0000] {processor.py:157} INFO - Started process (PID=2077) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:49:29.175+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:49:29.175+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:49:29.175+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:49:29.182+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:49:29.201+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:49:29.200+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:49:29.219+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:49:29.219+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:49:29.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T20:49:59.450+0000] {processor.py:157} INFO - Started process (PID=2087) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:49:59.458+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:49:59.459+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:49:59.459+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:49:59.465+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:49:59.484+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:49:59.484+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:49:59.502+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:49:59.502+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:49:59.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T20:50:29.748+0000] {processor.py:157} INFO - Started process (PID=2097) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:50:29.761+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:50:29.761+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:50:29.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:50:29.770+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:50:29.795+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:50:29.795+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:50:29.813+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:50:29.813+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:50:29.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.078 seconds
[2023-07-07T20:51:00.071+0000] {processor.py:157} INFO - Started process (PID=2107) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:51:00.076+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:51:00.077+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:51:00.077+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:51:00.083+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:51:00.104+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:51:00.104+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:51:00.126+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:51:00.125+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:51:00.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T20:51:30.370+0000] {processor.py:157} INFO - Started process (PID=2117) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:51:30.380+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:51:30.380+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:51:30.380+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:51:30.387+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:51:30.406+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:51:30.406+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:51:30.425+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:51:30.425+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:51:30.436+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T20:52:00.660+0000] {processor.py:157} INFO - Started process (PID=2127) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:52:00.666+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:52:00.666+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:52:00.666+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:52:00.673+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:52:00.691+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:52:00.691+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:52:00.710+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:52:00.710+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:52:00.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T20:52:30.962+0000] {processor.py:157} INFO - Started process (PID=2137) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:52:30.967+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:52:30.967+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:52:30.967+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:52:30.974+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:52:30.992+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:52:30.992+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:52:31.011+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:52:31.011+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:52:31.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T20:53:01.251+0000] {processor.py:157} INFO - Started process (PID=2147) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:53:01.258+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:53:01.259+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:53:01.259+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:53:01.265+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:53:01.284+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:53:01.284+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:53:01.303+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:53:01.303+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:53:01.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T20:53:31.556+0000] {processor.py:157} INFO - Started process (PID=2157) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:53:31.561+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:53:31.561+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:53:31.561+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:53:31.568+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:53:31.587+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:53:31.587+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:53:31.607+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:53:31.607+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:53:31.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T20:54:01.854+0000] {processor.py:157} INFO - Started process (PID=2166) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:54:01.864+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:54:01.864+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:54:01.864+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:54:01.870+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:54:01.890+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:54:01.890+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:54:01.908+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:54:01.908+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:54:01.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T20:54:32.180+0000] {processor.py:157} INFO - Started process (PID=2176) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:54:32.185+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:54:32.186+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:54:32.186+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:54:32.195+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:54:32.213+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:54:32.213+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:54:32.233+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:54:32.232+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:54:32.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T20:55:02.480+0000] {processor.py:157} INFO - Started process (PID=2186) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:55:02.492+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:55:02.492+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:55:02.492+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:55:02.499+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:55:02.517+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:55:02.517+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:55:02.537+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:55:02.537+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:55:02.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T20:55:32.805+0000] {processor.py:157} INFO - Started process (PID=2196) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:55:32.810+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:55:32.811+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:55:32.811+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:55:32.821+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:55:32.845+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:55:32.845+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:55:32.864+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:55:32.864+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:55:32.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.073 seconds
[2023-07-07T20:56:03.100+0000] {processor.py:157} INFO - Started process (PID=2206) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:56:03.107+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:56:03.107+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:56:03.107+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:56:03.114+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:56:03.132+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:56:03.132+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:56:03.151+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:56:03.151+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:56:03.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T20:56:33.368+0000] {processor.py:157} INFO - Started process (PID=2215) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:56:33.373+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:56:33.374+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:56:33.374+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:56:33.381+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:56:33.398+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:56:33.398+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:56:33.418+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:56:33.418+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:56:33.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T20:57:03.647+0000] {processor.py:157} INFO - Started process (PID=2225) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:57:03.656+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:57:03.656+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:57:03.656+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:57:03.663+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:57:03.680+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:57:03.680+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:57:03.700+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:57:03.700+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:57:03.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T20:57:33.937+0000] {processor.py:157} INFO - Started process (PID=2235) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:57:33.943+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:57:33.943+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:57:33.943+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:57:33.950+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:57:33.968+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:57:33.967+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:57:33.986+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:57:33.986+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:57:33.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T20:58:04.214+0000] {processor.py:157} INFO - Started process (PID=2245) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:58:04.219+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:58:04.220+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:58:04.220+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:58:04.226+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:58:04.245+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:58:04.245+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:58:04.264+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:58:04.264+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:58:04.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T20:58:34.505+0000] {processor.py:157} INFO - Started process (PID=2255) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:58:34.510+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:58:34.510+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:58:34.510+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:58:34.517+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:58:34.536+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:58:34.536+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:58:34.555+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:58:34.555+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:58:34.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T20:59:04.799+0000] {processor.py:157} INFO - Started process (PID=2265) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:59:04.810+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:59:04.811+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:59:04.811+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:59:04.819+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:59:04.838+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:59:04.838+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:59:04.858+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:59:04.858+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:59:04.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.073 seconds
[2023-07-07T20:59:35.094+0000] {processor.py:157} INFO - Started process (PID=2275) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:59:35.100+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T20:59:35.100+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:59:35.100+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:59:35.106+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T20:59:35.124+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:59:35.124+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T20:59:35.143+0000] {logging_mixin.py:149} INFO - [2023-07-07T20:59:35.143+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T20:59:35.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T21:00:05.394+0000] {processor.py:157} INFO - Started process (PID=2285) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:00:05.401+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:00:05.401+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:00:05.401+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:00:05.408+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:00:05.425+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:00:05.425+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:00:05.444+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:00:05.443+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:00:05.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T21:00:35.648+0000] {processor.py:157} INFO - Started process (PID=2295) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:00:35.654+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:00:35.654+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:00:35.654+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:00:35.661+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:00:35.682+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:00:35.682+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:00:35.701+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:00:35.701+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:00:35.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T21:01:05.907+0000] {processor.py:157} INFO - Started process (PID=2305) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:01:05.913+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:01:05.913+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:01:05.913+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:01:05.920+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:01:05.939+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:01:05.939+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:01:05.958+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:01:05.958+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:01:05.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T21:01:36.166+0000] {processor.py:157} INFO - Started process (PID=2315) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:01:36.172+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:01:36.172+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:01:36.172+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:01:36.181+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:01:36.199+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:01:36.199+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:01:36.218+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:01:36.218+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:01:36.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:02:06.441+0000] {processor.py:157} INFO - Started process (PID=2325) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:02:06.446+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:02:06.447+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:02:06.447+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:02:06.456+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:02:06.475+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:02:06.475+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:02:06.494+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:02:06.494+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:02:06.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T21:02:36.742+0000] {processor.py:157} INFO - Started process (PID=2335) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:02:36.753+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:02:36.754+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:02:36.754+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:02:36.764+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:02:36.789+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:02:36.789+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:02:36.808+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:02:36.808+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:02:36.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.079 seconds
[2023-07-07T21:03:07.073+0000] {processor.py:157} INFO - Started process (PID=2345) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:03:07.079+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:03:07.080+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:03:07.080+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:03:07.089+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:03:07.113+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:03:07.113+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:03:07.133+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:03:07.133+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:03:07.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.074 seconds
[2023-07-07T21:03:37.375+0000] {processor.py:157} INFO - Started process (PID=2355) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:03:37.382+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:03:37.382+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:03:37.382+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:03:37.389+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:03:37.408+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:03:37.408+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:03:37.427+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:03:37.427+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:03:37.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T21:04:07.666+0000] {processor.py:157} INFO - Started process (PID=2365) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:04:07.677+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:04:07.678+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:04:07.677+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:04:07.684+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:04:07.705+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:04:07.705+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:04:07.723+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:04:07.723+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:04:07.734+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T21:04:37.980+0000] {processor.py:157} INFO - Started process (PID=2375) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:04:37.987+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:04:37.987+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:04:37.987+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:04:37.996+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:04:38.019+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:04:38.018+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:04:38.037+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:04:38.037+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:04:38.047+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T21:05:08.261+0000] {processor.py:157} INFO - Started process (PID=2385) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:05:08.268+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:05:08.268+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:05:08.268+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:05:08.275+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:05:08.294+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:05:08.293+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:05:08.313+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:05:08.313+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:05:08.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T21:05:38.560+0000] {processor.py:157} INFO - Started process (PID=2395) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:05:38.567+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:05:38.567+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:05:38.567+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:05:38.574+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:05:38.591+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:05:38.591+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:05:38.610+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:05:38.610+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:05:38.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T21:06:08.825+0000] {processor.py:157} INFO - Started process (PID=2405) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:06:08.831+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:06:08.831+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:06:08.831+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:06:08.838+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:06:08.856+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:06:08.856+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:06:08.876+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:06:08.876+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:06:08.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T21:06:39.133+0000] {processor.py:157} INFO - Started process (PID=2415) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:06:39.144+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:06:39.144+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:06:39.144+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:06:39.151+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:06:39.169+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:06:39.169+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:06:39.188+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:06:39.188+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:06:39.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T21:07:09.441+0000] {processor.py:157} INFO - Started process (PID=2425) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:07:09.446+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:07:09.447+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:07:09.447+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:07:09.453+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:07:09.472+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:07:09.472+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:07:09.492+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:07:09.491+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:07:09.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:07:39.749+0000] {processor.py:157} INFO - Started process (PID=2435) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:07:39.755+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:07:39.755+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:07:39.755+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:07:39.762+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:07:39.780+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:07:39.780+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:07:39.800+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:07:39.800+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:07:39.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:08:10.058+0000] {processor.py:157} INFO - Started process (PID=2445) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:08:10.068+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:08:10.069+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:08:10.069+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:08:10.078+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:08:10.097+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:08:10.097+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:08:10.116+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:08:10.116+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:08:10.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T21:08:40.358+0000] {processor.py:157} INFO - Started process (PID=2455) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:08:40.365+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:08:40.365+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:08:40.365+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:08:40.372+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:08:40.391+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:08:40.391+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:08:40.409+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:08:40.409+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:08:40.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T21:09:10.677+0000] {processor.py:157} INFO - Started process (PID=2465) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:09:10.683+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:09:10.683+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:09:10.683+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:09:10.693+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:09:10.713+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:09:10.713+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:09:10.733+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:09:10.733+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:09:10.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T21:09:40.976+0000] {processor.py:157} INFO - Started process (PID=2475) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:09:40.983+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:09:40.983+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:09:40.983+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:09:40.989+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:09:41.008+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:09:41.008+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:09:41.028+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:09:41.028+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:09:41.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T21:10:11.277+0000] {processor.py:157} INFO - Started process (PID=2485) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:10:11.283+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:10:11.283+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:10:11.283+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:10:11.290+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:10:11.309+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:10:11.309+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:10:11.328+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:10:11.328+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:10:11.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:10:41.574+0000] {processor.py:157} INFO - Started process (PID=2495) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:10:41.582+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:10:41.582+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:10:41.582+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:10:41.589+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:10:41.609+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:10:41.609+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:10:41.628+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:10:41.628+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:10:41.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T21:11:11.862+0000] {processor.py:157} INFO - Started process (PID=2505) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:11:11.868+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:11:11.868+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:11:11.868+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:11:11.875+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:11:11.896+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:11:11.896+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:11:11.915+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:11:11.915+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:11:11.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T21:11:42.152+0000] {processor.py:157} INFO - Started process (PID=2515) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:11:42.159+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:11:42.159+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:11:42.159+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:11:42.168+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:11:42.186+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:11:42.186+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:11:42.205+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:11:42.204+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:11:42.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:12:12.466+0000] {processor.py:157} INFO - Started process (PID=2525) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:12:12.471+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:12:12.472+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:12:12.472+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:12:12.481+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:12:12.500+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:12:12.499+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:12:12.519+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:12:12.518+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:12:12.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T21:12:42.761+0000] {processor.py:157} INFO - Started process (PID=2535) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:12:42.766+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:12:42.767+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:12:42.767+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:12:42.776+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:12:42.796+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:12:42.796+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:12:42.815+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:12:42.815+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:12:42.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T21:13:13.069+0000] {processor.py:157} INFO - Started process (PID=2545) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:13:13.074+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:13:13.074+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:13:13.074+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:13:13.081+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:13:13.100+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:13:13.100+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:13:13.120+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:13:13.119+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:13:13.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:13:43.357+0000] {processor.py:157} INFO - Started process (PID=2555) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:13:43.367+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:13:43.367+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:13:43.367+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:13:43.374+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:13:43.392+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:13:43.392+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:13:43.411+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:13:43.411+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:13:43.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T21:14:13.664+0000] {processor.py:157} INFO - Started process (PID=2565) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:14:13.673+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:14:13.674+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:14:13.674+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:14:13.680+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:14:13.700+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:14:13.699+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:14:13.719+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:14:13.719+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:14:13.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T21:14:43.975+0000] {processor.py:157} INFO - Started process (PID=2575) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:14:43.986+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:14:43.987+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:14:43.986+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:14:43.993+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:14:44.010+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:14:44.010+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:14:44.029+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:14:44.029+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:14:44.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T21:15:14.270+0000] {processor.py:157} INFO - Started process (PID=2585) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:15:14.278+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:15:14.278+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:15:14.278+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:15:14.285+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:15:14.306+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:15:14.306+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:15:14.325+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:15:14.325+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:15:14.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T21:15:44.557+0000] {processor.py:157} INFO - Started process (PID=2595) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:15:44.562+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:15:44.563+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:15:44.563+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:15:44.570+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:15:44.587+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:15:44.587+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:15:44.607+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:15:44.607+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:15:44.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T21:16:14.866+0000] {processor.py:157} INFO - Started process (PID=2605) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:16:14.872+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:16:14.872+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:16:14.872+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:16:14.879+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:16:14.903+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:16:14.903+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:16:14.925+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:16:14.925+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:16:14.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T21:16:45.178+0000] {processor.py:157} INFO - Started process (PID=2615) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:16:45.183+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:16:45.184+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:16:45.184+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:16:45.191+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:16:45.209+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:16:45.208+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:16:45.228+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:16:45.228+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:16:45.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T21:17:15.468+0000] {processor.py:157} INFO - Started process (PID=2625) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:17:15.474+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:17:15.474+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:17:15.474+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:17:15.481+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:17:15.499+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:17:15.499+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:17:15.520+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:17:15.520+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:17:15.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T21:17:45.759+0000] {processor.py:157} INFO - Started process (PID=2635) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:17:45.766+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:17:45.766+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:17:45.766+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:17:45.773+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:17:45.790+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:17:45.790+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:17:45.810+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:17:45.810+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:17:45.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T21:18:16.051+0000] {processor.py:157} INFO - Started process (PID=2645) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:18:16.058+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:18:16.058+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:18:16.058+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:18:16.065+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:18:16.085+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:18:16.085+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:18:16.104+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:18:16.104+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:18:16.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:18:46.339+0000] {processor.py:157} INFO - Started process (PID=2655) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:18:46.345+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:18:46.345+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:18:46.345+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:18:46.352+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:18:46.371+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:18:46.371+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:18:46.390+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:18:46.390+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:18:46.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T21:19:16.633+0000] {processor.py:157} INFO - Started process (PID=2665) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:19:16.640+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:19:16.641+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:19:16.641+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:19:16.648+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:19:16.666+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:19:16.666+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:19:16.687+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:19:16.687+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:19:16.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T21:19:46.925+0000] {processor.py:157} INFO - Started process (PID=2675) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:19:46.935+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:19:46.935+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:19:46.935+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:19:46.942+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:19:46.961+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:19:46.961+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:19:46.980+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:19:46.980+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:19:46.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T21:20:17.204+0000] {processor.py:157} INFO - Started process (PID=2685) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:20:17.213+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:20:17.213+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:20:17.213+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:20:17.220+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:20:17.245+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:20:17.245+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:20:17.271+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:20:17.271+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:20:17.284+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.081 seconds
[2023-07-07T21:20:47.512+0000] {processor.py:157} INFO - Started process (PID=2695) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:20:47.520+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:20:47.521+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:20:47.520+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:20:47.528+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:20:47.546+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:20:47.546+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:20:47.565+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:20:47.565+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:20:47.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T21:21:17.809+0000] {processor.py:157} INFO - Started process (PID=2705) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:21:17.815+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:21:17.815+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:21:17.815+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:21:17.824+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:21:17.843+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:21:17.843+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:21:17.863+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:21:17.863+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:21:17.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T21:21:48.106+0000] {processor.py:157} INFO - Started process (PID=2715) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:21:48.112+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:21:48.112+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:21:48.112+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:21:48.121+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:21:48.140+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:21:48.139+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:21:48.158+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:21:48.158+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:21:48.168+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:22:18.399+0000] {processor.py:157} INFO - Started process (PID=2725) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:22:18.405+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:22:18.405+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:22:18.405+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:22:18.412+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:22:18.431+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:22:18.431+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:22:18.449+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:22:18.449+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:22:18.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:22:48.669+0000] {processor.py:157} INFO - Started process (PID=2735) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:22:48.674+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:22:48.675+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:22:48.675+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:22:48.681+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:22:48.700+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:22:48.700+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:22:48.719+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:22:48.719+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:22:48.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:23:18.970+0000] {processor.py:157} INFO - Started process (PID=2745) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:23:18.975+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:23:18.975+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:23:18.975+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:23:18.982+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:23:19.001+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:23:19.001+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:23:19.020+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:23:19.020+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:23:19.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.146 seconds
[2023-07-07T21:23:49.348+0000] {processor.py:157} INFO - Started process (PID=2755) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:23:49.355+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:23:49.355+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:23:49.355+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:23:49.362+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:23:49.380+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:23:49.380+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:23:49.399+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:23:49.399+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:23:49.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T21:24:19.653+0000] {processor.py:157} INFO - Started process (PID=2765) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:24:19.659+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:24:19.659+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:24:19.659+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:24:19.666+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:24:19.685+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:24:19.685+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:24:19.705+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:24:19.704+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:24:19.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T21:24:49.960+0000] {processor.py:157} INFO - Started process (PID=2775) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:24:49.971+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:24:49.972+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:24:49.972+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:24:49.978+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:24:49.998+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:24:49.998+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:24:50.017+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:24:50.017+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:24:50.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T21:25:20.286+0000] {processor.py:157} INFO - Started process (PID=2785) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:25:20.291+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:25:20.292+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:25:20.292+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:25:20.298+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:25:20.316+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:25:20.316+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:25:20.335+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:25:20.335+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:25:20.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.151 seconds
[2023-07-07T21:25:50.665+0000] {processor.py:157} INFO - Started process (PID=2795) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:25:50.673+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:25:50.673+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:25:50.673+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:25:50.680+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:25:50.700+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:25:50.700+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:25:50.719+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:25:50.719+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:25:50.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T21:26:20.949+0000] {processor.py:157} INFO - Started process (PID=2805) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:26:20.958+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:26:20.958+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:26:20.958+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:26:20.965+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:26:20.983+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:26:20.983+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:26:21.013+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:26:21.012+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:26:21.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.079 seconds
[2023-07-07T21:26:51.247+0000] {processor.py:157} INFO - Started process (PID=2815) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:26:51.254+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:26:51.255+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:26:51.254+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:26:51.261+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:26:51.279+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:26:51.279+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:26:51.297+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:26:51.297+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:26:51.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T21:27:21.530+0000] {processor.py:157} INFO - Started process (PID=2825) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:27:21.536+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:27:21.536+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:27:21.536+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:27:21.546+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:27:21.566+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:27:21.565+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:27:21.585+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:27:21.584+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:27:21.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.154 seconds
[2023-07-07T21:27:51.880+0000] {processor.py:157} INFO - Started process (PID=2835) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:27:51.886+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:27:51.887+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:27:51.887+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:27:51.894+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:27:51.912+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:27:51.912+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:27:52.015+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:27:52.015+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:27:52.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.148 seconds
[2023-07-07T21:28:22.228+0000] {processor.py:157} INFO - Started process (PID=2845) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:28:22.239+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:28:22.239+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:28:22.239+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:28:22.249+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:28:22.275+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:28:22.275+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:28:22.294+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:28:22.294+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:28:22.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.082 seconds
[2023-07-07T21:28:52.558+0000] {processor.py:157} INFO - Started process (PID=2855) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:28:52.570+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:28:52.570+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:28:52.570+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:28:52.577+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:28:52.597+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:28:52.597+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:28:52.615+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:28:52.615+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:28:52.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T21:29:22.861+0000] {processor.py:157} INFO - Started process (PID=2865) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:29:22.874+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:29:22.874+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:29:22.874+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:29:22.881+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:29:22.907+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:29:22.907+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:29:22.931+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:29:22.931+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:29:23.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.170 seconds
[2023-07-07T21:29:53.236+0000] {processor.py:157} INFO - Started process (PID=2875) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:29:53.241+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:29:53.242+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:29:53.242+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:29:53.248+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:29:53.266+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:29:53.266+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:29:53.372+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:29:53.372+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:29:53.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.150 seconds
[2023-07-07T21:30:23.617+0000] {processor.py:157} INFO - Started process (PID=2885) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:30:23.622+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:30:23.622+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:30:23.622+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:30:23.629+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:30:23.648+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:30:23.648+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:30:23.667+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:30:23.667+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:30:23.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T21:30:53.897+0000] {processor.py:157} INFO - Started process (PID=2895) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:30:53.898+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:30:53.898+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:30:53.898+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:30:53.905+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:30:53.924+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:30:53.924+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:30:53.943+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:30:53.943+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:30:53.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.060 seconds
[2023-07-07T21:31:24.164+0000] {processor.py:157} INFO - Started process (PID=2905) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:31:24.173+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:31:24.173+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:31:24.173+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:31:24.182+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:31:24.204+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:31:24.204+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:31:24.224+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:31:24.224+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:31:24.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.160 seconds
[2023-07-07T21:31:54.552+0000] {processor.py:157} INFO - Started process (PID=2915) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:31:54.558+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:31:54.558+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:31:54.558+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:31:54.565+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:31:54.584+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:31:54.583+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:31:54.685+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:31:54.685+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:31:54.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.146 seconds
[2023-07-07T21:32:24.912+0000] {processor.py:157} INFO - Started process (PID=2925) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:32:24.917+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:32:24.918+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:32:24.918+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:32:24.925+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:32:24.950+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:32:24.950+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:32:24.973+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:32:24.973+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:32:24.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.078 seconds
[2023-07-07T21:32:55.277+0000] {processor.py:157} INFO - Started process (PID=2935) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:32:55.283+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:32:55.283+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:32:55.283+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:32:55.290+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:32:55.309+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:32:55.308+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:32:55.328+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:32:55.328+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:32:55.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:33:25.569+0000] {processor.py:157} INFO - Started process (PID=2945) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:33:25.569+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:33:25.570+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:33:25.570+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:33:25.576+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:33:25.594+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:33:25.594+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:33:25.613+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:33:25.613+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:33:25.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.142 seconds
[2023-07-07T21:33:55.922+0000] {processor.py:157} INFO - Started process (PID=2955) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:33:55.928+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:33:55.928+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:33:55.928+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:33:55.937+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:33:55.962+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:33:55.962+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:33:56.075+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:33:56.075+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:33:56.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.166 seconds
[2023-07-07T21:34:26.310+0000] {processor.py:157} INFO - Started process (PID=2972) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:34:26.317+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:34:26.317+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:34:26.317+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:34:26.323+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:34:26.425+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:34:26.425+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:34:26.443+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:34:26.443+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:34:26.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.147 seconds
[2023-07-07T21:34:56.663+0000] {processor.py:157} INFO - Started process (PID=2982) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:34:56.669+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:34:56.670+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:34:56.670+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:34:56.676+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:34:56.695+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:34:56.695+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:34:56.714+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:34:56.714+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:34:56.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:35:26.948+0000] {processor.py:157} INFO - Started process (PID=2992) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:35:26.953+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:35:26.954+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:35:26.954+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:35:26.960+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:35:26.979+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:35:26.979+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:35:26.999+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:35:26.999+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:35:27.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.151 seconds
[2023-07-07T21:35:57.316+0000] {processor.py:157} INFO - Started process (PID=3002) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:35:57.324+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:35:57.324+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:35:57.324+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:35:57.334+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:35:57.358+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:35:57.358+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:35:57.459+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:35:57.459+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:35:57.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.156 seconds
[2023-07-07T21:36:27.690+0000] {processor.py:157} INFO - Started process (PID=3012) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:36:27.698+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:36:27.698+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:36:27.698+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:36:27.705+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:36:27.806+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:36:27.806+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:36:27.825+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:36:27.825+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:36:27.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.149 seconds
[2023-07-07T21:36:58.090+0000] {processor.py:157} INFO - Started process (PID=3022) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:36:58.091+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:36:58.092+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:36:58.092+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:36:58.185+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:36:58.201+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:36:58.201+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:36:58.219+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:36:58.219+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:36:58.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.145 seconds
[2023-07-07T21:37:28.539+0000] {processor.py:157} INFO - Started process (PID=3032) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:37:28.544+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:37:28.545+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:37:28.545+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:37:28.552+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:37:28.573+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:37:28.573+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:37:28.592+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:37:28.592+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:37:28.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T21:37:58.836+0000] {processor.py:157} INFO - Started process (PID=3042) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:37:58.841+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:37:58.841+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:37:58.841+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:37:58.848+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:37:58.866+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:37:58.866+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:37:58.885+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:37:58.885+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:37:58.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T21:38:29.140+0000] {processor.py:157} INFO - Started process (PID=3052) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:38:29.146+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:38:29.146+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:38:29.146+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:38:29.152+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:38:29.170+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:38:29.170+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:38:29.189+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:38:29.188+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:38:29.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.061 seconds
[2023-07-07T21:38:59.434+0000] {processor.py:157} INFO - Started process (PID=3062) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:38:59.439+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:38:59.440+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:38:59.440+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:38:59.446+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:38:59.464+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:38:59.464+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:38:59.483+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:38:59.483+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:38:59.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T21:39:29.705+0000] {processor.py:157} INFO - Started process (PID=3072) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:39:29.710+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:39:29.711+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:39:29.711+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:39:29.717+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:39:29.735+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:39:29.735+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:39:29.754+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:39:29.754+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:39:29.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T21:40:00.005+0000] {processor.py:157} INFO - Started process (PID=3082) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:40:00.012+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:40:00.012+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:40:00.012+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:40:00.019+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:40:00.038+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:40:00.038+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:40:00.057+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:40:00.057+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:40:00.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:40:30.322+0000] {processor.py:157} INFO - Started process (PID=3092) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:40:30.328+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:40:30.328+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:40:30.328+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:40:30.335+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:40:30.355+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:40:30.355+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:40:30.374+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:40:30.373+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:40:30.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T21:41:00.657+0000] {processor.py:157} INFO - Started process (PID=3102) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:41:00.669+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:41:00.669+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:41:00.669+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:41:00.676+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:41:00.694+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:41:00.694+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:41:00.714+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:41:00.714+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:41:00.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T21:41:30.974+0000] {processor.py:157} INFO - Started process (PID=3112) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:41:30.983+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:41:30.983+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:41:30.983+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:41:30.989+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:41:31.008+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:41:31.008+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:41:31.027+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:41:31.027+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:41:31.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:42:01.299+0000] {processor.py:157} INFO - Started process (PID=3122) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:42:01.305+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:42:01.305+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:42:01.305+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:42:01.312+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:42:01.332+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:42:01.332+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:42:01.352+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:42:01.352+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:42:01.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T21:42:31.610+0000] {processor.py:157} INFO - Started process (PID=3132) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:42:31.615+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:42:31.616+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:42:31.616+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:42:31.625+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:42:31.642+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:42:31.642+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:42:31.662+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:42:31.662+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:42:31.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T21:43:01.911+0000] {processor.py:157} INFO - Started process (PID=3142) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:43:01.917+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:43:01.917+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:43:01.917+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:43:01.924+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:43:01.947+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:43:01.947+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:43:01.971+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:43:01.971+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:43:01.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T21:43:32.220+0000] {processor.py:157} INFO - Started process (PID=3152) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:43:32.226+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:43:32.226+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:43:32.226+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:43:32.233+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:43:32.250+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:43:32.250+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:43:32.270+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:43:32.270+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:43:32.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:44:02.500+0000] {processor.py:157} INFO - Started process (PID=3162) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:44:02.509+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:44:02.510+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:44:02.510+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:44:02.520+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:44:02.543+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:44:02.543+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:44:02.568+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:44:02.568+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:44:02.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.086 seconds
[2023-07-07T21:44:32.810+0000] {processor.py:157} INFO - Started process (PID=3172) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:44:32.816+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:44:32.816+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:44:32.816+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:44:32.826+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:44:32.845+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:44:32.845+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:44:32.863+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:44:32.863+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:44:32.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T21:45:03.108+0000] {processor.py:157} INFO - Started process (PID=3182) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:45:03.114+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:45:03.114+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:45:03.114+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:45:03.123+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:45:03.141+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:45:03.141+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:45:03.160+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:45:03.160+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:45:03.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T21:45:33.409+0000] {processor.py:157} INFO - Started process (PID=3192) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:45:33.414+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:45:33.415+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:45:33.415+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:45:33.424+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:45:33.443+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:45:33.443+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:45:33.462+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:45:33.462+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:45:33.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T21:46:03.703+0000] {processor.py:157} INFO - Started process (PID=3202) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:46:03.720+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:46:03.720+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:46:03.720+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:46:03.727+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:46:03.749+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:46:03.749+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:46:03.768+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:46:03.768+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:46:03.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.080 seconds
[2023-07-07T21:46:34.013+0000] {processor.py:157} INFO - Started process (PID=3212) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:46:34.019+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:46:34.020+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:46:34.020+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:46:34.029+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:46:34.047+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:46:34.047+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:46:34.065+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:46:34.065+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:46:34.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:47:04.332+0000] {processor.py:157} INFO - Started process (PID=3222) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:47:04.340+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:47:04.341+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:47:04.341+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:47:04.347+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:47:04.366+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:47:04.366+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:47:04.385+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:47:04.384+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:47:04.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T21:47:34.638+0000] {processor.py:157} INFO - Started process (PID=3233) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:47:34.644+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:47:34.645+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:47:34.645+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:47:34.651+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:47:34.670+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:47:34.669+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:47:34.689+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:47:34.689+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:47:34.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:48:04.950+0000] {processor.py:157} INFO - Started process (PID=3243) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:48:04.963+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:48:04.963+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:48:04.963+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:48:04.970+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:48:04.995+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:48:04.995+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:48:05.016+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:48:05.016+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:48:05.028+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.080 seconds
[2023-07-07T21:48:35.251+0000] {processor.py:157} INFO - Started process (PID=3253) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:48:35.258+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:48:35.259+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:48:35.259+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:48:35.265+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:48:35.285+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:48:35.284+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:48:35.303+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:48:35.303+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:48:35.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T21:49:05.548+0000] {processor.py:157} INFO - Started process (PID=3263) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:49:05.560+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:49:05.560+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:49:05.560+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:49:05.567+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:49:05.583+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:49:05.583+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:49:05.604+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:49:05.604+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:49:05.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.073 seconds
[2023-07-07T21:49:35.852+0000] {processor.py:157} INFO - Started process (PID=3273) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:49:35.860+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:49:35.861+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:49:35.861+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:49:35.867+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:49:35.893+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:49:35.893+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:49:35.921+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:49:35.921+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:49:35.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.085 seconds
[2023-07-07T21:50:06.165+0000] {processor.py:157} INFO - Started process (PID=3283) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:50:06.170+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:50:06.171+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:50:06.170+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:50:06.180+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:50:06.198+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:50:06.198+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:50:06.217+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:50:06.217+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:50:06.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T21:50:36.468+0000] {processor.py:157} INFO - Started process (PID=3293) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:50:36.474+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:50:36.475+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:50:36.475+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:50:36.484+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:50:36.507+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:50:36.507+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:50:36.527+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:50:36.527+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:50:36.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T21:51:06.768+0000] {processor.py:157} INFO - Started process (PID=3303) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:51:06.774+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:51:06.774+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:51:06.774+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:51:06.781+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:51:06.799+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:51:06.798+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:51:06.817+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:51:06.817+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:51:06.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T21:51:37.049+0000] {processor.py:157} INFO - Started process (PID=3313) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:51:37.057+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:51:37.057+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:51:37.057+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:51:37.064+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:51:37.082+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:51:37.082+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:51:37.101+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:51:37.101+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:51:37.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T21:52:07.371+0000] {processor.py:157} INFO - Started process (PID=3323) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:52:07.382+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:52:07.382+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:52:07.382+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:52:07.388+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:52:07.408+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:52:07.408+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:52:07.427+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:52:07.427+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:52:07.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T21:52:37.673+0000] {processor.py:157} INFO - Started process (PID=3333) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:52:37.678+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:52:37.679+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:52:37.679+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:52:37.688+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:52:37.708+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:52:37.708+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:52:37.727+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:52:37.727+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:52:37.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T21:53:07.955+0000] {processor.py:157} INFO - Started process (PID=3343) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:53:07.961+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:53:07.961+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:53:07.961+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:53:07.968+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:53:07.987+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:53:07.987+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:53:08.006+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:53:08.005+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:53:08.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T21:53:38.271+0000] {processor.py:157} INFO - Started process (PID=3353) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:53:38.278+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:53:38.278+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:53:38.278+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:53:38.285+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:53:38.302+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:53:38.302+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:53:38.322+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:53:38.322+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:53:38.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:54:08.567+0000] {processor.py:157} INFO - Started process (PID=3363) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:54:08.574+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:54:08.574+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:54:08.574+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:54:08.581+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:54:08.600+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:54:08.600+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:54:08.619+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:54:08.619+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:54:08.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T21:54:38.865+0000] {processor.py:157} INFO - Started process (PID=3373) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:54:38.910+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:54:38.911+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:54:38.911+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:54:38.917+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:54:38.944+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:54:38.944+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:54:38.973+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:54:38.973+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:54:38.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.123 seconds
[2023-07-07T21:55:09.195+0000] {processor.py:157} INFO - Started process (PID=3383) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:55:09.201+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:55:09.201+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:55:09.201+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:55:09.210+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:55:09.230+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:55:09.230+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:55:09.250+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:55:09.250+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:55:09.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.073 seconds
[2023-07-07T21:55:39.489+0000] {processor.py:157} INFO - Started process (PID=3393) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:55:39.494+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:55:39.495+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:55:39.495+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:55:39.501+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:55:39.519+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:55:39.519+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:55:39.540+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:55:39.540+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:55:39.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T21:56:09.786+0000] {processor.py:157} INFO - Started process (PID=3403) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:56:09.798+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:56:09.799+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:56:09.799+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:56:09.808+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:56:09.834+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:56:09.834+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:56:09.854+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:56:09.853+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:56:09.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.083 seconds
[2023-07-07T21:56:40.081+0000] {processor.py:157} INFO - Started process (PID=3413) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:56:40.087+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:56:40.087+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:56:40.087+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:56:40.094+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:56:40.115+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:56:40.115+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:56:40.141+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:56:40.141+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:56:40.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.075 seconds
[2023-07-07T21:57:10.366+0000] {processor.py:157} INFO - Started process (PID=3422) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:57:10.372+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:57:10.372+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:57:10.372+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:57:10.379+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:57:10.399+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:57:10.399+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:57:10.420+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:57:10.420+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:57:10.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T21:57:40.654+0000] {processor.py:157} INFO - Started process (PID=3432) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:57:40.655+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:57:40.655+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:57:40.655+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:57:40.664+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:57:40.686+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:57:40.686+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:57:40.706+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:57:40.706+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:57:40.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.160 seconds
[2023-07-07T21:57:50.885+0000] {processor.py:157} INFO - Started process (PID=3435) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:57:50.885+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:57:50.886+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:57:50.886+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:57:50.893+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:57:50.913+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:57:50.913+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:57:50.933+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:57:50.933+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:57:50.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T21:58:21.094+0000] {processor.py:157} INFO - Started process (PID=3445) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:58:21.100+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:58:21.100+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:58:21.100+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:58:21.107+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:58:21.126+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:58:21.126+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:58:21.145+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:58:21.145+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:58:21.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T21:58:51.378+0000] {processor.py:157} INFO - Started process (PID=3454) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:58:51.383+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:58:51.383+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:58:51.383+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:58:51.390+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:58:51.409+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:58:51.409+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:58:51.428+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:58:51.428+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:58:51.440+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:59:21.674+0000] {processor.py:157} INFO - Started process (PID=3464) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:59:21.680+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:59:21.680+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:59:21.680+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:59:21.686+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:59:21.705+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:59:21.705+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:59:21.725+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:59:21.725+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:59:21.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T21:59:32.759+0000] {processor.py:157} INFO - Started process (PID=3472) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:59:32.760+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:59:32.760+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:59:32.760+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:59:32.767+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:59:32.787+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:59:32.787+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:59:32.806+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:59:32.806+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:59:32.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T21:59:33.793+0000] {processor.py:157} INFO - Started process (PID=3473) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:59:33.793+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T21:59:33.794+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:59:33.794+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:59:33.802+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T21:59:33.823+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:59:33.822+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T21:59:33.842+0000] {logging_mixin.py:149} INFO - [2023-07-07T21:59:33.842+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T21:59:33.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T22:00:04.038+0000] {processor.py:157} INFO - Started process (PID=3483) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:00:04.045+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:00:04.045+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:00:04.045+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:00:04.052+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:00:04.071+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:00:04.071+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:00:04.090+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:00:04.090+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:00:04.101+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T22:00:34.264+0000] {processor.py:157} INFO - Started process (PID=3493) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:00:34.271+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:00:34.272+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:00:34.271+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:00:34.278+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:00:34.298+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:00:34.298+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:00:34.317+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:00:34.317+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:00:34.328+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T22:01:04.513+0000] {processor.py:157} INFO - Started process (PID=3503) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:01:04.522+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:01:04.522+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:01:04.522+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:01:04.532+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:01:04.555+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:01:04.555+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:01:04.574+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:01:04.574+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:01:04.586+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.075 seconds
[2023-07-07T22:01:34.768+0000] {processor.py:157} INFO - Started process (PID=3513) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:01:34.769+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:01:34.770+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:01:34.769+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:01:34.776+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:01:34.795+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:01:34.794+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:01:34.814+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:01:34.814+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:01:34.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.059 seconds
[2023-07-07T22:02:05.062+0000] {processor.py:157} INFO - Started process (PID=3523) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:02:05.069+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:02:05.070+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:02:05.070+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:02:05.076+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:02:05.096+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:02:05.095+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:02:05.115+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:02:05.115+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:02:05.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T22:02:35.323+0000] {processor.py:157} INFO - Started process (PID=3533) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:02:35.329+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:02:35.330+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:02:35.330+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:02:35.338+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:02:35.360+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:02:35.360+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:02:35.384+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:02:35.384+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:02:35.396+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.076 seconds
[2023-07-07T22:03:05.582+0000] {processor.py:157} INFO - Started process (PID=3543) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:03:05.594+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:03:05.594+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:03:05.594+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:03:05.602+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:03:05.621+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:03:05.620+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:03:05.640+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:03:05.640+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:03:05.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T22:03:35.828+0000] {processor.py:157} INFO - Started process (PID=3553) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:03:35.835+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:03:35.835+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:03:35.835+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:03:35.842+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:03:35.862+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:03:35.862+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:03:35.881+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:03:35.881+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:03:35.892+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T22:04:06.111+0000] {processor.py:157} INFO - Started process (PID=3563) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:04:06.118+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:04:06.118+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:04:06.118+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:04:06.125+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:04:06.143+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:04:06.143+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:04:06.162+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:04:06.162+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:04:06.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T22:04:36.363+0000] {processor.py:157} INFO - Started process (PID=3573) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:04:36.364+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:04:36.364+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:04:36.364+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:04:36.371+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:04:36.390+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:04:36.390+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:04:36.410+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:04:36.410+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:04:36.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T22:05:06.626+0000] {processor.py:157} INFO - Started process (PID=3582) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:05:06.639+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:05:06.639+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:05:06.639+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:05:06.646+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:05:06.664+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:05:06.664+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:05:06.684+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:05:06.684+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:05:06.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T22:05:36.885+0000] {processor.py:157} INFO - Started process (PID=3592) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:05:36.893+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:05:36.894+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:05:36.894+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:05:36.900+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:05:36.919+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:05:36.919+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:05:36.939+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:05:36.939+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:05:36.950+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T22:06:07.125+0000] {processor.py:157} INFO - Started process (PID=3602) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:06:07.130+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:06:07.130+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:06:07.130+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:06:07.137+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:06:07.158+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:06:07.158+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:06:07.177+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:06:07.177+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:06:07.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T22:06:37.366+0000] {processor.py:157} INFO - Started process (PID=3612) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:06:37.373+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:06:37.373+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:06:37.373+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:06:37.379+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:06:37.399+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:06:37.398+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:06:37.418+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:06:37.418+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:06:37.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T22:07:07.663+0000] {processor.py:157} INFO - Started process (PID=3622) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:07:07.672+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:07:07.672+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:07:07.672+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:07:07.679+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:07:07.697+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:07:07.697+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:07:07.716+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:07:07.716+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:07:07.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T22:07:37.922+0000] {processor.py:157} INFO - Started process (PID=3632) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:07:37.927+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:07:37.928+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:07:37.927+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:07:37.934+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:07:37.953+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:07:37.953+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:07:37.972+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:07:37.972+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:07:37.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T22:08:08.195+0000] {processor.py:157} INFO - Started process (PID=3642) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:08:08.202+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:08:08.202+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:08:08.202+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:08:08.209+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:08:08.228+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:08:08.228+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:08:08.247+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:08:08.247+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:08:08.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T22:08:38.429+0000] {processor.py:157} INFO - Started process (PID=3652) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:08:38.437+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:08:38.437+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:08:38.437+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:08:38.444+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:08:38.462+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:08:38.462+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:08:38.480+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:08:38.480+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:08:38.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T22:09:08.710+0000] {processor.py:157} INFO - Started process (PID=3662) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:09:08.716+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:09:08.717+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:09:08.717+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:09:08.724+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:09:08.743+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:09:08.743+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:09:08.764+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:09:08.764+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:09:08.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T22:09:39.010+0000] {processor.py:157} INFO - Started process (PID=3672) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:09:39.018+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:09:39.018+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:09:39.018+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:09:39.024+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:09:39.044+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:09:39.044+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:09:39.067+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:09:39.067+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:09:39.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T22:10:09.273+0000] {processor.py:157} INFO - Started process (PID=3682) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:10:09.278+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:10:09.278+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:10:09.278+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:10:09.285+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:10:09.303+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:10:09.303+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:10:09.322+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:10:09.322+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:10:09.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T22:10:39.553+0000] {processor.py:157} INFO - Started process (PID=3692) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:10:39.560+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:10:39.560+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:10:39.560+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:10:39.567+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:10:39.586+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:10:39.586+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:10:39.604+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:10:39.604+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:10:39.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T22:11:09.784+0000] {processor.py:157} INFO - Started process (PID=3702) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:11:09.791+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:11:09.791+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:11:09.791+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:11:09.800+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:11:09.819+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:11:09.818+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:11:09.837+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:11:09.837+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:11:09.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T22:11:40.046+0000] {processor.py:157} INFO - Started process (PID=3712) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:11:40.054+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:11:40.055+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:11:40.055+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:11:40.061+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:11:40.080+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:11:40.080+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:11:40.099+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:11:40.099+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:11:40.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T22:12:10.270+0000] {processor.py:157} INFO - Started process (PID=3722) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:12:10.275+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:12:10.276+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:12:10.276+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:12:10.282+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:12:10.301+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:12:10.301+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:12:10.320+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:12:10.320+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:12:10.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T22:12:40.558+0000] {processor.py:157} INFO - Started process (PID=3732) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:12:40.569+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:12:40.570+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:12:40.570+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:12:40.576+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:12:40.598+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:12:40.598+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:12:40.617+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:12:40.617+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:12:40.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T22:13:10.822+0000] {processor.py:157} INFO - Started process (PID=3742) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:13:10.828+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:13:10.828+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:13:10.828+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:13:10.835+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:13:10.852+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:13:10.852+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:13:10.872+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:13:10.871+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:13:10.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T22:13:41.049+0000] {processor.py:157} INFO - Started process (PID=3752) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:13:41.056+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:13:41.056+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:13:41.056+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:13:41.063+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:13:41.083+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:13:41.082+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:13:41.102+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:13:41.102+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:13:41.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T22:14:11.309+0000] {processor.py:157} INFO - Started process (PID=3762) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:14:11.316+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:14:11.317+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:14:11.317+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:14:11.323+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:14:11.342+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:14:11.342+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:14:11.362+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:14:11.361+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:14:11.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T22:14:41.586+0000] {processor.py:157} INFO - Started process (PID=3772) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:14:41.596+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:14:41.596+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:14:41.596+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:14:41.603+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:14:41.623+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:14:41.622+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:14:41.642+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:14:41.642+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:14:41.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T22:15:11.834+0000] {processor.py:157} INFO - Started process (PID=3782) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:15:11.839+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:15:11.840+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:15:11.840+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:15:11.848+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:15:11.871+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:15:11.871+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:15:11.893+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:15:11.893+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:15:11.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.073 seconds
[2023-07-07T22:15:42.091+0000] {processor.py:157} INFO - Started process (PID=3792) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:15:42.098+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:15:42.098+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:15:42.098+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:15:42.105+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:15:42.124+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:15:42.123+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:15:42.143+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:15:42.143+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:15:42.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T22:16:06.333+0000] {processor.py:157} INFO - Started process (PID=3802) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:16:06.338+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:16:06.339+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:16:06.339+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:16:06.346+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:16:06.366+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:16:06.366+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:16:06.385+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:16:06.385+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:16:06.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T22:16:36.545+0000] {processor.py:157} INFO - Started process (PID=3812) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:16:36.553+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:16:36.553+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:16:36.553+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:16:36.559+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:16:36.578+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:16:36.577+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:16:36.597+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:16:36.597+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:16:36.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T22:17:06.778+0000] {processor.py:157} INFO - Started process (PID=3822) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:17:06.788+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:17:06.788+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:17:06.788+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:17:06.797+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:17:06.819+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:17:06.819+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:17:06.838+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:17:06.838+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:17:06.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.075 seconds
[2023-07-07T22:17:37.049+0000] {processor.py:157} INFO - Started process (PID=3832) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:17:37.057+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:17:37.057+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:17:37.057+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:17:37.064+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:17:37.083+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:17:37.083+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:17:37.102+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:17:37.102+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:17:37.113+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T22:18:07.265+0000] {processor.py:157} INFO - Started process (PID=3842) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:18:07.275+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:18:07.276+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:18:07.276+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:18:07.285+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:18:07.304+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:18:07.304+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:18:07.323+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:18:07.323+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:18:07.339+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.077 seconds
[2023-07-07T22:18:37.512+0000] {processor.py:157} INFO - Started process (PID=3852) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:18:37.520+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:18:37.521+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:18:37.521+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:18:37.527+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:18:37.546+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:18:37.546+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:18:37.565+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:18:37.565+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:18:37.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T22:19:07.757+0000] {processor.py:157} INFO - Started process (PID=3862) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:19:07.762+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:19:07.763+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:19:07.763+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:19:07.772+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:19:07.793+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:19:07.793+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:19:07.812+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:19:07.812+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:19:07.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T22:19:37.974+0000] {processor.py:157} INFO - Started process (PID=3872) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:19:37.979+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:19:37.980+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:19:37.980+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:19:37.986+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:19:38.005+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:19:38.005+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:19:38.025+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:19:38.025+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:19:38.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T22:20:08.253+0000] {processor.py:157} INFO - Started process (PID=3882) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:20:08.259+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:20:08.259+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:20:08.259+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:20:08.266+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:20:08.286+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:20:08.286+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:20:08.306+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:20:08.306+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:20:08.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T22:20:38.481+0000] {processor.py:157} INFO - Started process (PID=3892) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:20:38.486+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:20:38.487+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:20:38.487+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:20:38.496+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:20:38.515+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:20:38.515+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:20:38.533+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:20:38.533+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:20:38.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T22:21:08.715+0000] {processor.py:157} INFO - Started process (PID=3902) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:21:08.721+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:21:08.721+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:21:08.721+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:21:08.728+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:21:08.747+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:21:08.747+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:21:08.769+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:21:08.769+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:21:08.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T22:21:38.998+0000] {processor.py:157} INFO - Started process (PID=3912) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:21:39.003+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:21:39.003+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:21:39.003+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:21:39.010+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:21:39.029+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:21:39.029+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:21:39.050+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:21:39.050+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:21:39.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T22:22:09.216+0000] {processor.py:157} INFO - Started process (PID=3922) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:22:09.222+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:22:09.223+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:22:09.223+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:22:09.229+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:22:09.248+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:22:09.248+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:22:09.266+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:22:09.266+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:22:09.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T22:22:39.462+0000] {processor.py:157} INFO - Started process (PID=3932) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:22:39.472+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:22:39.472+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:22:39.472+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:22:39.479+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:22:39.500+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:22:39.500+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:22:39.519+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:22:39.519+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:22:39.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T22:23:09.688+0000] {processor.py:157} INFO - Started process (PID=3942) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:23:09.695+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:23:09.696+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:23:09.696+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:23:09.702+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:23:09.720+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:23:09.720+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:23:09.741+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:23:09.741+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:23:09.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T22:23:39.891+0000] {processor.py:157} INFO - Started process (PID=3951) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:23:40.054+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:23:40.055+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:23:40.054+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:23:41.092+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:23:41.226+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:23:41.226+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:23:41.245+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:23:41.245+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:23:41.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 1.370 seconds
[2023-07-07T22:24:10.707+0000] {processor.py:157} INFO - Started process (PID=32) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:24:10.707+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:24:10.708+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:24:10.708+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:24:10.717+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:24:10.883+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:24:10.883+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:24:10.909+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:24:10.908+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:24:10.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.221 seconds
[2023-07-07T22:24:41.085+0000] {processor.py:157} INFO - Started process (PID=42) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:24:41.090+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:24:41.091+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:24:41.091+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:24:41.098+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:24:41.120+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:24:41.120+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:24:41.140+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:24:41.140+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:24:41.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T22:25:11.359+0000] {processor.py:157} INFO - Started process (PID=52) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:25:11.370+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:25:11.371+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:25:11.370+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:25:11.378+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:25:11.398+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:25:11.398+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:25:11.419+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:25:11.418+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:25:11.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.099 seconds
[2023-07-07T22:25:41.633+0000] {processor.py:157} INFO - Started process (PID=62) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:25:41.638+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:25:41.639+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:25:41.639+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:25:41.646+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:25:41.672+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:25:41.672+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:25:41.703+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:25:41.703+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:25:41.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.085 seconds
[2023-07-07T22:26:11.898+0000] {processor.py:157} INFO - Started process (PID=72) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:26:11.904+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:26:11.904+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:26:11.904+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:26:11.911+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:26:11.931+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:26:11.931+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:26:11.952+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:26:11.952+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:26:11.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T22:26:42.153+0000] {processor.py:157} INFO - Started process (PID=82) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:26:42.159+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:26:42.159+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:26:42.159+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:26:42.166+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:26:42.185+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:26:42.185+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:26:42.206+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:26:42.206+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:26:42.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T22:27:12.432+0000] {processor.py:157} INFO - Started process (PID=92) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:27:12.438+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:27:12.438+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:27:12.438+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:27:12.446+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:27:12.470+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:27:12.470+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:27:12.495+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:27:12.495+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:27:12.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.078 seconds
[2023-07-07T22:27:42.692+0000] {processor.py:157} INFO - Started process (PID=102) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:27:42.693+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:27:42.693+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:27:42.693+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:27:42.701+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:27:42.726+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:27:42.725+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:27:42.757+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:27:42.757+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:27:42.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.085 seconds
[2023-07-07T22:28:12.974+0000] {processor.py:157} INFO - Started process (PID=112) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:28:12.980+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:28:12.980+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:28:12.980+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:28:12.987+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:28:13.014+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:28:13.013+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:28:13.035+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:28:13.034+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:28:13.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.076 seconds
[2023-07-07T22:28:43.286+0000] {processor.py:157} INFO - Started process (PID=122) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:28:43.293+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:28:43.294+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:28:43.294+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:28:43.301+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:28:43.321+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:28:43.320+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:28:43.340+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:28:43.340+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:28:43.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T22:29:13.565+0000] {processor.py:157} INFO - Started process (PID=132) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:29:13.570+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:29:13.571+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:29:13.571+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:29:13.577+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:29:13.595+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:29:13.595+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:29:13.614+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:29:13.614+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:29:13.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T22:29:43.811+0000] {processor.py:157} INFO - Started process (PID=142) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:29:43.821+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:29:43.821+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:29:43.821+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:29:43.828+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:29:43.846+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:29:43.846+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:29:43.866+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:29:43.866+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:29:43.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T22:30:14.082+0000] {processor.py:157} INFO - Started process (PID=152) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:30:14.087+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:30:14.088+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:30:14.087+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:30:14.094+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:30:14.121+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:30:14.121+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:30:14.144+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:30:14.144+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:30:14.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.077 seconds
[2023-07-07T22:30:44.375+0000] {processor.py:157} INFO - Started process (PID=162) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:30:44.381+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:30:44.381+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:30:44.381+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:30:44.389+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:30:44.408+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:30:44.408+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:30:44.427+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:30:44.427+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:30:44.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T22:31:14.637+0000] {processor.py:157} INFO - Started process (PID=172) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:31:14.642+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:31:14.643+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:31:14.643+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:31:14.652+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:31:14.673+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:31:14.673+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:31:14.692+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:31:14.692+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:31:14.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T22:31:44.906+0000] {processor.py:157} INFO - Started process (PID=182) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:31:44.912+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:31:44.912+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:31:44.912+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:31:44.919+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:31:44.943+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:31:44.943+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:31:44.973+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:31:44.973+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:31:44.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.082 seconds
[2023-07-07T22:32:15.183+0000] {processor.py:157} INFO - Started process (PID=192) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:32:15.189+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:32:15.189+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:32:15.189+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:32:15.198+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:32:15.217+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:32:15.216+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:32:15.239+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:32:15.239+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:32:15.253+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T22:32:45.450+0000] {processor.py:157} INFO - Started process (PID=202) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:32:45.455+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:32:45.456+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:32:45.455+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:32:45.462+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:32:45.482+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:32:45.481+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:32:45.501+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:32:45.500+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:32:45.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T22:33:15.723+0000] {processor.py:157} INFO - Started process (PID=212) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:33:15.729+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:33:15.729+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:33:15.729+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:33:15.736+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:33:15.756+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:33:15.756+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:33:15.777+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:33:15.776+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:33:15.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T22:33:46.001+0000] {processor.py:157} INFO - Started process (PID=222) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:33:46.006+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:33:46.007+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:33:46.007+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:33:46.013+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:33:46.033+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:33:46.033+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:33:46.054+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:33:46.054+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:33:46.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T22:34:16.263+0000] {processor.py:157} INFO - Started process (PID=232) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:34:16.268+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:34:16.269+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:34:16.268+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:34:16.275+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:34:16.293+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:34:16.293+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:34:16.312+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:34:16.312+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:34:16.323+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T22:34:46.538+0000] {processor.py:157} INFO - Started process (PID=242) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:34:46.550+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:34:46.550+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:34:46.550+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:34:46.557+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:34:46.575+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:34:46.575+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:34:46.594+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:34:46.594+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:34:46.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T22:35:16.794+0000] {processor.py:157} INFO - Started process (PID=252) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:35:16.799+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:35:16.800+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:35:16.800+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:35:16.806+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:35:16.824+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:35:16.824+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:35:16.844+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:35:16.844+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:35:16.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T22:35:47.053+0000] {processor.py:157} INFO - Started process (PID=262) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:35:47.059+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:35:47.059+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:35:47.059+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:35:47.066+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:35:47.086+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:35:47.086+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:35:47.107+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:35:47.107+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:35:47.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T22:36:17.328+0000] {processor.py:157} INFO - Started process (PID=272) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:36:17.339+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:36:17.340+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:36:17.340+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:36:17.346+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:36:17.366+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:36:17.366+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:36:17.386+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:36:17.386+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:36:17.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.074 seconds
[2023-07-07T22:36:47.605+0000] {processor.py:157} INFO - Started process (PID=282) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:36:47.610+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:36:47.610+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:36:47.610+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:36:47.617+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:36:47.638+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:36:47.638+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:36:47.657+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:36:47.657+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:36:47.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T22:37:17.887+0000] {processor.py:157} INFO - Started process (PID=292) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:37:17.894+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:37:17.895+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:37:17.895+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:37:17.901+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:37:17.922+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:37:17.921+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:37:17.941+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:37:17.941+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:37:17.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T22:37:48.156+0000] {processor.py:157} INFO - Started process (PID=302) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:37:48.161+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:37:48.162+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:37:48.162+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:37:48.169+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:37:48.187+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:37:48.187+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:37:48.207+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:37:48.206+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:37:48.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T22:38:18.439+0000] {processor.py:157} INFO - Started process (PID=312) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:38:18.444+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:38:18.445+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:38:18.444+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:38:18.451+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:38:18.471+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:38:18.471+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:38:18.491+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:38:18.491+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:38:18.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T22:38:48.714+0000] {processor.py:157} INFO - Started process (PID=322) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:38:48.720+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:38:48.720+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:38:48.720+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:38:48.727+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:38:48.745+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:38:48.745+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:38:48.765+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:38:48.765+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:38:48.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T22:39:19.014+0000] {processor.py:157} INFO - Started process (PID=332) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:39:19.019+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:39:19.020+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:39:19.020+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:39:19.027+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:39:19.045+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:39:19.045+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:39:19.064+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:39:19.064+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:39:19.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T22:39:49.286+0000] {processor.py:157} INFO - Started process (PID=342) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:39:49.292+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:39:49.292+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:39:49.292+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:39:49.301+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:39:49.320+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:39:49.320+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:39:49.339+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:39:49.339+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:39:49.351+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T22:40:19.567+0000] {processor.py:157} INFO - Started process (PID=352) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:40:19.569+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:40:19.569+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:40:19.569+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:40:19.576+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:40:19.600+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:40:19.600+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:40:19.620+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:40:19.620+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:40:19.632+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T22:40:49.812+0000] {processor.py:157} INFO - Started process (PID=362) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:40:49.819+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:40:49.819+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:40:49.819+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:40:49.827+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:40:49.851+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:40:49.851+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:40:49.871+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:40:49.871+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:40:49.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T22:41:20.073+0000] {processor.py:157} INFO - Started process (PID=372) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:41:20.078+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:41:20.079+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:41:20.079+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:41:20.086+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:41:20.105+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:41:20.105+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:41:20.126+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:41:20.126+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:41:20.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T22:41:50.304+0000] {processor.py:157} INFO - Started process (PID=382) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:41:50.310+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:41:50.310+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:41:50.310+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:41:50.317+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:41:50.335+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:41:50.335+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:41:50.355+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:41:50.355+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:41:50.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T22:42:20.548+0000] {processor.py:157} INFO - Started process (PID=392) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:42:20.554+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:42:20.554+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:42:20.554+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:42:20.561+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:42:20.580+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:42:20.580+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:42:20.601+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:42:20.600+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:42:20.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T22:42:50.801+0000] {processor.py:157} INFO - Started process (PID=402) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:42:50.806+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:42:50.806+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:42:50.806+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:42:50.813+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:42:50.833+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:42:50.833+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:42:50.852+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:42:50.852+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:42:50.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T22:43:21.055+0000] {processor.py:157} INFO - Started process (PID=412) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:43:21.061+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:43:21.061+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:43:21.061+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:43:21.068+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:43:21.086+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:43:21.086+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:43:21.106+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:43:21.105+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:43:21.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T22:43:51.299+0000] {processor.py:157} INFO - Started process (PID=422) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:43:51.304+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:43:51.304+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:43:51.304+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:43:51.311+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:43:51.329+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:43:51.329+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:43:51.349+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:43:51.348+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:43:51.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T22:44:21.562+0000] {processor.py:157} INFO - Started process (PID=432) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:44:21.570+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:44:21.570+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:44:21.570+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:44:21.577+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:44:21.596+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:44:21.596+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:44:21.616+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:44:21.616+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:44:21.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T22:44:51.832+0000] {processor.py:157} INFO - Started process (PID=442) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:44:51.838+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:44:51.838+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:44:51.838+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:44:51.846+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:44:51.865+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:44:51.864+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:44:51.884+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:44:51.884+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:44:51.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T22:45:22.092+0000] {processor.py:157} INFO - Started process (PID=452) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:45:22.097+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:45:22.098+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:45:22.098+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:45:22.105+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:45:22.125+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:45:22.125+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:45:22.146+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:45:22.146+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:45:22.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T22:45:52.406+0000] {processor.py:157} INFO - Started process (PID=462) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:45:52.414+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:45:52.414+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:45:52.414+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:45:52.421+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:45:52.445+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:45:52.445+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:45:52.475+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:45:52.475+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:45:52.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.083 seconds
[2023-07-07T22:46:22.737+0000] {processor.py:157} INFO - Started process (PID=472) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:46:22.748+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:46:22.748+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:46:22.748+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:46:22.755+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:46:22.774+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:46:22.774+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:46:22.794+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:46:22.793+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:46:22.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T22:46:53.050+0000] {processor.py:157} INFO - Started process (PID=482) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:46:53.056+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:46:53.057+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:46:53.057+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:46:53.063+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:46:53.084+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:46:53.084+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:46:53.103+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:46:53.103+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:46:53.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T22:47:23.358+0000] {processor.py:157} INFO - Started process (PID=492) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:47:23.368+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:47:23.368+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:47:23.368+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:47:23.377+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:47:23.397+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:47:23.397+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:47:23.416+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:47:23.416+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:47:23.429+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T22:47:53.661+0000] {processor.py:157} INFO - Started process (PID=502) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:47:53.668+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:47:53.668+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:47:53.668+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:47:53.675+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:47:53.695+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:47:53.695+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:47:53.715+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:47:53.715+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:47:53.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T22:48:23.972+0000] {processor.py:157} INFO - Started process (PID=512) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:48:23.983+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:48:23.984+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:48:23.983+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:48:23.990+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:48:24.009+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:48:24.008+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:48:24.029+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:48:24.028+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:48:24.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T22:48:54.287+0000] {processor.py:157} INFO - Started process (PID=522) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:48:54.297+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:48:54.297+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:48:54.297+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:48:54.304+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:48:54.324+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:48:54.324+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:48:54.347+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:48:54.347+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:48:54.365+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.080 seconds
[2023-07-07T22:49:24.624+0000] {processor.py:157} INFO - Started process (PID=532) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:49:24.625+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:49:24.625+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:49:24.625+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:49:24.632+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:49:24.652+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:49:24.652+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:49:24.671+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:49:24.670+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:49:24.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.060 seconds
[2023-07-07T22:49:54.927+0000] {processor.py:157} INFO - Started process (PID=542) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:49:54.933+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:49:54.933+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:49:54.933+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:49:54.940+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:49:54.958+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:49:54.958+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:49:54.977+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:49:54.977+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:49:54.989+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T22:50:25.191+0000] {processor.py:157} INFO - Started process (PID=552) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:50:25.201+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:50:25.201+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:50:25.201+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:50:25.208+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:50:25.231+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:50:25.231+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:50:25.253+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:50:25.253+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:50:25.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.077 seconds
[2023-07-07T22:50:55.490+0000] {processor.py:157} INFO - Started process (PID=562) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:50:55.495+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:50:55.495+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:50:55.495+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:50:55.502+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:50:55.521+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:50:55.521+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:50:55.540+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:50:55.540+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:50:55.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T22:51:25.743+0000] {processor.py:157} INFO - Started process (PID=572) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:51:25.750+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:51:25.750+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:51:25.750+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:51:25.758+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:51:25.778+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:51:25.778+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:51:25.799+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:51:25.799+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:51:25.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T22:51:56.006+0000] {processor.py:157} INFO - Started process (PID=582) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:51:56.013+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:51:56.013+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:51:56.013+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:51:56.020+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:51:56.038+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:51:56.038+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:51:56.058+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:51:56.058+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:51:56.068+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T22:52:26.245+0000] {processor.py:157} INFO - Started process (PID=592) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:52:26.251+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:52:26.251+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:52:26.251+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:52:26.258+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:52:26.278+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:52:26.278+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:52:26.298+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:52:26.298+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:52:26.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T22:52:56.497+0000] {processor.py:157} INFO - Started process (PID=602) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:52:56.502+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:52:56.502+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:52:56.502+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:52:56.509+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:52:56.529+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:52:56.529+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:52:56.548+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:52:56.548+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:52:56.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T22:53:26.740+0000] {processor.py:157} INFO - Started process (PID=612) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:53:26.746+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:53:26.747+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:53:26.746+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:53:26.753+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:53:26.779+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:53:26.779+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:53:26.808+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:53:26.808+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:53:26.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.085 seconds
[2023-07-07T22:53:57.013+0000] {processor.py:157} INFO - Started process (PID=622) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:53:57.014+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:53:57.014+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:53:57.014+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:53:57.021+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:53:57.041+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:53:57.041+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:53:57.062+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:53:57.062+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:53:57.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T22:54:27.280+0000] {processor.py:157} INFO - Started process (PID=632) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:54:27.287+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:54:27.288+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:54:27.287+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:54:27.295+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:54:27.313+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:54:27.313+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:54:27.333+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:54:27.332+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:54:27.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T22:54:57.534+0000] {processor.py:157} INFO - Started process (PID=642) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:54:57.539+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:54:57.540+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:54:57.540+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:54:57.547+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:54:57.566+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:54:57.566+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:54:57.585+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:54:57.585+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:54:57.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T22:55:27.788+0000] {processor.py:157} INFO - Started process (PID=652) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:55:27.793+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:55:27.794+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:55:27.794+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:55:27.801+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:55:27.819+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:55:27.819+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:55:27.838+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:55:27.838+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:55:27.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T22:55:58.046+0000] {processor.py:157} INFO - Started process (PID=662) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:55:58.052+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:55:58.052+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:55:58.052+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:55:58.058+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:55:58.080+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:55:58.080+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:55:58.101+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:55:58.101+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:55:58.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T22:56:28.304+0000] {processor.py:157} INFO - Started process (PID=672) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:56:28.312+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:56:28.313+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:56:28.313+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:56:28.319+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:56:28.338+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:56:28.338+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:56:28.357+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:56:28.357+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:56:28.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T22:56:58.583+0000] {processor.py:157} INFO - Started process (PID=682) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:56:58.589+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:56:58.589+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:56:58.589+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:56:58.596+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:56:58.614+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:56:58.613+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:56:58.633+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:56:58.633+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:56:58.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T22:57:28.835+0000] {processor.py:157} INFO - Started process (PID=692) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:57:28.840+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:57:28.841+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:57:28.841+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:57:28.850+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:57:28.869+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:57:28.869+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:57:28.889+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:57:28.889+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:57:28.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T22:57:59.089+0000] {processor.py:157} INFO - Started process (PID=702) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:57:59.090+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:57:59.091+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:57:59.091+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:57:59.098+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:57:59.120+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:57:59.119+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:57:59.141+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:57:59.141+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:57:59.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T22:58:29.324+0000] {processor.py:157} INFO - Started process (PID=712) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:58:29.330+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:58:29.331+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:58:29.330+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:58:29.337+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:58:29.364+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:58:29.364+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:58:29.387+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:58:29.387+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:58:29.399+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.078 seconds
[2023-07-07T22:58:59.589+0000] {processor.py:157} INFO - Started process (PID=722) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:58:59.596+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:58:59.596+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:58:59.596+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:58:59.606+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:58:59.627+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:58:59.627+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:58:59.645+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:58:59.645+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:58:59.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T22:59:29.852+0000] {processor.py:157} INFO - Started process (PID=732) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:59:29.863+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T22:59:29.863+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:59:29.863+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:59:29.870+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T22:59:29.888+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:59:29.887+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T22:59:29.907+0000] {logging_mixin.py:149} INFO - [2023-07-07T22:59:29.906+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T22:59:29.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T23:00:00.080+0000] {processor.py:157} INFO - Started process (PID=742) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:00:00.088+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:00:00.089+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:00:00.088+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:00:00.096+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:00:00.117+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:00:00.117+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:00:00.138+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:00:00.137+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:00:00.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T23:00:30.338+0000] {processor.py:157} INFO - Started process (PID=752) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:00:30.344+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:00:30.345+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:00:30.345+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:00:30.351+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:00:30.371+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:00:30.371+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:00:30.390+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:00:30.390+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:00:30.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T23:01:00.621+0000] {processor.py:157} INFO - Started process (PID=762) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:01:00.628+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:01:00.628+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:01:00.628+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:01:00.635+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:01:00.653+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:01:00.653+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:01:00.674+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:01:00.674+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:01:00.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T23:01:30.874+0000] {processor.py:157} INFO - Started process (PID=772) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:01:30.880+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:01:30.881+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:01:30.881+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:01:30.888+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:01:30.907+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:01:30.907+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:01:30.927+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:01:30.927+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:01:30.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T23:02:01.129+0000] {processor.py:157} INFO - Started process (PID=782) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:02:01.135+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:02:01.136+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:02:01.136+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:02:01.143+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:02:01.162+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:02:01.162+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:02:01.183+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:02:01.182+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:02:01.194+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T23:02:31.362+0000] {processor.py:157} INFO - Started process (PID=792) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:02:31.368+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:02:31.368+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:02:31.368+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:02:31.375+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:02:31.394+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:02:31.394+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:02:31.414+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:02:31.414+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:02:31.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T23:03:01.595+0000] {processor.py:157} INFO - Started process (PID=802) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:03:01.598+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:03:01.599+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:03:01.599+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:03:01.605+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:03:01.624+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:03:01.624+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:03:01.643+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:03:01.643+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:03:01.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.061 seconds
[2023-07-07T23:03:31.854+0000] {processor.py:157} INFO - Started process (PID=812) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:03:31.860+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:03:31.860+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:03:31.860+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:03:31.867+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:03:31.885+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:03:31.885+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:03:31.904+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:03:31.904+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:03:31.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T23:04:02.107+0000] {processor.py:157} INFO - Started process (PID=822) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:04:02.112+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:04:02.113+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:04:02.113+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:04:02.120+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:04:02.139+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:04:02.139+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:04:02.159+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:04:02.159+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:04:02.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T23:04:32.383+0000] {processor.py:157} INFO - Started process (PID=832) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:04:32.389+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:04:32.389+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:04:32.389+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:04:32.396+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:04:32.415+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:04:32.415+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:04:32.434+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:04:32.433+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:04:32.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T23:05:02.616+0000] {processor.py:157} INFO - Started process (PID=842) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:05:02.627+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:05:02.628+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:05:02.628+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:05:02.635+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:05:02.653+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:05:02.653+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:05:02.674+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:05:02.674+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:05:02.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.075 seconds
[2023-07-07T23:05:32.886+0000] {processor.py:157} INFO - Started process (PID=852) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:05:32.891+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:05:32.892+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:05:32.892+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:05:32.898+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:05:32.917+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:05:32.917+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:05:32.936+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:05:32.936+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:05:32.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T23:06:03.146+0000] {processor.py:157} INFO - Started process (PID=862) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:06:03.151+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:06:03.152+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:06:03.152+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:06:03.159+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:06:03.177+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:06:03.177+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:06:03.197+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:06:03.197+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:06:03.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T23:06:33.377+0000] {processor.py:157} INFO - Started process (PID=872) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:06:33.382+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:06:33.383+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:06:33.382+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:06:33.389+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:06:33.409+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:06:33.408+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:06:33.428+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:06:33.428+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:06:33.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.075 seconds
[2023-07-07T23:07:03.628+0000] {processor.py:157} INFO - Started process (PID=882) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:07:03.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:07:03.634+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:07:03.634+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:07:03.641+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:07:03.659+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:07:03.659+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:07:03.678+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:07:03.678+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:07:03.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T23:07:33.865+0000] {processor.py:157} INFO - Started process (PID=892) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:07:33.872+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:07:33.872+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:07:33.872+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:07:33.880+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:07:33.898+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:07:33.898+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:07:33.917+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:07:33.917+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:07:33.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T23:08:04.126+0000] {processor.py:157} INFO - Started process (PID=902) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:08:04.136+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:08:04.137+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:08:04.136+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:08:04.143+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:08:04.162+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:08:04.162+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:08:04.181+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:08:04.181+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:08:04.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T23:08:34.392+0000] {processor.py:157} INFO - Started process (PID=912) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:08:34.400+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:08:34.401+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:08:34.401+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:08:34.407+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:08:34.425+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:08:34.425+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:08:34.444+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:08:34.444+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:08:34.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T23:09:04.657+0000] {processor.py:157} INFO - Started process (PID=922) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:09:04.663+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:09:04.663+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:09:04.663+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:09:04.670+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:09:04.689+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:09:04.688+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:09:04.708+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:09:04.708+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:09:04.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T23:09:34.979+0000] {processor.py:157} INFO - Started process (PID=932) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:09:34.989+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:09:34.989+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:09:34.989+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:09:34.996+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:09:35.015+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:09:35.015+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:09:35.035+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:09:35.035+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:09:35.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T23:10:05.280+0000] {processor.py:157} INFO - Started process (PID=942) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:10:05.285+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:10:05.286+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:10:05.286+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:10:05.295+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:10:05.314+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:10:05.314+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:10:05.333+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:10:05.333+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:10:05.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T23:10:35.567+0000] {processor.py:157} INFO - Started process (PID=952) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:10:35.576+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:10:35.577+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:10:35.577+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:10:35.584+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:10:35.605+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:10:35.605+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:10:35.628+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:10:35.628+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:10:35.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.077 seconds
[2023-07-07T23:11:05.838+0000] {processor.py:157} INFO - Started process (PID=962) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:11:05.845+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:11:05.845+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:11:05.845+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:11:05.852+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:11:05.871+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:11:05.871+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:11:05.891+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:11:05.890+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:11:05.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T23:11:36.104+0000] {processor.py:157} INFO - Started process (PID=972) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:11:36.111+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:11:36.111+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:11:36.111+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:11:36.118+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:11:36.138+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:11:36.138+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:11:36.157+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:11:36.157+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:11:36.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T23:12:06.338+0000] {processor.py:157} INFO - Started process (PID=982) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:12:06.344+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:12:06.344+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:12:06.344+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:12:06.351+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:12:06.370+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:12:06.370+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:12:06.390+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:12:06.390+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:12:06.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T23:12:36.565+0000] {processor.py:157} INFO - Started process (PID=992) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:12:36.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:12:36.572+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:12:36.572+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:12:36.579+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:12:36.597+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:12:36.597+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:12:36.617+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:12:36.617+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:12:36.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T23:13:06.844+0000] {processor.py:157} INFO - Started process (PID=1002) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:13:06.850+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:13:06.850+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:13:06.850+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:13:06.857+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:13:06.875+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:13:06.875+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:13:06.894+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:13:06.894+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:13:06.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T23:13:37.088+0000] {processor.py:157} INFO - Started process (PID=1012) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:13:37.093+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:13:37.094+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:13:37.094+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:13:37.101+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:13:37.120+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:13:37.120+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:13:37.139+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:13:37.139+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:13:37.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T23:14:07.345+0000] {processor.py:157} INFO - Started process (PID=1022) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:14:07.352+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:14:07.352+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:14:07.352+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:14:07.359+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:14:07.379+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:14:07.379+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:14:07.400+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:14:07.400+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:14:07.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T23:14:37.620+0000] {processor.py:157} INFO - Started process (PID=1032) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:14:37.626+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:14:37.627+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:14:37.627+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:14:37.633+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:14:37.653+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:14:37.652+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:14:37.672+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:14:37.672+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:14:37.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T23:15:07.876+0000] {processor.py:157} INFO - Started process (PID=1042) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:15:07.879+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:15:07.879+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:15:07.879+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:15:07.886+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:15:07.905+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:15:07.905+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:15:07.924+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:15:07.924+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:15:07.935+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T23:15:38.152+0000] {processor.py:157} INFO - Started process (PID=1052) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:15:38.159+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:15:38.159+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:15:38.159+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:15:38.166+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:15:38.184+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:15:38.184+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:15:38.203+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:15:38.202+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:15:38.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T23:16:08.433+0000] {processor.py:157} INFO - Started process (PID=1062) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:16:08.440+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:16:08.441+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:16:08.441+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:16:08.448+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:16:08.466+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:16:08.466+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:16:08.487+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:16:08.487+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:16:08.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T23:16:38.685+0000] {processor.py:157} INFO - Started process (PID=1072) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:16:38.693+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:16:38.694+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:16:38.693+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:16:38.701+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:16:38.720+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:16:38.720+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:16:38.742+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:16:38.742+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:16:38.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T23:17:09.003+0000] {processor.py:157} INFO - Started process (PID=1082) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:17:09.008+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:17:09.009+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:17:09.009+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:17:09.017+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:17:09.038+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:17:09.038+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:17:09.059+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:17:09.059+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:17:09.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T23:17:39.247+0000] {processor.py:157} INFO - Started process (PID=1092) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:17:39.253+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:17:39.253+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:17:39.253+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:17:39.260+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:17:39.281+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:17:39.281+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:17:39.302+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:17:39.301+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:17:39.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T23:18:09.518+0000] {processor.py:157} INFO - Started process (PID=1102) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:18:09.524+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:18:09.524+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:18:09.524+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:18:09.531+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:18:09.550+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:18:09.550+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:18:09.571+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:18:09.571+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:18:09.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T23:18:39.764+0000] {processor.py:157} INFO - Started process (PID=1112) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:18:39.774+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:18:39.775+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:18:39.774+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:18:39.782+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:18:39.802+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:18:39.802+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:18:39.822+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:18:39.822+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:18:39.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.073 seconds
[2023-07-07T23:19:10.066+0000] {processor.py:157} INFO - Started process (PID=1122) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:19:10.074+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:19:10.074+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:19:10.074+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:19:10.081+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:19:10.099+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:19:10.099+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:19:10.119+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:19:10.119+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:19:10.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T23:19:40.364+0000] {processor.py:157} INFO - Started process (PID=1132) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:19:40.369+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:19:40.370+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:19:40.370+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:19:40.377+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:19:40.395+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:19:40.395+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:19:40.415+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:19:40.415+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:19:40.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T23:20:10.619+0000] {processor.py:157} INFO - Started process (PID=1142) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:20:10.630+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:20:10.631+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:20:10.630+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:20:10.637+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:20:10.656+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:20:10.656+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:20:10.675+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:20:10.675+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:20:10.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T23:20:40.868+0000] {processor.py:157} INFO - Started process (PID=1152) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:20:40.880+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:20:40.881+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:20:40.880+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:20:40.887+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:20:40.909+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:20:40.909+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:20:40.931+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:20:40.931+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:20:40.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.076 seconds
[2023-07-07T23:21:11.134+0000] {processor.py:157} INFO - Started process (PID=1162) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:21:11.139+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:21:11.140+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:21:11.140+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:21:11.147+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:21:11.165+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:21:11.165+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:21:11.184+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:21:11.184+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:21:11.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T23:21:41.432+0000] {processor.py:157} INFO - Started process (PID=1172) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:21:41.444+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:21:41.444+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:21:41.444+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:21:41.451+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:21:41.470+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:21:41.469+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:21:41.489+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:21:41.489+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:21:41.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T23:22:11.708+0000] {processor.py:157} INFO - Started process (PID=1182) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:22:11.714+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:22:11.714+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:22:11.714+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:22:11.721+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:22:11.746+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:22:11.746+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:22:11.773+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:22:11.773+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:22:11.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.079 seconds
[2023-07-07T23:22:42.012+0000] {processor.py:157} INFO - Started process (PID=1192) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:22:42.019+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:22:42.020+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:22:42.020+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:22:42.028+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:22:42.050+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:22:42.050+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:22:42.075+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:22:42.074+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:22:42.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.080 seconds
[2023-07-07T23:23:12.298+0000] {processor.py:157} INFO - Started process (PID=1202) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:23:12.304+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:23:12.304+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:23:12.304+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:23:12.311+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:23:12.330+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:23:12.329+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:23:12.348+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:23:12.348+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:23:12.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T23:23:42.581+0000] {processor.py:157} INFO - Started process (PID=1212) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:23:42.587+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:23:42.588+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:23:42.587+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:23:42.597+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:23:42.616+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:23:42.616+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:23:42.636+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:23:42.636+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:23:42.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T23:24:12.878+0000] {processor.py:157} INFO - Started process (PID=1222) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:24:12.885+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:24:12.885+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:24:12.885+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:24:12.895+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:24:12.913+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:24:12.913+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:24:12.932+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:24:12.932+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:24:12.945+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T23:24:43.175+0000] {processor.py:157} INFO - Started process (PID=1232) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:24:43.182+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:24:43.183+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:24:43.183+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:24:43.189+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:24:43.207+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:24:43.207+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:24:43.226+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:24:43.226+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:24:43.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T23:25:13.462+0000] {processor.py:157} INFO - Started process (PID=1242) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:25:13.468+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:25:13.469+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:25:13.469+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:25:13.476+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:25:13.497+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:25:13.496+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:25:13.517+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:25:13.517+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:25:13.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T23:25:43.736+0000] {processor.py:157} INFO - Started process (PID=1252) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:25:43.745+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:25:43.745+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:25:43.745+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:25:43.753+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:25:43.779+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:25:43.779+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:25:43.803+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:25:43.803+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:25:43.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.080 seconds
[2023-07-07T23:26:14.031+0000] {processor.py:157} INFO - Started process (PID=1262) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:26:14.040+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:26:14.041+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:26:14.041+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:26:14.047+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:26:14.066+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:26:14.066+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:26:14.086+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:26:14.086+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:26:14.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T23:26:44.321+0000] {processor.py:157} INFO - Started process (PID=1272) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:26:44.326+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:26:44.327+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:26:44.327+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:26:44.336+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:26:44.361+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:26:44.361+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:26:44.383+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:26:44.383+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:26:44.395+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.078 seconds
[2023-07-07T23:27:14.574+0000] {processor.py:157} INFO - Started process (PID=1282) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:27:14.584+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:27:14.584+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:27:14.584+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:27:14.591+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:27:14.610+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:27:14.610+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:27:14.629+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:27:14.629+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:27:14.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T23:27:44.814+0000] {processor.py:157} INFO - Started process (PID=1292) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:27:44.819+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:27:44.820+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:27:44.820+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:27:44.827+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:27:44.845+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:27:44.845+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:27:44.865+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:27:44.865+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:27:44.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T23:28:15.072+0000] {processor.py:157} INFO - Started process (PID=1302) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:28:15.078+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:28:15.078+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:28:15.078+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:28:15.085+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:28:15.103+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:28:15.103+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:28:15.123+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:28:15.123+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:28:15.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T23:28:45.320+0000] {processor.py:157} INFO - Started process (PID=1312) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:28:45.408+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:28:45.409+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:28:45.409+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:28:45.421+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:28:45.452+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:28:45.452+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:28:45.478+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:28:45.478+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:28:45.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.330 seconds
[2023-07-07T23:29:15.830+0000] {processor.py:157} INFO - Started process (PID=1322) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:29:15.835+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:29:15.836+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:29:15.835+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:29:15.842+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:29:15.861+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:29:15.860+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:29:15.879+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:29:15.879+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:29:15.890+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T23:29:46.092+0000] {processor.py:157} INFO - Started process (PID=1332) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:29:46.097+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:29:46.098+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:29:46.098+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:29:46.104+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:29:46.123+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:29:46.123+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:29:46.143+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:29:46.143+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:29:46.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T23:30:16.336+0000] {processor.py:157} INFO - Started process (PID=1342) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:30:16.337+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:30:16.337+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:30:16.337+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:30:16.345+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:30:16.366+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:30:16.365+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:30:16.386+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:30:16.386+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:30:16.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T23:30:46.606+0000] {processor.py:157} INFO - Started process (PID=1352) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:30:46.612+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:30:46.612+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:30:46.612+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:30:46.619+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:30:46.640+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:30:46.640+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:30:46.661+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:30:46.661+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:30:46.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T23:30:52.745+0000] {processor.py:157} INFO - Started process (PID=1362) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:30:52.746+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:30:52.746+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:30:52.746+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:30:52.761+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:30:52.779+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:30:52.779+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:30:52.798+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:30:52.798+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:30:52.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T23:31:23.001+0000] {processor.py:157} INFO - Started process (PID=1372) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:31:23.010+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:31:23.011+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:31:23.011+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:31:23.018+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:31:23.043+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:31:23.043+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:31:23.064+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:31:23.064+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:31:23.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.077 seconds
[2023-07-07T23:31:35.129+0000] {processor.py:157} INFO - Started process (PID=1373) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:31:35.129+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:31:35.130+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:31:35.130+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:31:35.137+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:31:35.157+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:31:35.157+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:31:35.178+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:31:35.178+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:31:35.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T23:32:05.407+0000] {processor.py:157} INFO - Started process (PID=1383) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:32:05.414+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:32:05.415+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:32:05.414+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:32:05.424+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:32:05.446+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:32:05.446+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:32:05.466+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:32:05.466+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:32:05.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T23:32:15.467+0000] {processor.py:157} INFO - Started process (PID=1384) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:32:15.467+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:32:15.467+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:32:15.467+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:32:15.475+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v7']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:32:15.495+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:32:15.495+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:32:15.517+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:32:15.517+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v7 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:32:15.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T23:32:35.671+0000] {processor.py:157} INFO - Started process (PID=1394) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:32:35.675+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:32:35.676+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:32:35.676+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:32:35.683+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:32:35.777+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:32:35.777+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:dag_scrap_biobio_v8
[2023-07-07T23:32:35.786+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:32:35.786+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:dag_scrap_biobio_v8
[2023-07-07T23:32:35.790+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:32:35.790+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:dag_scrap_biobio_v8
[2023-07-07T23:32:35.801+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:32:35.801+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:32:35.810+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:32:35.810+0000] {dag.py:2747} INFO - Creating ORM DAG for dag_scrap_biobio_v8
[2023-07-07T23:32:35.819+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:32:35.819+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-06T00:00:00+00:00, run_after=2023-07-07T00:00:00+00:00
[2023-07-07T23:32:35.832+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.164 seconds
[2023-07-07T23:33:05.855+0000] {processor.py:157} INFO - Started process (PID=1408) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:33:05.867+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:33:05.867+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:33:05.867+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:33:05.874+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:33:05.892+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:33:05.892+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:33:05.912+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:33:05.912+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:33:05.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T23:33:16.924+0000] {processor.py:157} INFO - Started process (PID=1409) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:33:16.925+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:33:16.925+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:33:16.925+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:33:16.933+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:33:16.952+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:33:16.952+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:33:16.974+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:33:16.974+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:33:16.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.065 seconds
[2023-07-07T23:33:47.208+0000] {processor.py:157} INFO - Started process (PID=1419) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:33:47.241+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:33:47.242+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:33:47.242+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:33:47.250+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:33:47.271+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:33:47.271+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:33:47.295+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:33:47.295+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:33:47.310+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.103 seconds
[2023-07-07T23:34:17.456+0000] {processor.py:157} INFO - Started process (PID=1429) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:34:17.461+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:34:17.462+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:34:17.462+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:34:17.470+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:34:17.490+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:34:17.490+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:34:17.509+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:34:17.509+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:34:17.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T23:34:47.793+0000] {processor.py:157} INFO - Started process (PID=1439) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:34:47.806+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:34:47.807+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:34:47.807+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:34:47.813+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:34:47.832+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:34:47.832+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:34:47.852+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:34:47.852+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:34:47.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.073 seconds
[2023-07-07T23:35:18.116+0000] {processor.py:157} INFO - Started process (PID=1449) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:35:18.123+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:35:18.124+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:35:18.124+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:35:18.130+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:35:18.149+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:35:18.149+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:35:18.169+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:35:18.169+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:35:18.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T23:35:48.420+0000] {processor.py:157} INFO - Started process (PID=1459) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:35:48.425+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:35:48.426+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:35:48.426+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:35:48.435+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:35:48.455+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:35:48.455+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:35:48.475+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:35:48.474+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:35:48.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T23:36:18.703+0000] {processor.py:157} INFO - Started process (PID=1469) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:36:18.703+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:36:18.704+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:36:18.704+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:36:18.710+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:36:18.730+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:36:18.730+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:36:18.750+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:36:18.750+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:36:18.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T23:36:48.944+0000] {processor.py:157} INFO - Started process (PID=1479) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:36:48.949+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:36:48.950+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:36:48.950+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:36:48.959+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:36:48.978+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:36:48.978+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:36:48.997+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:36:48.997+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:36:49.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T23:37:19.210+0000] {processor.py:157} INFO - Started process (PID=1489) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:37:19.215+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:37:19.216+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:37:19.216+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:37:19.224+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:37:19.244+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:37:19.244+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:37:19.264+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:37:19.264+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:37:19.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T23:37:49.497+0000] {processor.py:157} INFO - Started process (PID=1499) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:37:49.508+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:37:49.508+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:37:49.508+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:37:49.515+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:37:49.537+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:37:49.536+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:37:49.556+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:37:49.556+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:37:49.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T23:38:19.762+0000] {processor.py:157} INFO - Started process (PID=1509) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:38:19.768+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:38:19.768+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:38:19.768+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:38:19.775+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:38:19.797+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:38:19.797+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:38:19.817+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:38:19.817+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:38:19.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T23:38:50.033+0000] {processor.py:157} INFO - Started process (PID=1519) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:38:50.039+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:38:50.040+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:38:50.039+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:38:50.046+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:38:50.067+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:38:50.067+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:38:50.087+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:38:50.087+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:38:50.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T23:39:20.230+0000] {processor.py:157} INFO - Started process (PID=1529) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:39:20.237+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:39:20.237+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:39:20.237+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:39:20.244+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:39:20.265+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:39:20.265+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:39:20.284+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:39:20.284+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:39:20.297+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T23:39:50.479+0000] {processor.py:157} INFO - Started process (PID=1539) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:39:50.486+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:39:50.487+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:39:50.486+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:39:50.494+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:39:50.514+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:39:50.514+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:39:50.536+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:39:50.536+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:39:50.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T23:40:20.727+0000] {processor.py:157} INFO - Started process (PID=1549) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:40:20.734+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:40:20.734+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:40:20.734+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:40:20.742+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:40:20.763+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:40:20.763+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:40:20.783+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:40:20.783+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:40:20.795+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T23:40:50.964+0000] {processor.py:157} INFO - Started process (PID=1559) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:40:50.972+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:40:50.973+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:40:50.973+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:40:50.979+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:40:51.000+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:40:51.000+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:40:51.023+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:40:51.023+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:40:51.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.073 seconds
[2023-07-07T23:41:21.215+0000] {processor.py:157} INFO - Started process (PID=1575) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:41:21.220+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:41:21.221+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:41:21.221+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:41:21.229+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:41:21.251+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:41:21.250+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:41:21.270+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:41:21.270+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:41:21.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T23:41:51.491+0000] {processor.py:157} INFO - Started process (PID=1586) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:41:51.502+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:41:51.502+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:41:51.502+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:41:51.509+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:41:51.528+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:41:51.528+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:41:51.549+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:41:51.548+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:41:51.560+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T23:42:21.751+0000] {processor.py:157} INFO - Started process (PID=1596) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:42:21.752+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:42:21.753+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:42:21.752+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:42:21.760+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:42:21.781+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:42:21.781+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:42:21.801+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:42:21.801+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:42:21.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.064 seconds
[2023-07-07T23:42:52.002+0000] {processor.py:157} INFO - Started process (PID=1606) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:42:52.008+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:42:52.008+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:42:52.008+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:42:52.016+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:42:52.037+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:42:52.037+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:42:52.063+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:42:52.062+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:42:52.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.076 seconds
[2023-07-07T23:43:22.275+0000] {processor.py:157} INFO - Started process (PID=1616) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:43:22.286+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:43:22.286+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:43:22.286+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:43:22.293+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:43:22.312+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:43:22.312+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:43:22.331+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:43:22.331+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:43:22.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T23:43:52.527+0000] {processor.py:157} INFO - Started process (PID=1626) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:43:52.532+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:43:52.533+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:43:52.533+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:43:52.541+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:43:52.561+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:43:52.561+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:43:52.583+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:43:52.582+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:43:52.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T23:44:22.809+0000] {processor.py:157} INFO - Started process (PID=1636) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:44:22.815+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:44:22.815+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:44:22.815+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:44:22.822+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:44:22.844+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:44:22.844+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:44:22.865+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:44:22.865+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:44:22.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T23:44:53.063+0000] {processor.py:157} INFO - Started process (PID=1646) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:44:53.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:44:53.070+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:44:53.070+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:44:53.077+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:44:53.097+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:44:53.097+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:44:53.119+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:44:53.119+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:44:53.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T23:45:23.319+0000] {processor.py:157} INFO - Started process (PID=1656) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:45:23.325+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:45:23.325+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:45:23.325+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:45:23.332+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:45:23.352+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:45:23.352+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:45:23.372+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:45:23.372+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:45:23.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T23:45:53.560+0000] {processor.py:157} INFO - Started process (PID=1666) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:45:53.565+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:45:53.566+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:45:53.565+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:45:53.573+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:45:53.591+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:45:53.591+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:45:53.612+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:45:53.612+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:45:53.624+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T23:46:23.809+0000] {processor.py:157} INFO - Started process (PID=1676) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:46:23.815+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:46:23.815+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:46:23.815+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:46:23.822+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:46:23.842+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:46:23.842+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:46:23.862+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:46:23.862+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:46:23.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T23:46:54.054+0000] {processor.py:157} INFO - Started process (PID=1686) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:46:54.059+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:46:54.060+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:46:54.059+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:46:54.066+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:46:54.086+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:46:54.086+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:46:54.106+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:46:54.106+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:46:54.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T23:47:24.313+0000] {processor.py:157} INFO - Started process (PID=1696) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:47:24.318+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:47:24.319+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:47:24.319+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:47:24.326+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:47:24.346+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:47:24.346+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:47:24.367+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:47:24.367+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:47:24.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.071 seconds
[2023-07-07T23:47:54.580+0000] {processor.py:157} INFO - Started process (PID=1706) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:47:54.587+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:47:54.588+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:47:54.588+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:47:54.594+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:47:54.616+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:47:54.616+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:47:54.638+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:47:54.638+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:47:54.650+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
[2023-07-07T23:48:24.886+0000] {processor.py:157} INFO - Started process (PID=1716) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:48:24.892+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:48:24.892+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:48:24.892+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:48:24.901+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:48:24.921+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:48:24.920+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:48:24.941+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:48:24.941+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:48:24.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.069 seconds
[2023-07-07T23:48:55.155+0000] {processor.py:157} INFO - Started process (PID=1726) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:48:55.161+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:48:55.161+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:48:55.161+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:48:55.168+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:48:55.188+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:48:55.188+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:48:55.211+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:48:55.211+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:48:55.222+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T23:49:25.445+0000] {processor.py:157} INFO - Started process (PID=1736) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:49:25.452+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:49:25.452+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:49:25.452+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:49:25.460+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:49:25.479+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:49:25.479+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:49:25.501+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:49:25.501+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:49:25.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T23:49:55.746+0000] {processor.py:157} INFO - Started process (PID=1746) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:49:55.752+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:49:55.752+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:49:55.752+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:49:55.760+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:49:55.782+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:49:55.782+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:49:55.808+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:49:55.808+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:49:55.819+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.075 seconds
[2023-07-07T23:50:26.012+0000] {processor.py:157} INFO - Started process (PID=1756) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:50:26.017+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:50:26.018+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:50:26.018+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:50:26.024+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:50:26.044+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:50:26.044+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:50:26.065+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:50:26.065+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:50:26.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T23:50:56.278+0000] {processor.py:157} INFO - Started process (PID=1766) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:50:56.284+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:50:56.284+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:50:56.284+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:50:56.291+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:50:56.310+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:50:56.310+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:50:56.329+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:50:56.329+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:50:56.342+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T23:51:26.525+0000] {processor.py:157} INFO - Started process (PID=1776) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:51:26.532+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:51:26.532+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:51:26.532+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:51:26.539+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:51:26.560+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:51:26.560+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:51:26.580+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:51:26.579+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:51:26.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.068 seconds
[2023-07-07T23:51:56.811+0000] {processor.py:157} INFO - Started process (PID=1786) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:51:56.818+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:51:56.819+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:51:56.818+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:51:56.825+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:51:56.845+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:51:56.845+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:51:56.865+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:51:56.865+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:51:56.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T23:51:58.919+0000] {processor.py:157} INFO - Started process (PID=1789) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:51:58.919+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:51:58.920+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:51:58.919+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:51:58.927+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:51:58.947+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:51:58.946+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:51:58.969+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:51:58.968+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:51:58.983+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T23:52:03.961+0000] {processor.py:157} INFO - Started process (PID=1790) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:52:03.962+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:52:03.962+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:52:03.962+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:52:03.970+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:52:03.990+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:52:03.989+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:52:04.010+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:52:04.010+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:52:04.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T23:52:34.216+0000] {processor.py:157} INFO - Started process (PID=1800) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:52:34.222+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:52:34.223+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:52:34.223+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:52:34.231+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:52:34.257+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:52:34.256+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:52:34.279+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:52:34.279+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:52:34.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.076 seconds
[2023-07-07T23:52:35.312+0000] {processor.py:157} INFO - Started process (PID=1801) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:52:35.312+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:52:35.312+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:52:35.312+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:52:35.320+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:52:35.339+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:52:35.339+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:52:35.364+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:52:35.364+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:52:35.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.074 seconds
[2023-07-07T23:52:48.384+0000] {processor.py:157} INFO - Started process (PID=1802) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:52:48.385+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:52:48.385+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:52:48.385+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:52:48.394+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:52:48.413+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:52:48.413+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:52:48.433+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:52:48.432+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:52:48.445+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.063 seconds
[2023-07-07T23:53:00.538+0000] {processor.py:157} INFO - Started process (PID=1812) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:53:00.543+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:53:00.544+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:53:00.544+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:53:00.551+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v8']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:53:00.572+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:53:00.571+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:53:00.596+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:53:00.596+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v8 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:53:00.610+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.073 seconds
[2023-07-07T23:53:19.712+0000] {processor.py:157} INFO - Started process (PID=1813) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:53:19.712+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:53:19.713+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:53:19.713+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:53:19.723+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v9']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:53:19.821+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:53:19.821+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:dag_scrap_biobio_v9
[2023-07-07T23:53:19.830+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:53:19.829+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:dag_scrap_biobio_v9
[2023-07-07T23:53:19.834+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:53:19.834+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:dag_scrap_biobio_v9
[2023-07-07T23:53:19.845+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:53:19.844+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:53:19.855+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:53:19.855+0000] {dag.py:2747} INFO - Creating ORM DAG for dag_scrap_biobio_v9
[2023-07-07T23:53:19.865+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:53:19.865+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v9 to 2023-07-06T00:00:00+00:00, run_after=2023-07-07T00:00:00+00:00
[2023-07-07T23:53:19.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.167 seconds
[2023-07-07T23:53:50.014+0000] {processor.py:157} INFO - Started process (PID=1823) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:53:50.021+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:53:50.021+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:53:50.021+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:53:50.031+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v9']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:53:50.053+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:53:50.052+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:53:50.074+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:53:50.074+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v9 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:53:50.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.075 seconds
[2023-07-07T23:54:20.261+0000] {processor.py:157} INFO - Started process (PID=1833) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:54:20.266+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:54:20.267+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:54:20.267+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:54:20.273+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v9']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:54:20.294+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:54:20.294+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:54:20.314+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:54:20.314+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v9 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:54:20.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T23:54:50.502+0000] {processor.py:157} INFO - Started process (PID=1843) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:54:50.507+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:54:50.507+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:54:50.507+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:54:50.514+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v9']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:54:50.535+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:54:50.535+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:54:50.554+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:54:50.554+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v9 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:54:50.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T23:55:20.763+0000] {processor.py:157} INFO - Started process (PID=1853) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:55:20.765+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:55:20.765+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:55:20.765+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:55:20.772+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v9']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:55:20.791+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:55:20.791+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:55:20.812+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:55:20.811+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v9 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:55:20.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.062 seconds
[2023-07-07T23:55:27.813+0000] {processor.py:157} INFO - Started process (PID=1861) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:55:27.813+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:55:27.814+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:55:27.814+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:55:27.822+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v9']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:55:27.840+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:55:27.840+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:55:27.859+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:55:27.859+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v9 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:55:27.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.061 seconds
[2023-07-07T23:55:38.947+0000] {processor.py:157} INFO - Started process (PID=1864) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:55:38.953+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:55:38.953+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:55:38.953+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:55:38.960+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v9']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:55:38.982+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:55:38.982+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:55:39.002+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:55:39.002+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v9 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:55:39.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T23:55:54.063+0000] {processor.py:157} INFO - Started process (PID=1865) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:55:54.064+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:55:54.064+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:55:54.064+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:55:54.072+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v10']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:55:54.167+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:55:54.167+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:dag_scrap_biobio_v10
[2023-07-07T23:55:54.174+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:55:54.174+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:dag_scrap_biobio_v10
[2023-07-07T23:55:54.178+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:55:54.178+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:dag_scrap_biobio_v10
[2023-07-07T23:55:54.190+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:55:54.190+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:55:54.201+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:55:54.201+0000] {dag.py:2747} INFO - Creating ORM DAG for dag_scrap_biobio_v10
[2023-07-07T23:55:54.212+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:55:54.212+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v10 to 2023-07-06T00:00:00+00:00, run_after=2023-07-07T00:00:00+00:00
[2023-07-07T23:55:54.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.164 seconds
[2023-07-07T23:56:24.242+0000] {processor.py:157} INFO - Started process (PID=1875) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:56:24.249+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:56:24.249+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:56:24.249+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:56:24.256+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v10']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:56:24.279+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:56:24.279+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:56:24.303+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:56:24.303+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v10 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:56:24.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.077 seconds
[2023-07-07T23:56:54.482+0000] {processor.py:157} INFO - Started process (PID=1885) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:56:54.488+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:56:54.489+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:56:54.489+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:56:54.495+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v10']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:56:54.515+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:56:54.514+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:56:54.534+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:56:54.534+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v10 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:56:54.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T23:57:24.728+0000] {processor.py:157} INFO - Started process (PID=1895) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:57:24.734+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:57:24.735+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:57:24.735+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:57:24.744+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v10']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:57:24.769+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:57:24.769+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:57:24.788+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:57:24.788+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v10 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:57:24.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.074 seconds
[2023-07-07T23:57:54.972+0000] {processor.py:157} INFO - Started process (PID=1911) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:57:54.981+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:57:54.981+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:57:54.981+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:57:54.988+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v10']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:57:55.031+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:57:55.031+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:57:55.052+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:57:55.052+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v10 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:57:55.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.092 seconds
[2023-07-07T23:58:25.228+0000] {processor.py:157} INFO - Started process (PID=1922) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:58:25.234+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:58:25.235+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:58:25.235+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:58:25.241+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v10']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:58:25.261+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:58:25.261+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:58:25.281+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:58:25.281+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v10 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:58:25.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.067 seconds
[2023-07-07T23:58:55.485+0000] {processor.py:157} INFO - Started process (PID=1932) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:58:55.493+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:58:55.493+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:58:55.493+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:58:55.500+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v10']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:58:55.519+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:58:55.519+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:58:55.540+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:58:55.540+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v10 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:58:55.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.070 seconds
[2023-07-07T23:59:25.741+0000] {processor.py:157} INFO - Started process (PID=1942) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:59:25.748+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:59:25.748+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:59:25.748+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:59:25.755+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v10']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:59:25.775+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:59:25.774+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:59:25.794+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:59:25.794+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v10 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:59:25.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.066 seconds
[2023-07-07T23:59:55.972+0000] {processor.py:157} INFO - Started process (PID=1952) to work on /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:59:55.979+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/dag_scrap_biobio.py for tasks to queue
[2023-07-07T23:59:55.980+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:59:55.980+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:59:55.986+0000] {processor.py:836} INFO - DAG(s) dict_keys(['dag_scrap_biobio_v10']) retrieved from /opt/airflow/dags/dag_scrap_biobio.py
[2023-07-07T23:59:56.008+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:59:56.008+0000] {dag.py:2726} INFO - Sync 1 DAGs
[2023-07-07T23:59:56.029+0000] {logging_mixin.py:149} INFO - [2023-07-07T23:59:56.029+0000] {dag.py:3490} INFO - Setting next_dagrun for dag_scrap_biobio_v10 to 2023-07-07T00:00:00+00:00, run_after=2023-07-08T00:00:00+00:00
[2023-07-07T23:59:56.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/dag_scrap_biobio.py took 0.072 seconds
